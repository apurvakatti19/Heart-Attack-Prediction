{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected2D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.MinMaxScaler(feature_range=(0,1))\n",
    "#sb.set(rc={'figure.figsize':(10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['id', 'ccf', 'age', 'sex', 'painLocation', 'painExcertion', 'painResting', 'pncaden', 'chestPainType',\n",
    "        'restingBP','hyperTension', 'cholestrol', 'smoker', 'noOfCigarette' , 'smokingYears', 'bloodSugar',\n",
    "        'historyOfDiabetes', 'historyOfHA', 'restingECG', 'ekgmo', 'ekgday', 'ekgyr', 'dig',\n",
    "        'prop', 'nitr', 'pro' ,'diuretic', 'proto', 'stressTestDuration', 'stressTestSTTime', 'stressTestMet',\n",
    "        'stressTestMaxHR', 'stressTestRestingHR', 'stressTestMaxFirstBPS','stressTestMaxSecondBPS', 'dummy',\n",
    "        'stressTestRestingBP', 'exerciseAngina', 'xhypo', 'STDepressionExercise', 'STDepressionSlope',\n",
    "        'rldv5','rldv5e', 'coloredVesselsFluroscopy', 'restckm','exerckm','restef', 'restwm', 'exeref', 'exerwm',\n",
    "        'heartWallDamage', 'thalsev', 'thalpul', 'earlobe', 'cmo', 'cday', 'cyr', 'output', 'lmt',\n",
    " 'ladprox', 'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4',\n",
    " 'lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop=['id', 'ccf', 'painExcertion', 'painResting', 'pncaden','historyOfDiabetes', 'ekgmo', 'ekgday',\n",
    "               'ekgyr', 'dig', 'prop', 'nitr', 'pro' ,'diuretic', 'proto','stressTestMet', 'dummy', 'xhypo',\n",
    "               'rldv5','rldv5e','restckm','exerckm','restef', 'restwm', 'exeref','exerwm', 'thalsev', 'thalpul',\n",
    "               'earlobe', 'cmo', 'cday', 'cyr', 'lmt', 'ladprox', 'laddist', 'diag','cxmain', 'ramus', 'om1', 'om2',\n",
    "               'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4','lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting and Preprocessing the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleveland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedCleveland.txt', 'w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clevelandData=pd.read_csv(\"processedCleveland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "clevelandData=clevelandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hungarian.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedHungarian.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarianData=pd.read_csv(\"processedHungarian.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "hungarianData=hungarianData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('switzerland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedSwitzerland.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "switzerlandData=pd.read_csv(\"processedSwitzerland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "switzerlandData=switzerlandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long-beach-va.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedLongBeach.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "longBeachData=pd.read_csv(\"processedLongBeach.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "longBeachData=longBeachData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[clevelandData,hungarianData,longBeachData,switzerlandData]\n",
    "data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 76 columns):\n",
      "id                          900 non-null object\n",
      "ccf                         900 non-null object\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "painExcertion               900 non-null float64\n",
      "painResting                 900 non-null float64\n",
      "pncaden                     900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfDiabetes           900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "ekgmo                       900 non-null float64\n",
      "ekgday                      900 non-null float64\n",
      "ekgyr                       900 non-null object\n",
      "dig                         900 non-null float64\n",
      "prop                        900 non-null float64\n",
      "nitr                        900 non-null object\n",
      "pro                         900 non-null object\n",
      "diuretic                    900 non-null float64\n",
      "proto                       900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMet               900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "dummy                       900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "xhypo                       900 non-null object\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "rldv5                       900 non-null object\n",
      "rldv5e                      900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "restckm                     900 non-null object\n",
      "exerckm                     900 non-null float64\n",
      "restef                      900 non-null float64\n",
      "restwm                      900 non-null float64\n",
      "exeref                      900 non-null float64\n",
      "exerwm                      900 non-null float64\n",
      "heartWallDamage             900 non-null float64\n",
      "thalsev                     900 non-null float64\n",
      "thalpul                     900 non-null float64\n",
      "earlobe                     900 non-null object\n",
      "cmo                         900 non-null float64\n",
      "cday                        900 non-null float64\n",
      "cyr                         900 non-null float64\n",
      "output                      900 non-null float64\n",
      "lmt                         900 non-null float64\n",
      "ladprox                     900 non-null float64\n",
      "laddist                     900 non-null float64\n",
      "diag                        900 non-null float64\n",
      "cxmain                      900 non-null float64\n",
      "ramus                       900 non-null float64\n",
      "om1                         900 non-null float64\n",
      "om2                         900 non-null float64\n",
      "rcaprox                     900 non-null float64\n",
      "rcadist                     900 non-null float64\n",
      "lvx1                        900 non-null float64\n",
      "lvx2                        900 non-null object\n",
      "lvx3                        900 non-null float64\n",
      "lvx4                        900 non-null object\n",
      "lvf                         900 non-null object\n",
      "cathef                      900 non-null object\n",
      "junk                        900 non-null float64\n",
      "name                        900 non-null object\n",
      "dtypes: float64(56), object(20)\n",
      "memory usage: 541.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>painExcertion</th>\n",
       "      <th>painResting</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>bloodSugar</th>\n",
       "      <th>historyOfDiabetes</th>\n",
       "      <th>historyOfHA</th>\n",
       "      <th>restingECG</th>\n",
       "      <th>ekgmo</th>\n",
       "      <th>ekgday</th>\n",
       "      <th>ekgyr</th>\n",
       "      <th>dig</th>\n",
       "      <th>prop</th>\n",
       "      <th>nitr</th>\n",
       "      <th>pro</th>\n",
       "      <th>diuretic</th>\n",
       "      <th>proto</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMet</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>dummy</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>xhypo</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>rldv5</th>\n",
       "      <th>rldv5e</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>restckm</th>\n",
       "      <th>exerckm</th>\n",
       "      <th>restef</th>\n",
       "      <th>restwm</th>\n",
       "      <th>exeref</th>\n",
       "      <th>exerwm</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>thalsev</th>\n",
       "      <th>thalpul</th>\n",
       "      <th>earlobe</th>\n",
       "      <th>cmo</th>\n",
       "      <th>cday</th>\n",
       "      <th>cyr</th>\n",
       "      <th>output</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx1</th>\n",
       "      <th>lvx2</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "      <th>cathef</th>\n",
       "      <th>junk</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ccf age  sex  painLocation  painExcertion  painResting  pncaden  \\\n",
       "0  1   0  63  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "1  2   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "2  3   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "3  4   0  37  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "4  6   0  41  0.0          -9.0           -9.0         -9.0     -9.0   \n",
       "\n",
       "  chestPainType restingBP hyperTension  cholestrol smoker  noOfCigarette  \\\n",
       "0             1       145            1       233.0     -9           50.0   \n",
       "1             4       160            1       286.0     -9           40.0   \n",
       "2             4       120            1       229.0     -9           20.0   \n",
       "3             3       130            0       250.0     -9            0.0   \n",
       "4             2       130            1       204.0     -9            0.0   \n",
       "\n",
       "   smokingYears  bloodSugar  historyOfDiabetes  historyOfHA  restingECG  \\\n",
       "0          20.0         1.0               -9.0          1.0         2.0   \n",
       "1          40.0         0.0               -9.0          1.0         2.0   \n",
       "2          35.0         0.0               -9.0          1.0         2.0   \n",
       "3           0.0         0.0               -9.0          1.0         0.0   \n",
       "4           0.0         0.0               -9.0          1.0         2.0   \n",
       "\n",
       "   ekgmo  ekgday ekgyr  dig  prop nitr pro  diuretic  proto  \\\n",
       "0    2.0     3.0    81  0.0   0.0    0   0       0.0    1.0   \n",
       "1    3.0     5.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "2    2.0    19.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "3    2.0    13.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "4    2.0     7.0    81  0.0   0.0    0   0       0.0    1.0   \n",
       "\n",
       "   stressTestDuration  stressTestSTTime  stressTestMet  stressTestMaxHR  \\\n",
       "0                10.5               6.0           13.0            150.0   \n",
       "1                 9.5               6.0           13.0            108.0   \n",
       "2                 8.5               6.0           10.0            129.0   \n",
       "3                13.0              13.0           17.0            187.0   \n",
       "4                 7.0              -9.0            9.0            172.0   \n",
       "\n",
       "   stressTestRestingHR  stressTestMaxFirstBPS  stressTestMaxSecondBPS  dummy  \\\n",
       "0                 60.0                  190.0                    90.0  145.0   \n",
       "1                 64.0                  160.0                    90.0  160.0   \n",
       "2                 78.0                  140.0                    80.0  120.0   \n",
       "3                 84.0                  195.0                    68.0  130.0   \n",
       "4                 71.0                  160.0                    74.0  130.0   \n",
       "\n",
       "   stressTestRestingBP  exerciseAngina xhypo  STDepressionExercise  \\\n",
       "0                 85.0             0.0     0                   2.3   \n",
       "1                 90.0             1.0     0                   1.5   \n",
       "2                 80.0             1.0     0                   2.6   \n",
       "3                 78.0             0.0     0                   3.5   \n",
       "4                 86.0             0.0     0                   1.4   \n",
       "\n",
       "   STDepressionSlope rldv5  rldv5e coloredVesselsFluroscopy restckm  exerckm  \\\n",
       "0                3.0    -9   172.0                        0      -9     -9.0   \n",
       "1                2.0    -9   185.0                        3      -9     -9.0   \n",
       "2                2.0    -9   150.0                        2      -9     -9.0   \n",
       "3                3.0    -9   167.0                        0      -9     -9.0   \n",
       "4                1.0    -9    40.0                        0      -9     -9.0   \n",
       "\n",
       "   restef  restwm  exeref  exerwm  heartWallDamage  thalsev  thalpul earlobe  \\\n",
       "0    -9.0    -9.0    -9.0    -9.0              6.0     -9.0     -9.0      -9   \n",
       "1    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "2    -9.0    -9.0    -9.0    -9.0              7.0     -9.0     -9.0      -9   \n",
       "3    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "4    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "\n",
       "   cmo  cday   cyr  output  lmt  ladprox  laddist  diag  cxmain  ramus  om1  \\\n",
       "0  2.0  16.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "1  2.0   5.0  81.0     2.0  1.0      2.0      2.0  -9.0     2.0   -9.0  1.0   \n",
       "2  2.0  20.0  81.0     1.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "3  2.0   4.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "4  2.0  18.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "\n",
       "   om2  rcaprox  rcadist  lvx1 lvx2  lvx3 lvx4 lvf cathef  junk  name  \n",
       "0 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "1 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "2 -9.0      2.0      2.0   1.0    1   1.0    7   3     -9  -9.0  name  \n",
       "3 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "4 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columnsToDrop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>bloodSugar</th>\n",
       "      <th>historyOfHA</th>\n",
       "      <th>restingECG</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex  painLocation chestPainType restingBP hyperTension  cholestrol  \\\n",
       "0  63  1.0          -9.0             1       145            1       233.0   \n",
       "1  67  1.0          -9.0             4       160            1       286.0   \n",
       "2  67  1.0          -9.0             4       120            1       229.0   \n",
       "3  37  1.0          -9.0             3       130            0       250.0   \n",
       "4  41  0.0          -9.0             2       130            1       204.0   \n",
       "\n",
       "  smoker  noOfCigarette  smokingYears  bloodSugar  historyOfHA  restingECG  \\\n",
       "0     -9           50.0          20.0         1.0          1.0         2.0   \n",
       "1     -9           40.0          40.0         0.0          1.0         2.0   \n",
       "2     -9           20.0          35.0         0.0          1.0         2.0   \n",
       "3     -9            0.0           0.0         0.0          1.0         0.0   \n",
       "4     -9            0.0           0.0         0.0          1.0         2.0   \n",
       "\n",
       "   stressTestDuration  stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0                10.5               6.0            150.0                 60.0   \n",
       "1                 9.5               6.0            108.0                 64.0   \n",
       "2                 8.5               6.0            129.0                 78.0   \n",
       "3                13.0              13.0            187.0                 84.0   \n",
       "4                 7.0              -9.0            172.0                 71.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    90.0                 85.0   \n",
       "1                  160.0                    90.0                 90.0   \n",
       "2                  140.0                    80.0                 80.0   \n",
       "3                  195.0                    68.0                 78.0   \n",
       "4                  160.0                    74.0                 86.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  STDepressionSlope  \\\n",
       "0             0.0                   2.3                3.0   \n",
       "1             1.0                   1.5                2.0   \n",
       "2             1.0                   2.6                2.0   \n",
       "3             0.0                   3.5                3.0   \n",
       "4             0.0                   1.4                1.0   \n",
       "\n",
       "  coloredVesselsFluroscopy  heartWallDamage  output  \n",
       "0                        0              6.0     0.0  \n",
       "1                        3              3.0     2.0  \n",
       "2                        2              7.0     1.0  \n",
       "3                        0              3.0     0.0  \n",
       "4                        0              3.0     0.0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "heartWallDamage             900 non-null float64\n",
      "output                      900 non-null float64\n",
      "dtypes: float64(20), object(6)\n",
      "memory usage: 189.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPainLocation(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>0):\n",
    "            if(columns[2]==1):\n",
    "                return 0\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceByMean(columns,mean):\n",
    "    if(columns[0]<1):\n",
    "        return int(mean)\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHypertension(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>120):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCholestrol(columns):\n",
    "    if(columns[0]<=200):\n",
    "        return 0\n",
    "    elif(columns[0]<=239):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSmoking(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(int(columns[1])>0):\n",
    "            return 1\n",
    "        elif(int(columns[1])==0):\n",
    "            return 0\n",
    "        if(int(columns[2])>0):\n",
    "            return 1\n",
    "        elif(int(columns[2])==0):\n",
    "            return 0\n",
    "    return int(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDummyCategory(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRestingECG(columns):\n",
    "    if(columns[0]==2):\n",
    "        return 1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processstressTestSTTime(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processExerciseAgnia(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]==1):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSTDepressionSlope(columns):\n",
    "    if(columns[0]<1):\n",
    "        return -1\n",
    "    if(columns[0]==1):\n",
    "        return 1\n",
    "    if(columns[0]==2):\n",
    "        return 0\n",
    "    if(columns[0]==3):\n",
    "        return 2\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processcoloredVesselsFluroscopy(columns):\n",
    "    if(columns[0]==-9 or columns[0]==9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHeartWallDamage(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    if(columns[0]<=3):\n",
    "        return 0\n",
    "    if(columns[0]<=6):\n",
    "        return 2\n",
    "    if(columns[0]==7):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(columns):\n",
    "    if(columns[0]>1):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age']=pd.to_numeric(data['age'])\n",
    "d=data[data.age !=-9]\n",
    "d=d[d.age != 0]\n",
    "mean=d['age'].mean()\n",
    "mean=data['age'].mean()\n",
    "data['age']=data[['age']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex']=pd.to_numeric(data['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['painLocation']=data[['painLocation','output','bloodSugar']].apply(processPainLocation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['chestPainType']=pd.to_numeric(data['chestPainType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['chestPainType'], prefix='chestPainType')\n",
    "data=data.drop('chestPainType',axis=1)\n",
    "data=data.join(dummyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingBP']=pd.to_numeric(data['restingBP'])\n",
    "d=data[data.restingBP !=-9]\n",
    "d=d[d.restingBP != 0]\n",
    "mean=d['restingBP'].mean()\n",
    "data['restingBP']=data[['restingBP']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hyperTension']=pd.to_numeric(data['hyperTension'])\n",
    "data['hyperTension']=data[['hyperTension','restingBP']].apply(processHypertension,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=pd.to_numeric(data['cholestrol'])\n",
    "d=data[data.cholestrol !=-9]\n",
    "d=d[d.cholestrol != 0]\n",
    "mean=d['cholestrol'].mean()\n",
    "data['cholestrol']=data[['cholestrol']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=data[['cholestrol']].apply(processCholestrol,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['cholestrol'], prefix='cholestrol')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('cholestrol',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=pd.to_numeric(data['smoker'])\n",
    "data['smoker']=data[['smoker','smokingYears','noOfCigarette']].apply(processSmoking,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=data[['smoker']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['smoker'], prefix='smoker')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('smoker',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bloodSugar']=pd.to_numeric(data['bloodSugar'])\n",
    "data['bloodSugar']=data[['bloodSugar']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.bloodSugar==40].index[0],'bloodSugar']=int(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['bloodSugar'], prefix='bloodSugar')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('bloodSugar',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['historyOfHA']=pd.to_numeric(data['historyOfHA'])\n",
    "data['historyOfHA']=data[['historyOfHA']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['historyOfHA'], prefix='historyOfHA')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('historyOfHA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingECG']=pd.to_numeric(data['restingECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==0.4].index[0],'restingECG']=int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['restingECG'], prefix='restingECG')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('restingECG',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['restingECG']=data[['restingECG']].apply(processRestingECG,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestDuration']=pd.to_numeric(data['stressTestDuration'])\n",
    "data['stressTestDuration']=data[['stressTestDuration']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestSTTime']=pd.to_numeric(data['stressTestSTTime'])\n",
    "data['stressTestSTTime']=data[['stressTestSTTime']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxHR']=pd.to_numeric(data['stressTestMaxHR'])\n",
    "d=data[data.stressTestMaxHR !=-9]\n",
    "mean=d['stressTestMaxHR'].mean()\n",
    "data['stressTestMaxHR']=data[['stressTestMaxHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxHR==8105].index[0],'stressTestMaxHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingHR']=pd.to_numeric(data['stressTestRestingHR'])\n",
    "d=data[data.stressTestRestingHR !=-9]\n",
    "mean=d['stressTestRestingHR'].mean()\n",
    "data['stressTestRestingHR']=data[['stressTestRestingHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingHR==1.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==37.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==39.0].index[0],'stressTestRestingHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxFirstBPS']=pd.to_numeric(data['stressTestMaxFirstBPS'])\n",
    "d=data[data.stressTestMaxFirstBPS !=-9]\n",
    "mean=d['stressTestMaxFirstBPS'].mean()\n",
    "data['stressTestMaxFirstBPS']=data[['stressTestMaxFirstBPS']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxSecondBPS']=pd.to_numeric(data['stressTestMaxSecondBPS'])\n",
    "d=data[data.stressTestMaxSecondBPS !=-9]\n",
    "mean=d['stressTestMaxSecondBPS'].mean()\n",
    "data['stressTestMaxSecondBPS']=data[['stressTestMaxSecondBPS']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxSecondBPS==1.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==11.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==26.0].index[0],'stressTestMaxSecondBPS']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingBP']=pd.to_numeric(data['stressTestRestingBP'])\n",
    "d=data[data.stressTestRestingBP !=-9]\n",
    "mean=d['stressTestRestingBP'].mean()\n",
    "data['stressTestRestingBP']=data[['stressTestRestingBP']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingBP==1018].index[0],'stressTestRestingBP']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exerciseAngina']=pd.to_numeric(data['exerciseAngina'])\n",
    "data['exerciseAngina']=data[['exerciseAngina','painLocation']].apply(processExerciseAgnia,axis=1)\n",
    "data.at[data[data.exerciseAngina==101881].index[0],'exerciseAngina']=int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionExercise']=pd.to_numeric(data['STDepressionExercise'])\n",
    "d=data[data.STDepressionExercise !=-9]\n",
    "mean=d['STDepressionExercise'].mean()\n",
    "data['STDepressionExercise']=data[['STDepressionExercise']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionSlope']=pd.to_numeric(data['STDepressionSlope'])\n",
    "data['STDepressionSlope']=data[['STDepressionSlope']].apply(processSTDepressionSlope,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['STDepressionSlope'], prefix='STDepressionSlope')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('STDepressionSlope',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coloredVesselsFluroscopy']=pd.to_numeric(data['coloredVesselsFluroscopy'])\n",
    "data['coloredVesselsFluroscopy']=data[['coloredVesselsFluroscopy']].apply(processcoloredVesselsFluroscopy,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['coloredVesselsFluroscopy'], prefix='coloredVesselsFluroscopy')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('coloredVesselsFluroscopy',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heartWallDamage']=pd.to_numeric(data['heartWallDamage'])\n",
    "data['heartWallDamage']=data[['heartWallDamage']].apply(processHeartWallDamage,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['heartWallDamage'], prefix='heartWallDamage')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('heartWallDamage',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output']=pd.to_numeric(data['output'])\n",
    "data['output']=data[['output']].apply(processOutput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOutput=pd.DataFrame(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 1 columns):\n",
      "output    900 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataOutput.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['noOfCigarette' , 'smokingYears'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['output'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   51  1.0           0.0         94             1                 7.3   \n",
       "1   62  0.0           1.0        160             0                 5.2   \n",
       "2   60  1.0           1.0        152             1                 6.5   \n",
       "3   52  1.0           1.0        128             1                12.0   \n",
       "4   41  1.0           1.0        130             1                10.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0               0.0            154.0                 83.0   \n",
       "1               3.0            145.0                 64.0   \n",
       "2              -1.0            118.0                 58.0   \n",
       "3              -1.0            180.0                 75.0   \n",
       "4               9.0            130.0                 87.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  124.0                    70.0                 72.0   \n",
       "1                  160.0                    70.0                 90.0   \n",
       "2                  164.0                    96.0                 94.0   \n",
       "3                  210.0                   104.0                 70.0   \n",
       "4                  160.0                   100.0                 90.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             1.0                   0.0                0                0   \n",
       "1             0.0                   6.2                0                0   \n",
       "2             1.0                   0.0                0                0   \n",
       "3             0.0                   3.0                0                0   \n",
       "4             0.0                   2.0                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             0             1             0   \n",
       "1                0                1             1             0             0   \n",
       "2                0                1             0             0             1   \n",
       "3                1                0             0             0             1   \n",
       "4                0                1             1             0             0   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          0         0         1                0               1   \n",
       "1          0         1         0                0               1   \n",
       "2          0         1         0                0               1   \n",
       "3          0         0         1                0               1   \n",
       "4          1         0         0                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 0                1                0   \n",
       "1               0                 0                0                1   \n",
       "2               0                 0                1                0   \n",
       "3               0                 0                1                0   \n",
       "4               0                 1                0                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               0               0               1                     0   \n",
       "2               0               1               0                     1   \n",
       "3               0               1               0                     0   \n",
       "4               0               1               0                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    0                    1                    0   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            1                           0   \n",
       "3                            1                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   0                  0   \n",
       "1                           1                   0                  0   \n",
       "2                           0                   0                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  1                  0  \n",
       "1                  1                  0  \n",
       "2                  1                  0  \n",
       "3                  0                  1  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop(['smoker_-1','bloodSugar_-1.0','historyOfHA_-1.0','STDepressionSlope_-1',\n",
    "#               'coloredVesselsFluroscopy_-1','heartWallDamage_-1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   51  1.0           0.0         94             1                 7.3   \n",
       "1   62  0.0           1.0        160             0                 5.2   \n",
       "2   60  1.0           1.0        152             1                 6.5   \n",
       "3   52  1.0           1.0        128             1                12.0   \n",
       "4   41  1.0           1.0        130             1                10.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0               0.0            154.0                 83.0   \n",
       "1               3.0            145.0                 64.0   \n",
       "2              -1.0            118.0                 58.0   \n",
       "3              -1.0            180.0                 75.0   \n",
       "4               9.0            130.0                 87.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  124.0                    70.0                 72.0   \n",
       "1                  160.0                    70.0                 90.0   \n",
       "2                  164.0                    96.0                 94.0   \n",
       "3                  210.0                   104.0                 70.0   \n",
       "4                  160.0                   100.0                 90.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             1.0                   0.0                0                0   \n",
       "1             0.0                   6.2                0                0   \n",
       "2             1.0                   0.0                0                0   \n",
       "3             0.0                   3.0                0                0   \n",
       "4             0.0                   2.0                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             0             1             0   \n",
       "1                0                1             1             0             0   \n",
       "2                0                1             0             0             1   \n",
       "3                1                0             0             0             1   \n",
       "4                0                1             1             0             0   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          0         0         1                0               1   \n",
       "1          0         1         0                0               1   \n",
       "2          0         1         0                0               1   \n",
       "3          0         0         1                0               1   \n",
       "4          1         0         0                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 0                1                0   \n",
       "1               0                 0                0                1   \n",
       "2               0                 0                1                0   \n",
       "3               0                 0                1                0   \n",
       "4               0                 1                0                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               0               0               1                     0   \n",
       "2               0               1               0                     1   \n",
       "3               0               1               0                     0   \n",
       "4               0               1               0                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    0                    1                    0   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            1                           0   \n",
       "3                            1                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   0                  0   \n",
       "1                           1                   0                  0   \n",
       "2                           0                   0                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  1                  0  \n",
       "1                  1                  0  \n",
       "2                  1                  0  \n",
       "3                  0                  1  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 46 columns):\n",
      "age                            900 non-null int64\n",
      "sex                            900 non-null float64\n",
      "painLocation                   900 non-null float64\n",
      "restingBP                      900 non-null int64\n",
      "hyperTension                   900 non-null int64\n",
      "stressTestDuration             900 non-null float64\n",
      "stressTestSTTime               900 non-null float64\n",
      "stressTestMaxHR                900 non-null float64\n",
      "stressTestRestingHR            900 non-null float64\n",
      "stressTestMaxFirstBPS          900 non-null float64\n",
      "stressTestMaxSecondBPS         900 non-null float64\n",
      "stressTestRestingBP            900 non-null float64\n",
      "exerciseAngina                 900 non-null float64\n",
      "STDepressionExercise           900 non-null float64\n",
      "chestPainType_1                900 non-null uint8\n",
      "chestPainType_2                900 non-null uint8\n",
      "chestPainType_3                900 non-null uint8\n",
      "chestPainType_4                900 non-null uint8\n",
      "cholestrol_0                   900 non-null uint8\n",
      "cholestrol_1                   900 non-null uint8\n",
      "cholestrol_2                   900 non-null uint8\n",
      "smoker_-1                      900 non-null uint8\n",
      "smoker_0                       900 non-null uint8\n",
      "smoker_1                       900 non-null uint8\n",
      "bloodSugar_-1.0                900 non-null uint8\n",
      "bloodSugar_0.0                 900 non-null uint8\n",
      "bloodSugar_1.0                 900 non-null uint8\n",
      "historyOfHA_-1.0               900 non-null uint8\n",
      "historyOfHA_0.0                900 non-null uint8\n",
      "historyOfHA_1.0                900 non-null uint8\n",
      "restingECG_0.0                 900 non-null uint8\n",
      "restingECG_1.0                 900 non-null uint8\n",
      "restingECG_2.0                 900 non-null uint8\n",
      "STDepressionSlope_-1           900 non-null uint8\n",
      "STDepressionSlope_0            900 non-null uint8\n",
      "STDepressionSlope_1            900 non-null uint8\n",
      "STDepressionSlope_2            900 non-null uint8\n",
      "coloredVesselsFluroscopy_-1    900 non-null uint8\n",
      "coloredVesselsFluroscopy_0     900 non-null uint8\n",
      "coloredVesselsFluroscopy_1     900 non-null uint8\n",
      "coloredVesselsFluroscopy_2     900 non-null uint8\n",
      "coloredVesselsFluroscopy_3     900 non-null uint8\n",
      "heartWallDamage_-1             900 non-null uint8\n",
      "heartWallDamage_0              900 non-null uint8\n",
      "heartWallDamage_1              900 non-null uint8\n",
      "heartWallDamage_2              900 non-null uint8\n",
      "dtypes: float64(11), int64(3), uint8(32)\n",
      "memory usage: 126.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_X, testingData_X, trainingData_Y, testingData_Y = train_test_split(data,\n",
    "                                                                                dataOutput,\n",
    "                                                                                test_size = 0.2,\n",
    "                                                                                random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=trainingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=trainingData_Y.values\n",
    "y_test=testingData_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "y_train=y_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "y_test=y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLayer=x_train.shape[1]\n",
    "secondLayer=int(x_train.shape[1]/2)\n",
    "thirdLayer=int(secondLayer/2)\n",
    "fourthLayer=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46   23   11   1\n"
     ]
    }
   ],
   "source": [
    "print(firstLayer,\" \",secondLayer,\" \",thirdLayer,\" \",fourthLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(firstLayer, input_dim=x_train.shape[1], activation='relu',\n",
    "                kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(secondLayer,activation='relu',\n",
    "                kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0),\n",
    "               kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(thirdLayer,activation='relu',\n",
    "                kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(fourthLayer, activation='sigmoid',kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 23)                1081      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 11)                264       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 3,519\n",
      "Trainable params: 3,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/1000\n",
      "648/648 [==============================] - 0s 423us/step - loss: 1.9878 - acc: 0.3302 - val_loss: 1.9289 - val_acc: 0.3056\n",
      "Epoch 2/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 1.9161 - acc: 0.3657 - val_loss: 1.8684 - val_acc: 0.3333\n",
      "Epoch 3/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 1.8600 - acc: 0.3904 - val_loss: 1.8160 - val_acc: 0.3750\n",
      "Epoch 4/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 1.8121 - acc: 0.4043 - val_loss: 1.7678 - val_acc: 0.3472\n",
      "Epoch 5/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 1.7623 - acc: 0.4414 - val_loss: 1.7242 - val_acc: 0.4444\n",
      "Epoch 6/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 1.7175 - acc: 0.4398 - val_loss: 1.6836 - val_acc: 0.5139\n",
      "Epoch 7/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 1.6813 - acc: 0.4660 - val_loss: 1.6450 - val_acc: 0.5278\n",
      "Epoch 8/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 1.6438 - acc: 0.4691 - val_loss: 1.6083 - val_acc: 0.5833\n",
      "Epoch 9/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 1.5979 - acc: 0.5293 - val_loss: 1.5727 - val_acc: 0.5972\n",
      "Epoch 10/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 1.5640 - acc: 0.5278 - val_loss: 1.5370 - val_acc: 0.6111\n",
      "Epoch 11/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 1.5319 - acc: 0.5309 - val_loss: 1.5024 - val_acc: 0.6528\n",
      "Epoch 12/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 1.4932 - acc: 0.5802 - val_loss: 1.4690 - val_acc: 0.6389\n",
      "Epoch 13/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 1.4555 - acc: 0.6173 - val_loss: 1.4358 - val_acc: 0.6528\n",
      "Epoch 14/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 1.4272 - acc: 0.6265 - val_loss: 1.4033 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.3979 - acc: 0.5756 - val_loss: 1.3715 - val_acc: 0.6806\n",
      "Epoch 16/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 1.3665 - acc: 0.6019 - val_loss: 1.3401 - val_acc: 0.6806\n",
      "Epoch 17/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 1.3276 - acc: 0.6466 - val_loss: 1.3086 - val_acc: 0.6806\n",
      "Epoch 18/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 1.3041 - acc: 0.6034 - val_loss: 1.2782 - val_acc: 0.6806\n",
      "Epoch 19/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.2740 - acc: 0.6142 - val_loss: 1.2482 - val_acc: 0.6806\n",
      "Epoch 20/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 1.2428 - acc: 0.6404 - val_loss: 1.2190 - val_acc: 0.6806\n",
      "Epoch 21/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 1.2147 - acc: 0.6312 - val_loss: 1.1901 - val_acc: 0.6806\n",
      "Epoch 22/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 1.1862 - acc: 0.6497 - val_loss: 1.1621 - val_acc: 0.6806\n",
      "Epoch 23/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.1602 - acc: 0.6296 - val_loss: 1.1344 - val_acc: 0.6806\n",
      "Epoch 24/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 1.1308 - acc: 0.6373 - val_loss: 1.1072 - val_acc: 0.6806\n",
      "Epoch 25/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 1.1024 - acc: 0.6605 - val_loss: 1.0805 - val_acc: 0.6806\n",
      "Epoch 26/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 1.0721 - acc: 0.6713 - val_loss: 1.0547 - val_acc: 0.6806\n",
      "Epoch 27/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 1.0488 - acc: 0.6543 - val_loss: 1.0296 - val_acc: 0.6806\n",
      "Epoch 28/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 1.0267 - acc: 0.6590 - val_loss: 1.0052 - val_acc: 0.6806\n",
      "Epoch 29/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.0000 - acc: 0.6435 - val_loss: 0.9810 - val_acc: 0.6806\n",
      "Epoch 30/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.9780 - acc: 0.6620 - val_loss: 0.9575 - val_acc: 0.6806\n",
      "Epoch 31/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.9554 - acc: 0.6466 - val_loss: 0.9344 - val_acc: 0.6806\n",
      "Epoch 32/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.9302 - acc: 0.6667 - val_loss: 0.9117 - val_acc: 0.6806\n",
      "Epoch 33/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.9113 - acc: 0.6543 - val_loss: 0.8896 - val_acc: 0.6806\n",
      "Epoch 34/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.8903 - acc: 0.6451 - val_loss: 0.8681 - val_acc: 0.6806\n",
      "Epoch 35/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.8638 - acc: 0.6574 - val_loss: 0.8468 - val_acc: 0.6806\n",
      "Epoch 36/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.8436 - acc: 0.6497 - val_loss: 0.8260 - val_acc: 0.6806\n",
      "Epoch 37/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.8244 - acc: 0.6651 - val_loss: 0.8057 - val_acc: 0.6806\n",
      "Epoch 38/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.8068 - acc: 0.6620 - val_loss: 0.7859 - val_acc: 0.6806\n",
      "Epoch 39/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.7847 - acc: 0.6590 - val_loss: 0.7664 - val_acc: 0.6806\n",
      "Epoch 40/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.7648 - acc: 0.6651 - val_loss: 0.7472 - val_acc: 0.6806\n",
      "Epoch 41/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.7517 - acc: 0.6620 - val_loss: 0.7285 - val_acc: 0.6806\n",
      "Epoch 42/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.7318 - acc: 0.6528 - val_loss: 0.7101 - val_acc: 0.6806\n",
      "Epoch 43/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.7052 - acc: 0.6620 - val_loss: 0.6919 - val_acc: 0.6806\n",
      "Epoch 44/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.6944 - acc: 0.6528 - val_loss: 0.6745 - val_acc: 0.6806\n",
      "Epoch 45/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.6753 - acc: 0.6574 - val_loss: 0.6575 - val_acc: 0.6806\n",
      "Epoch 46/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.6583 - acc: 0.6620 - val_loss: 0.6412 - val_acc: 0.6806\n",
      "Epoch 47/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.6378 - acc: 0.6698 - val_loss: 0.6252 - val_acc: 0.6806\n",
      "Epoch 48/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.6230 - acc: 0.6682 - val_loss: 0.6098 - val_acc: 0.6806\n",
      "Epoch 49/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.6077 - acc: 0.6698 - val_loss: 0.5949 - val_acc: 0.6806\n",
      "Epoch 50/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.5960 - acc: 0.6636 - val_loss: 0.5807 - val_acc: 0.6806\n",
      "Epoch 51/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.5811 - acc: 0.6620 - val_loss: 0.5668 - val_acc: 0.6806\n",
      "Epoch 52/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.5645 - acc: 0.6651 - val_loss: 0.5532 - val_acc: 0.6806\n",
      "Epoch 53/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.5561 - acc: 0.6636 - val_loss: 0.5400 - val_acc: 0.6806\n",
      "Epoch 54/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.5410 - acc: 0.6620 - val_loss: 0.5273 - val_acc: 0.6806\n",
      "Epoch 55/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.5282 - acc: 0.6713 - val_loss: 0.5148 - val_acc: 0.6806\n",
      "Epoch 56/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.5181 - acc: 0.6636 - val_loss: 0.5028 - val_acc: 0.6806\n",
      "Epoch 57/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.5038 - acc: 0.6667 - val_loss: 0.4910 - val_acc: 0.6806\n",
      "Epoch 58/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.4890 - acc: 0.6682 - val_loss: 0.4797 - val_acc: 0.6806\n",
      "Epoch 59/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.4819 - acc: 0.6651 - val_loss: 0.4688 - val_acc: 0.6806\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 109us/step - loss: 0.4731 - acc: 0.6667 - val_loss: 0.4584 - val_acc: 0.6806\n",
      "Epoch 61/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.4621 - acc: 0.6636 - val_loss: 0.4483 - val_acc: 0.6806\n",
      "Epoch 62/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.4483 - acc: 0.6682 - val_loss: 0.4383 - val_acc: 0.6806\n",
      "Epoch 63/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.4428 - acc: 0.6651 - val_loss: 0.4286 - val_acc: 0.6806\n",
      "Epoch 64/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.4341 - acc: 0.6620 - val_loss: 0.4193 - val_acc: 0.6806\n",
      "Epoch 65/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.4202 - acc: 0.6605 - val_loss: 0.4102 - val_acc: 0.6806\n",
      "Epoch 66/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.4134 - acc: 0.6667 - val_loss: 0.4012 - val_acc: 0.6806\n",
      "Epoch 67/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.4061 - acc: 0.6590 - val_loss: 0.3927 - val_acc: 0.6806\n",
      "Epoch 68/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.3945 - acc: 0.6651 - val_loss: 0.3842 - val_acc: 0.6806\n",
      "Epoch 69/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.3842 - acc: 0.6682 - val_loss: 0.3759 - val_acc: 0.6806\n",
      "Epoch 70/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.3799 - acc: 0.6667 - val_loss: 0.3681 - val_acc: 0.6806\n",
      "Epoch 71/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.3744 - acc: 0.6667 - val_loss: 0.3605 - val_acc: 0.6806\n",
      "Epoch 72/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.3645 - acc: 0.6636 - val_loss: 0.3533 - val_acc: 0.6806\n",
      "Epoch 73/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.3590 - acc: 0.6667 - val_loss: 0.3463 - val_acc: 0.6806\n",
      "Epoch 74/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.3501 - acc: 0.6620 - val_loss: 0.3395 - val_acc: 0.6806\n",
      "Epoch 75/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.3424 - acc: 0.6636 - val_loss: 0.3329 - val_acc: 0.6806\n",
      "Epoch 76/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.3363 - acc: 0.6667 - val_loss: 0.3265 - val_acc: 0.6806\n",
      "Epoch 77/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.3297 - acc: 0.6667 - val_loss: 0.3203 - val_acc: 0.6806\n",
      "Epoch 78/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.3237 - acc: 0.6667 - val_loss: 0.3143 - val_acc: 0.6806\n",
      "Epoch 79/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.3171 - acc: 0.6682 - val_loss: 0.3086 - val_acc: 0.6806\n",
      "Epoch 80/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.3109 - acc: 0.6651 - val_loss: 0.3032 - val_acc: 0.6806\n",
      "Epoch 81/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.3076 - acc: 0.6651 - val_loss: 0.2981 - val_acc: 0.6806\n",
      "Epoch 82/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.3024 - acc: 0.6651 - val_loss: 0.2932 - val_acc: 0.6806\n",
      "Epoch 83/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.2960 - acc: 0.6651 - val_loss: 0.2885 - val_acc: 0.6806\n",
      "Epoch 84/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.2953 - acc: 0.6651 - val_loss: 0.2841 - val_acc: 0.6806\n",
      "Epoch 85/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2861 - acc: 0.6698 - val_loss: 0.2795 - val_acc: 0.6806\n",
      "Epoch 86/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2854 - acc: 0.6636 - val_loss: 0.2751 - val_acc: 0.6806\n",
      "Epoch 87/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.2770 - acc: 0.6682 - val_loss: 0.2710 - val_acc: 0.6806\n",
      "Epoch 88/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.2745 - acc: 0.6744 - val_loss: 0.2669 - val_acc: 0.6806\n",
      "Epoch 89/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.2703 - acc: 0.6759 - val_loss: 0.2632 - val_acc: 0.6806\n",
      "Epoch 90/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.2685 - acc: 0.6651 - val_loss: 0.2593 - val_acc: 0.6806\n",
      "Epoch 91/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.2643 - acc: 0.6713 - val_loss: 0.2556 - val_acc: 0.6806\n",
      "Epoch 92/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.2605 - acc: 0.6836 - val_loss: 0.2517 - val_acc: 0.6806\n",
      "Epoch 93/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.2602 - acc: 0.6651 - val_loss: 0.2487 - val_acc: 0.6806\n",
      "Epoch 94/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.2507 - acc: 0.6898 - val_loss: 0.2455 - val_acc: 0.6806\n",
      "Epoch 95/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2510 - acc: 0.6728 - val_loss: 0.2424 - val_acc: 0.6806\n",
      "Epoch 96/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2463 - acc: 0.6883 - val_loss: 0.2393 - val_acc: 0.6806\n",
      "Epoch 97/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.2476 - acc: 0.6836 - val_loss: 0.2369 - val_acc: 0.6806\n",
      "Epoch 98/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.2415 - acc: 0.6775 - val_loss: 0.2342 - val_acc: 0.6806\n",
      "Epoch 99/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.2429 - acc: 0.6929 - val_loss: 0.2317 - val_acc: 0.6806\n",
      "Epoch 100/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.2397 - acc: 0.6991 - val_loss: 0.2295 - val_acc: 0.6806\n",
      "Epoch 101/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2334 - acc: 0.7114 - val_loss: 0.2272 - val_acc: 0.7222\n",
      "Epoch 102/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2370 - acc: 0.6821 - val_loss: 0.2253 - val_acc: 0.7361\n",
      "Epoch 103/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2339 - acc: 0.6929 - val_loss: 0.2236 - val_acc: 0.7222\n",
      "Epoch 104/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.2354 - acc: 0.6975 - val_loss: 0.2219 - val_acc: 0.7222\n",
      "Epoch 105/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.2322 - acc: 0.6944 - val_loss: 0.2201 - val_acc: 0.7361\n",
      "Epoch 106/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.2281 - acc: 0.7052 - val_loss: 0.2182 - val_acc: 0.7500\n",
      "Epoch 107/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.2271 - acc: 0.6975 - val_loss: 0.2166 - val_acc: 0.7500\n",
      "Epoch 108/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.2296 - acc: 0.6883 - val_loss: 0.2150 - val_acc: 0.7500\n",
      "Epoch 109/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.2282 - acc: 0.6944 - val_loss: 0.2136 - val_acc: 0.7500\n",
      "Epoch 110/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.2244 - acc: 0.7022 - val_loss: 0.2122 - val_acc: 0.7500\n",
      "Epoch 111/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2239 - acc: 0.6991 - val_loss: 0.2108 - val_acc: 0.7361\n",
      "Epoch 112/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.2227 - acc: 0.7052 - val_loss: 0.2094 - val_acc: 0.7361\n",
      "Epoch 113/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.2211 - acc: 0.7022 - val_loss: 0.2083 - val_acc: 0.7639\n",
      "Epoch 114/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.2185 - acc: 0.7191 - val_loss: 0.2073 - val_acc: 0.7500\n",
      "Epoch 115/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.2174 - acc: 0.7037 - val_loss: 0.2062 - val_acc: 0.7500\n",
      "Epoch 116/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.2197 - acc: 0.6991 - val_loss: 0.2051 - val_acc: 0.7639\n",
      "Epoch 117/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.2192 - acc: 0.7130 - val_loss: 0.2042 - val_acc: 0.7639\n",
      "Epoch 118/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.2195 - acc: 0.7037 - val_loss: 0.2035 - val_acc: 0.7639\n",
      "Epoch 119/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.2099 - acc: 0.7269 - val_loss: 0.2021 - val_acc: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.2154 - acc: 0.7006 - val_loss: 0.2014 - val_acc: 0.7639\n",
      "Epoch 121/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.2107 - acc: 0.7176 - val_loss: 0.2006 - val_acc: 0.7639\n",
      "Epoch 122/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.2153 - acc: 0.6775 - val_loss: 0.1999 - val_acc: 0.7639\n",
      "Epoch 123/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.2144 - acc: 0.6960 - val_loss: 0.1995 - val_acc: 0.7639\n",
      "Epoch 124/1000\n",
      "648/648 [==============================] - 0s 139us/step - loss: 0.2111 - acc: 0.7099 - val_loss: 0.1983 - val_acc: 0.7778\n",
      "Epoch 125/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.2051 - acc: 0.7284 - val_loss: 0.1975 - val_acc: 0.7778\n",
      "Epoch 126/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2128 - acc: 0.7130 - val_loss: 0.1967 - val_acc: 0.7639\n",
      "Epoch 127/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.2123 - acc: 0.7068 - val_loss: 0.1962 - val_acc: 0.7639\n",
      "Epoch 128/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.2125 - acc: 0.6806 - val_loss: 0.1957 - val_acc: 0.7639\n",
      "Epoch 129/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.2102 - acc: 0.7037 - val_loss: 0.1952 - val_acc: 0.7639\n",
      "Epoch 130/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2018 - acc: 0.7207 - val_loss: 0.1946 - val_acc: 0.7639\n",
      "Epoch 131/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.2094 - acc: 0.7176 - val_loss: 0.1940 - val_acc: 0.7778\n",
      "Epoch 132/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1976 - acc: 0.7207 - val_loss: 0.1932 - val_acc: 0.7639\n",
      "Epoch 133/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.2040 - acc: 0.7284 - val_loss: 0.1925 - val_acc: 0.7639\n",
      "Epoch 134/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.2050 - acc: 0.7083 - val_loss: 0.1920 - val_acc: 0.7639\n",
      "Epoch 135/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.2053 - acc: 0.7114 - val_loss: 0.1918 - val_acc: 0.7778\n",
      "Epoch 136/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.2014 - acc: 0.7407 - val_loss: 0.1913 - val_acc: 0.7778\n",
      "Epoch 137/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1991 - acc: 0.7099 - val_loss: 0.1907 - val_acc: 0.7778\n",
      "Epoch 138/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.2062 - acc: 0.7222 - val_loss: 0.1902 - val_acc: 0.7778\n",
      "Epoch 139/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.2001 - acc: 0.7330 - val_loss: 0.1896 - val_acc: 0.7778\n",
      "Epoch 140/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.2034 - acc: 0.6991 - val_loss: 0.1890 - val_acc: 0.7778\n",
      "Epoch 141/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.2034 - acc: 0.6944 - val_loss: 0.1886 - val_acc: 0.7778\n",
      "Epoch 142/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.2035 - acc: 0.7130 - val_loss: 0.1884 - val_acc: 0.7917\n",
      "Epoch 143/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.2016 - acc: 0.7083 - val_loss: 0.1880 - val_acc: 0.7778\n",
      "Epoch 144/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.2013 - acc: 0.7330 - val_loss: 0.1876 - val_acc: 0.7778\n",
      "Epoch 145/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.2052 - acc: 0.7176 - val_loss: 0.1873 - val_acc: 0.7778\n",
      "Epoch 146/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.2013 - acc: 0.7006 - val_loss: 0.1868 - val_acc: 0.7917\n",
      "Epoch 147/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1999 - acc: 0.7130 - val_loss: 0.1863 - val_acc: 0.7778\n",
      "Epoch 148/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.2021 - acc: 0.7191 - val_loss: 0.1860 - val_acc: 0.7778\n",
      "Epoch 149/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1945 - acc: 0.7346 - val_loss: 0.1857 - val_acc: 0.7778\n",
      "Epoch 150/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1935 - acc: 0.7423 - val_loss: 0.1851 - val_acc: 0.7778\n",
      "Epoch 151/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1967 - acc: 0.7207 - val_loss: 0.1847 - val_acc: 0.7778\n",
      "Epoch 152/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1961 - acc: 0.7176 - val_loss: 0.1844 - val_acc: 0.7778\n",
      "Epoch 153/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1985 - acc: 0.7130 - val_loss: 0.1840 - val_acc: 0.7778\n",
      "Epoch 154/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1954 - acc: 0.7176 - val_loss: 0.1838 - val_acc: 0.7778\n",
      "Epoch 155/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1900 - acc: 0.7238 - val_loss: 0.1836 - val_acc: 0.7639\n",
      "Epoch 156/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.2023 - acc: 0.7207 - val_loss: 0.1834 - val_acc: 0.7639\n",
      "Epoch 157/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1952 - acc: 0.7176 - val_loss: 0.1832 - val_acc: 0.7778\n",
      "Epoch 158/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1912 - acc: 0.7546 - val_loss: 0.1828 - val_acc: 0.7778\n",
      "Epoch 159/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1929 - acc: 0.7299 - val_loss: 0.1826 - val_acc: 0.7639\n",
      "Epoch 160/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1972 - acc: 0.7284 - val_loss: 0.1824 - val_acc: 0.7500\n",
      "Epoch 161/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1970 - acc: 0.7253 - val_loss: 0.1825 - val_acc: 0.7639\n",
      "Epoch 162/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1921 - acc: 0.7222 - val_loss: 0.1822 - val_acc: 0.7639\n",
      "Epoch 163/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1904 - acc: 0.7392 - val_loss: 0.1819 - val_acc: 0.7500\n",
      "Epoch 164/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1949 - acc: 0.7099 - val_loss: 0.1815 - val_acc: 0.7500\n",
      "Epoch 165/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1929 - acc: 0.7222 - val_loss: 0.1812 - val_acc: 0.7639\n",
      "Epoch 166/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1885 - acc: 0.7515 - val_loss: 0.1811 - val_acc: 0.7500\n",
      "Epoch 167/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1951 - acc: 0.7114 - val_loss: 0.1814 - val_acc: 0.7639\n",
      "Epoch 168/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1940 - acc: 0.7222 - val_loss: 0.1809 - val_acc: 0.7500\n",
      "Epoch 169/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1965 - acc: 0.7114 - val_loss: 0.1807 - val_acc: 0.7500\n",
      "Epoch 170/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1926 - acc: 0.7269 - val_loss: 0.1808 - val_acc: 0.7500\n",
      "Epoch 171/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1953 - acc: 0.7052 - val_loss: 0.1804 - val_acc: 0.7639\n",
      "Epoch 172/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1925 - acc: 0.7160 - val_loss: 0.1805 - val_acc: 0.7639\n",
      "Epoch 173/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1918 - acc: 0.7083 - val_loss: 0.1801 - val_acc: 0.7639\n",
      "Epoch 174/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1900 - acc: 0.7176 - val_loss: 0.1795 - val_acc: 0.7778\n",
      "Epoch 175/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1942 - acc: 0.7099 - val_loss: 0.1795 - val_acc: 0.7778\n",
      "Epoch 176/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1916 - acc: 0.7284 - val_loss: 0.1792 - val_acc: 0.7639\n",
      "Epoch 177/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1928 - acc: 0.7052 - val_loss: 0.1792 - val_acc: 0.7639\n",
      "Epoch 178/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1921 - acc: 0.7083 - val_loss: 0.1792 - val_acc: 0.7778\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 102us/step - loss: 0.1871 - acc: 0.7407 - val_loss: 0.1788 - val_acc: 0.7917\n",
      "Epoch 180/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1909 - acc: 0.7145 - val_loss: 0.1786 - val_acc: 0.7778\n",
      "Epoch 181/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1855 - acc: 0.7191 - val_loss: 0.1785 - val_acc: 0.7778\n",
      "Epoch 182/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1886 - acc: 0.7284 - val_loss: 0.1787 - val_acc: 0.7639\n",
      "Epoch 183/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1938 - acc: 0.7222 - val_loss: 0.1784 - val_acc: 0.7778\n",
      "Epoch 184/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1950 - acc: 0.7083 - val_loss: 0.1782 - val_acc: 0.7639\n",
      "Epoch 185/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1846 - acc: 0.7701 - val_loss: 0.1778 - val_acc: 0.7639\n",
      "Epoch 186/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1875 - acc: 0.7315 - val_loss: 0.1776 - val_acc: 0.7500\n",
      "Epoch 187/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1888 - acc: 0.7253 - val_loss: 0.1776 - val_acc: 0.7500\n",
      "Epoch 188/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1863 - acc: 0.7330 - val_loss: 0.1774 - val_acc: 0.7639\n",
      "Epoch 189/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1923 - acc: 0.7207 - val_loss: 0.1773 - val_acc: 0.7639\n",
      "Epoch 190/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1896 - acc: 0.7269 - val_loss: 0.1772 - val_acc: 0.7639\n",
      "Epoch 191/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1877 - acc: 0.7346 - val_loss: 0.1769 - val_acc: 0.7639\n",
      "Epoch 192/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1875 - acc: 0.7207 - val_loss: 0.1770 - val_acc: 0.7639\n",
      "Epoch 193/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1858 - acc: 0.7222 - val_loss: 0.1772 - val_acc: 0.7500\n",
      "Epoch 194/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1882 - acc: 0.7222 - val_loss: 0.1768 - val_acc: 0.7500\n",
      "Epoch 195/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1905 - acc: 0.7037 - val_loss: 0.1767 - val_acc: 0.7639\n",
      "Epoch 196/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1880 - acc: 0.7423 - val_loss: 0.1765 - val_acc: 0.7639\n",
      "Epoch 197/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1879 - acc: 0.7160 - val_loss: 0.1762 - val_acc: 0.7778\n",
      "Epoch 198/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1900 - acc: 0.7160 - val_loss: 0.1764 - val_acc: 0.7778\n",
      "Epoch 199/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1908 - acc: 0.7145 - val_loss: 0.1760 - val_acc: 0.7778\n",
      "Epoch 200/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1878 - acc: 0.7330 - val_loss: 0.1761 - val_acc: 0.7639\n",
      "Epoch 201/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1847 - acc: 0.7284 - val_loss: 0.1758 - val_acc: 0.7778\n",
      "Epoch 202/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1894 - acc: 0.7114 - val_loss: 0.1759 - val_acc: 0.7639\n",
      "Epoch 203/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1841 - acc: 0.7346 - val_loss: 0.1755 - val_acc: 0.7639\n",
      "Epoch 204/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1860 - acc: 0.7377 - val_loss: 0.1754 - val_acc: 0.7639\n",
      "Epoch 205/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1860 - acc: 0.7299 - val_loss: 0.1753 - val_acc: 0.7639\n",
      "Epoch 206/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1859 - acc: 0.7207 - val_loss: 0.1755 - val_acc: 0.7500\n",
      "Epoch 207/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1831 - acc: 0.7515 - val_loss: 0.1748 - val_acc: 0.7500\n",
      "Epoch 208/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1858 - acc: 0.7238 - val_loss: 0.1750 - val_acc: 0.7500\n",
      "Epoch 209/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1824 - acc: 0.7299 - val_loss: 0.1746 - val_acc: 0.7500\n",
      "Epoch 210/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1860 - acc: 0.7299 - val_loss: 0.1745 - val_acc: 0.7500\n",
      "Epoch 211/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1853 - acc: 0.7423 - val_loss: 0.1744 - val_acc: 0.7500\n",
      "Epoch 212/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1823 - acc: 0.7207 - val_loss: 0.1745 - val_acc: 0.7500\n",
      "Epoch 213/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1908 - acc: 0.7083 - val_loss: 0.1744 - val_acc: 0.7500\n",
      "Epoch 214/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1783 - acc: 0.7485 - val_loss: 0.1742 - val_acc: 0.7500\n",
      "Epoch 215/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1859 - acc: 0.7238 - val_loss: 0.1738 - val_acc: 0.7500\n",
      "Epoch 216/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1877 - acc: 0.7130 - val_loss: 0.1740 - val_acc: 0.7500\n",
      "Epoch 217/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1839 - acc: 0.7407 - val_loss: 0.1738 - val_acc: 0.7500\n",
      "Epoch 218/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1814 - acc: 0.7562 - val_loss: 0.1736 - val_acc: 0.7500\n",
      "Epoch 219/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1843 - acc: 0.7423 - val_loss: 0.1733 - val_acc: 0.7500\n",
      "Epoch 220/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1836 - acc: 0.7469 - val_loss: 0.1730 - val_acc: 0.7500\n",
      "Epoch 221/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1817 - acc: 0.7346 - val_loss: 0.1729 - val_acc: 0.7500\n",
      "Epoch 222/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1803 - acc: 0.7361 - val_loss: 0.1727 - val_acc: 0.7639\n",
      "Epoch 223/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1826 - acc: 0.7191 - val_loss: 0.1727 - val_acc: 0.7500\n",
      "Epoch 224/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1855 - acc: 0.7207 - val_loss: 0.1724 - val_acc: 0.7500\n",
      "Epoch 225/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1805 - acc: 0.7253 - val_loss: 0.1723 - val_acc: 0.7500\n",
      "Epoch 226/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1854 - acc: 0.7176 - val_loss: 0.1723 - val_acc: 0.7500\n",
      "Epoch 227/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1838 - acc: 0.7222 - val_loss: 0.1726 - val_acc: 0.7639\n",
      "Epoch 228/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1812 - acc: 0.7346 - val_loss: 0.1723 - val_acc: 0.7500\n",
      "Epoch 229/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1835 - acc: 0.7377 - val_loss: 0.1721 - val_acc: 0.7639\n",
      "Epoch 230/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1814 - acc: 0.7299 - val_loss: 0.1721 - val_acc: 0.7500\n",
      "Epoch 231/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1835 - acc: 0.7392 - val_loss: 0.1719 - val_acc: 0.7639\n",
      "Epoch 232/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1794 - acc: 0.7253 - val_loss: 0.1720 - val_acc: 0.7500\n",
      "Epoch 233/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1853 - acc: 0.7238 - val_loss: 0.1721 - val_acc: 0.7639\n",
      "Epoch 234/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1826 - acc: 0.7500 - val_loss: 0.1721 - val_acc: 0.7778\n",
      "Epoch 235/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1726 - acc: 0.7623 - val_loss: 0.1716 - val_acc: 0.7639\n",
      "Epoch 236/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1823 - acc: 0.7469 - val_loss: 0.1715 - val_acc: 0.7639\n",
      "Epoch 237/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1846 - acc: 0.7253 - val_loss: 0.1715 - val_acc: 0.7639\n",
      "Epoch 238/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1836 - acc: 0.7346 - val_loss: 0.1713 - val_acc: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1788 - acc: 0.7407 - val_loss: 0.1707 - val_acc: 0.7639\n",
      "Epoch 240/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1834 - acc: 0.7269 - val_loss: 0.1707 - val_acc: 0.7639\n",
      "Epoch 241/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1839 - acc: 0.7315 - val_loss: 0.1708 - val_acc: 0.7639\n",
      "Epoch 242/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1790 - acc: 0.7361 - val_loss: 0.1709 - val_acc: 0.7639\n",
      "Epoch 243/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1808 - acc: 0.7315 - val_loss: 0.1707 - val_acc: 0.7639\n",
      "Epoch 244/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1806 - acc: 0.7377 - val_loss: 0.1702 - val_acc: 0.7639\n",
      "Epoch 245/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1779 - acc: 0.7392 - val_loss: 0.1701 - val_acc: 0.7639\n",
      "Epoch 246/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1840 - acc: 0.7330 - val_loss: 0.1702 - val_acc: 0.7639\n",
      "Epoch 247/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1796 - acc: 0.7577 - val_loss: 0.1696 - val_acc: 0.7778\n",
      "Epoch 248/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1798 - acc: 0.7469 - val_loss: 0.1695 - val_acc: 0.7639\n",
      "Epoch 249/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1840 - acc: 0.7253 - val_loss: 0.1697 - val_acc: 0.7639\n",
      "Epoch 250/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1728 - acc: 0.7454 - val_loss: 0.1694 - val_acc: 0.7639\n",
      "Epoch 251/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1824 - acc: 0.7238 - val_loss: 0.1695 - val_acc: 0.7639\n",
      "Epoch 252/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1788 - acc: 0.7454 - val_loss: 0.1694 - val_acc: 0.7639\n",
      "Epoch 253/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1827 - acc: 0.7377 - val_loss: 0.1691 - val_acc: 0.7778\n",
      "Epoch 254/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1840 - acc: 0.7315 - val_loss: 0.1693 - val_acc: 0.7778\n",
      "Epoch 255/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1801 - acc: 0.7238 - val_loss: 0.1691 - val_acc: 0.7778\n",
      "Epoch 256/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1826 - acc: 0.7361 - val_loss: 0.1691 - val_acc: 0.7639\n",
      "Epoch 257/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1746 - acc: 0.7454 - val_loss: 0.1686 - val_acc: 0.7778\n",
      "Epoch 258/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1806 - acc: 0.7407 - val_loss: 0.1687 - val_acc: 0.7778\n",
      "Epoch 259/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1836 - acc: 0.7485 - val_loss: 0.1689 - val_acc: 0.7639\n",
      "Epoch 260/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1823 - acc: 0.7160 - val_loss: 0.1691 - val_acc: 0.7778\n",
      "Epoch 261/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1819 - acc: 0.7284 - val_loss: 0.1685 - val_acc: 0.7778\n",
      "Epoch 262/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1796 - acc: 0.7361 - val_loss: 0.1685 - val_acc: 0.7778\n",
      "Epoch 263/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1776 - acc: 0.7330 - val_loss: 0.1686 - val_acc: 0.7639\n",
      "Epoch 264/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1812 - acc: 0.7114 - val_loss: 0.1684 - val_acc: 0.7778\n",
      "Epoch 265/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1814 - acc: 0.7423 - val_loss: 0.1682 - val_acc: 0.7639\n",
      "Epoch 266/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1804 - acc: 0.7407 - val_loss: 0.1682 - val_acc: 0.7639\n",
      "Epoch 267/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1782 - acc: 0.7392 - val_loss: 0.1682 - val_acc: 0.7639\n",
      "Epoch 268/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1813 - acc: 0.7330 - val_loss: 0.1682 - val_acc: 0.7778\n",
      "Epoch 269/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1801 - acc: 0.7361 - val_loss: 0.1680 - val_acc: 0.7778\n",
      "Epoch 270/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1786 - acc: 0.7330 - val_loss: 0.1679 - val_acc: 0.7639\n",
      "Epoch 271/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1812 - acc: 0.7238 - val_loss: 0.1679 - val_acc: 0.7778\n",
      "Epoch 272/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1809 - acc: 0.7253 - val_loss: 0.1680 - val_acc: 0.7639\n",
      "Epoch 273/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1806 - acc: 0.7299 - val_loss: 0.1680 - val_acc: 0.7639\n",
      "Epoch 274/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1776 - acc: 0.7392 - val_loss: 0.1686 - val_acc: 0.7778\n",
      "Epoch 275/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1812 - acc: 0.7407 - val_loss: 0.1682 - val_acc: 0.7778\n",
      "Epoch 276/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1765 - acc: 0.7546 - val_loss: 0.1677 - val_acc: 0.7639\n",
      "Epoch 277/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1779 - acc: 0.7315 - val_loss: 0.1679 - val_acc: 0.7778\n",
      "Epoch 278/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1839 - acc: 0.7068 - val_loss: 0.1677 - val_acc: 0.7778\n",
      "Epoch 279/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1737 - acc: 0.7485 - val_loss: 0.1675 - val_acc: 0.7778\n",
      "Epoch 280/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1739 - acc: 0.7361 - val_loss: 0.1675 - val_acc: 0.7778\n",
      "Epoch 281/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1711 - acc: 0.7716 - val_loss: 0.1669 - val_acc: 0.7778\n",
      "Epoch 282/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1791 - acc: 0.7438 - val_loss: 0.1668 - val_acc: 0.7778\n",
      "Epoch 283/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1779 - acc: 0.7330 - val_loss: 0.1670 - val_acc: 0.7778\n",
      "Epoch 284/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1750 - acc: 0.7407 - val_loss: 0.1667 - val_acc: 0.7778\n",
      "Epoch 285/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1713 - acc: 0.7346 - val_loss: 0.1671 - val_acc: 0.7778\n",
      "Epoch 286/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1769 - acc: 0.7330 - val_loss: 0.1672 - val_acc: 0.7778\n",
      "Epoch 287/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1722 - acc: 0.7346 - val_loss: 0.1666 - val_acc: 0.7778\n",
      "Epoch 288/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1726 - acc: 0.7377 - val_loss: 0.1665 - val_acc: 0.7778\n",
      "Epoch 289/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1778 - acc: 0.7500 - val_loss: 0.1662 - val_acc: 0.7778\n",
      "Epoch 290/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1765 - acc: 0.7330 - val_loss: 0.1660 - val_acc: 0.7778\n",
      "Epoch 291/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1799 - acc: 0.7330 - val_loss: 0.1664 - val_acc: 0.7778\n",
      "Epoch 292/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1812 - acc: 0.7222 - val_loss: 0.1661 - val_acc: 0.7778\n",
      "Epoch 293/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1725 - acc: 0.7500 - val_loss: 0.1659 - val_acc: 0.7778\n",
      "Epoch 294/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1791 - acc: 0.7500 - val_loss: 0.1663 - val_acc: 0.7778\n",
      "Epoch 295/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1774 - acc: 0.7500 - val_loss: 0.1661 - val_acc: 0.7778\n",
      "Epoch 296/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.1711 - acc: 0.7654 - val_loss: 0.1655 - val_acc: 0.7778\n",
      "Epoch 297/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1764 - acc: 0.7454 - val_loss: 0.1654 - val_acc: 0.7778\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 128us/step - loss: 0.1748 - acc: 0.7454 - val_loss: 0.1654 - val_acc: 0.7778\n",
      "Epoch 299/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1788 - acc: 0.7515 - val_loss: 0.1656 - val_acc: 0.7778\n",
      "Epoch 300/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1724 - acc: 0.7361 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 301/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1748 - acc: 0.7469 - val_loss: 0.1651 - val_acc: 0.7778\n",
      "Epoch 302/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1758 - acc: 0.7377 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 303/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1749 - acc: 0.7423 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 304/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1698 - acc: 0.7623 - val_loss: 0.1658 - val_acc: 0.7778\n",
      "Epoch 305/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1761 - acc: 0.7284 - val_loss: 0.1656 - val_acc: 0.7778\n",
      "Epoch 306/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1745 - acc: 0.7500 - val_loss: 0.1651 - val_acc: 0.7778\n",
      "Epoch 307/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1744 - acc: 0.7531 - val_loss: 0.1643 - val_acc: 0.7917\n",
      "Epoch 308/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1734 - acc: 0.7485 - val_loss: 0.1656 - val_acc: 0.7778\n",
      "Epoch 309/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1791 - acc: 0.7407 - val_loss: 0.1654 - val_acc: 0.7778\n",
      "Epoch 310/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1733 - acc: 0.7377 - val_loss: 0.1650 - val_acc: 0.7917\n",
      "Epoch 311/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1728 - acc: 0.7515 - val_loss: 0.1645 - val_acc: 0.7917\n",
      "Epoch 312/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1759 - acc: 0.7469 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 313/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1715 - acc: 0.7593 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 314/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1745 - acc: 0.7469 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 315/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1757 - acc: 0.7454 - val_loss: 0.1652 - val_acc: 0.7778\n",
      "Epoch 316/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1749 - acc: 0.7562 - val_loss: 0.1644 - val_acc: 0.7778\n",
      "Epoch 317/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1744 - acc: 0.7454 - val_loss: 0.1646 - val_acc: 0.7778\n",
      "Epoch 318/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1736 - acc: 0.7454 - val_loss: 0.1645 - val_acc: 0.7917\n",
      "Epoch 319/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1726 - acc: 0.7485 - val_loss: 0.1646 - val_acc: 0.7778\n",
      "Epoch 320/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1711 - acc: 0.7515 - val_loss: 0.1643 - val_acc: 0.7778\n",
      "Epoch 321/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1764 - acc: 0.7392 - val_loss: 0.1654 - val_acc: 0.7778\n",
      "Epoch 322/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1755 - acc: 0.7361 - val_loss: 0.1645 - val_acc: 0.7778\n",
      "Epoch 323/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1723 - acc: 0.7469 - val_loss: 0.1643 - val_acc: 0.7778\n",
      "Epoch 324/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1730 - acc: 0.7546 - val_loss: 0.1644 - val_acc: 0.7778\n",
      "Epoch 325/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1768 - acc: 0.7361 - val_loss: 0.1650 - val_acc: 0.7778\n",
      "Epoch 326/1000\n",
      "648/648 [==============================] - 0s 130us/step - loss: 0.1716 - acc: 0.7546 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 327/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1721 - acc: 0.7515 - val_loss: 0.1636 - val_acc: 0.7917\n",
      "Epoch 328/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1756 - acc: 0.7423 - val_loss: 0.1636 - val_acc: 0.7917\n",
      "Epoch 329/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1767 - acc: 0.7330 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 330/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1722 - acc: 0.7515 - val_loss: 0.1637 - val_acc: 0.7778\n",
      "Epoch 331/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1712 - acc: 0.7562 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 332/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1743 - acc: 0.7330 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 333/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1729 - acc: 0.7623 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 334/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1742 - acc: 0.7485 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 335/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1714 - acc: 0.7593 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 336/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1714 - acc: 0.7546 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 337/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1697 - acc: 0.7531 - val_loss: 0.1643 - val_acc: 0.7778\n",
      "Epoch 338/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1786 - acc: 0.7330 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 339/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1726 - acc: 0.7500 - val_loss: 0.1642 - val_acc: 0.7778\n",
      "Epoch 340/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1741 - acc: 0.7377 - val_loss: 0.1642 - val_acc: 0.7778\n",
      "Epoch 341/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1752 - acc: 0.7361 - val_loss: 0.1642 - val_acc: 0.7778\n",
      "Epoch 342/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1777 - acc: 0.7299 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 343/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1666 - acc: 0.7485 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 344/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1761 - acc: 0.7238 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 345/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1693 - acc: 0.7546 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 346/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1748 - acc: 0.7546 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 347/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1681 - acc: 0.7485 - val_loss: 0.1631 - val_acc: 0.7778\n",
      "Epoch 348/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1764 - acc: 0.7531 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 349/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1707 - acc: 0.7361 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 350/1000\n",
      "648/648 [==============================] - 0s 136us/step - loss: 0.1781 - acc: 0.7315 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 351/1000\n",
      "648/648 [==============================] - 0s 136us/step - loss: 0.1717 - acc: 0.7500 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 352/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1665 - acc: 0.7670 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 353/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1661 - acc: 0.7716 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 354/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1683 - acc: 0.7562 - val_loss: 0.1632 - val_acc: 0.7778\n",
      "Epoch 355/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1715 - acc: 0.7361 - val_loss: 0.1631 - val_acc: 0.7778\n",
      "Epoch 356/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1717 - acc: 0.7685 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 357/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1769 - acc: 0.7423 - val_loss: 0.1634 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1709 - acc: 0.7438 - val_loss: 0.1621 - val_acc: 0.7778\n",
      "Epoch 359/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1721 - acc: 0.7330 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 360/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1739 - acc: 0.7407 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 361/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1705 - acc: 0.7593 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 362/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1747 - acc: 0.7515 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 363/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1702 - acc: 0.7546 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 364/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1675 - acc: 0.7531 - val_loss: 0.1627 - val_acc: 0.7778\n",
      "Epoch 365/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1714 - acc: 0.7438 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 366/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1746 - acc: 0.7515 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 367/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1723 - acc: 0.7500 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 368/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1711 - acc: 0.7500 - val_loss: 0.1630 - val_acc: 0.7778\n",
      "Epoch 369/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1688 - acc: 0.7623 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 370/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1656 - acc: 0.7701 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 371/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1679 - acc: 0.7515 - val_loss: 0.1617 - val_acc: 0.7778\n",
      "Epoch 372/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1741 - acc: 0.7485 - val_loss: 0.1628 - val_acc: 0.7778\n",
      "Epoch 373/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1660 - acc: 0.7762 - val_loss: 0.1628 - val_acc: 0.7778\n",
      "Epoch 374/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1690 - acc: 0.7608 - val_loss: 0.1624 - val_acc: 0.7778\n",
      "Epoch 375/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1729 - acc: 0.7500 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 376/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1666 - acc: 0.7731 - val_loss: 0.1627 - val_acc: 0.7778\n",
      "Epoch 377/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1657 - acc: 0.7546 - val_loss: 0.1630 - val_acc: 0.7778\n",
      "Epoch 378/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1717 - acc: 0.7623 - val_loss: 0.1631 - val_acc: 0.7778\n",
      "Epoch 379/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1717 - acc: 0.7593 - val_loss: 0.1631 - val_acc: 0.7778\n",
      "Epoch 380/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1691 - acc: 0.7546 - val_loss: 0.1624 - val_acc: 0.7778\n",
      "Epoch 381/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1682 - acc: 0.7438 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 382/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1685 - acc: 0.7562 - val_loss: 0.1629 - val_acc: 0.7778\n",
      "Epoch 383/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1711 - acc: 0.7500 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 384/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1636 - acc: 0.7608 - val_loss: 0.1624 - val_acc: 0.7778\n",
      "Epoch 385/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1665 - acc: 0.7392 - val_loss: 0.1629 - val_acc: 0.7778\n",
      "Epoch 386/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1635 - acc: 0.7593 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 387/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1720 - acc: 0.7392 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 388/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1747 - acc: 0.7485 - val_loss: 0.1628 - val_acc: 0.7778\n",
      "Epoch 389/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1685 - acc: 0.7608 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 390/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1744 - acc: 0.7469 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 391/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1687 - acc: 0.7623 - val_loss: 0.1618 - val_acc: 0.7778\n",
      "Epoch 392/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1649 - acc: 0.7454 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 393/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1661 - acc: 0.7670 - val_loss: 0.1628 - val_acc: 0.7778\n",
      "Epoch 394/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1687 - acc: 0.7392 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 395/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1626 - acc: 0.7840 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 396/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1677 - acc: 0.7623 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 397/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1663 - acc: 0.7824 - val_loss: 0.1634 - val_acc: 0.7917\n",
      "Epoch 398/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1716 - acc: 0.7469 - val_loss: 0.1638 - val_acc: 0.7917\n",
      "Epoch 399/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1664 - acc: 0.7623 - val_loss: 0.1635 - val_acc: 0.7917\n",
      "Epoch 400/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1700 - acc: 0.7469 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 401/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1674 - acc: 0.7747 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 402/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1668 - acc: 0.7623 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 403/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1645 - acc: 0.7701 - val_loss: 0.1612 - val_acc: 0.7778\n",
      "Epoch 404/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1720 - acc: 0.7546 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 405/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1695 - acc: 0.7562 - val_loss: 0.1628 - val_acc: 0.7917\n",
      "Epoch 406/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1638 - acc: 0.7701 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 407/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1735 - acc: 0.7423 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 408/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1715 - acc: 0.7438 - val_loss: 0.1621 - val_acc: 0.7778\n",
      "Epoch 409/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1673 - acc: 0.7623 - val_loss: 0.1629 - val_acc: 0.7917\n",
      "Epoch 410/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1673 - acc: 0.7670 - val_loss: 0.1614 - val_acc: 0.7778\n",
      "Epoch 411/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1676 - acc: 0.7438 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 412/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1661 - acc: 0.7485 - val_loss: 0.1618 - val_acc: 0.7778\n",
      "Epoch 413/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1704 - acc: 0.7608 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 414/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1659 - acc: 0.7685 - val_loss: 0.1617 - val_acc: 0.7778\n",
      "Epoch 415/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1654 - acc: 0.7469 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 416/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1638 - acc: 0.7670 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 417/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 76us/step - loss: 0.1665 - acc: 0.7577 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 418/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1616 - acc: 0.7562 - val_loss: 0.1621 - val_acc: 0.7917\n",
      "Epoch 419/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1706 - acc: 0.7485 - val_loss: 0.1630 - val_acc: 0.7917\n",
      "Epoch 420/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1735 - acc: 0.7454 - val_loss: 0.1627 - val_acc: 0.7917\n",
      "Epoch 421/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1680 - acc: 0.7562 - val_loss: 0.1624 - val_acc: 0.7778\n",
      "Epoch 422/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1677 - acc: 0.7639 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 423/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1698 - acc: 0.7423 - val_loss: 0.1628 - val_acc: 0.7917\n",
      "Epoch 424/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1666 - acc: 0.7546 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 425/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1666 - acc: 0.7562 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 426/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1669 - acc: 0.7577 - val_loss: 0.1627 - val_acc: 0.7917\n",
      "Epoch 427/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1626 - acc: 0.7809 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 428/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1687 - acc: 0.7315 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 429/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1656 - acc: 0.7608 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 430/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1643 - acc: 0.7654 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 431/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1640 - acc: 0.7716 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 432/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1664 - acc: 0.7438 - val_loss: 0.1626 - val_acc: 0.7917\n",
      "Epoch 433/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1679 - acc: 0.7623 - val_loss: 0.1626 - val_acc: 0.7917\n",
      "Epoch 434/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1653 - acc: 0.7762 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 435/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1664 - acc: 0.7716 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 436/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1650 - acc: 0.7608 - val_loss: 0.1624 - val_acc: 0.7917\n",
      "Epoch 437/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1600 - acc: 0.7716 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 438/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1710 - acc: 0.7762 - val_loss: 0.1618 - val_acc: 0.7778\n",
      "Epoch 439/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1638 - acc: 0.7531 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 440/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1667 - acc: 0.7485 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 441/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1672 - acc: 0.7562 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 442/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1659 - acc: 0.7546 - val_loss: 0.1623 - val_acc: 0.7778\n",
      "Epoch 443/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1684 - acc: 0.7407 - val_loss: 0.1622 - val_acc: 0.7917\n",
      "Epoch 444/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1644 - acc: 0.7747 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 445/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1647 - acc: 0.7731 - val_loss: 0.1626 - val_acc: 0.7917\n",
      "Epoch 446/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1608 - acc: 0.7701 - val_loss: 0.1627 - val_acc: 0.7917\n",
      "Epoch 447/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1648 - acc: 0.7454 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 448/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1618 - acc: 0.7685 - val_loss: 0.1622 - val_acc: 0.7917\n",
      "Epoch 449/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1659 - acc: 0.7716 - val_loss: 0.1612 - val_acc: 0.7778\n",
      "Epoch 450/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1647 - acc: 0.7793 - val_loss: 0.1617 - val_acc: 0.7778\n",
      "Epoch 451/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1600 - acc: 0.7762 - val_loss: 0.1611 - val_acc: 0.7778\n",
      "Epoch 452/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1662 - acc: 0.7731 - val_loss: 0.1615 - val_acc: 0.7778\n",
      "Epoch 453/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1667 - acc: 0.7608 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 454/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1705 - acc: 0.7639 - val_loss: 0.1617 - val_acc: 0.7778\n",
      "Epoch 455/1000\n",
      "648/648 [==============================] - 0s 132us/step - loss: 0.1626 - acc: 0.7762 - val_loss: 0.1615 - val_acc: 0.7778\n",
      "Epoch 456/1000\n",
      "648/648 [==============================] - 0s 132us/step - loss: 0.1651 - acc: 0.7762 - val_loss: 0.1621 - val_acc: 0.7917\n",
      "Epoch 457/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1645 - acc: 0.7731 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 458/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1644 - acc: 0.7562 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 459/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1636 - acc: 0.7716 - val_loss: 0.1610 - val_acc: 0.7778\n",
      "Epoch 460/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1636 - acc: 0.7731 - val_loss: 0.1612 - val_acc: 0.7778\n",
      "Epoch 461/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1616 - acc: 0.7701 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 462/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1684 - acc: 0.7654 - val_loss: 0.1621 - val_acc: 0.7917\n",
      "Epoch 463/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1647 - acc: 0.7654 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 464/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1624 - acc: 0.7685 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 465/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1652 - acc: 0.7608 - val_loss: 0.1619 - val_acc: 0.7917\n",
      "Epoch 466/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1637 - acc: 0.7654 - val_loss: 0.1611 - val_acc: 0.7917\n",
      "Epoch 467/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1629 - acc: 0.7685 - val_loss: 0.1618 - val_acc: 0.7917\n",
      "Epoch 468/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1603 - acc: 0.7685 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 469/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1638 - acc: 0.7670 - val_loss: 0.1609 - val_acc: 0.7778\n",
      "Epoch 470/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1645 - acc: 0.7793 - val_loss: 0.1607 - val_acc: 0.7778\n",
      "Epoch 471/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1630 - acc: 0.7701 - val_loss: 0.1615 - val_acc: 0.7917\n",
      "Epoch 472/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1641 - acc: 0.7670 - val_loss: 0.1608 - val_acc: 0.7778\n",
      "Epoch 473/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1653 - acc: 0.7685 - val_loss: 0.1611 - val_acc: 0.7778\n",
      "Epoch 474/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1587 - acc: 0.781 - 0s 101us/step - loss: 0.1599 - acc: 0.7840 - val_loss: 0.1603 - val_acc: 0.7917\n",
      "Epoch 475/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1695 - acc: 0.7654 - val_loss: 0.1609 - val_acc: 0.7778\n",
      "Epoch 476/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 110us/step - loss: 0.1678 - acc: 0.7500 - val_loss: 0.1614 - val_acc: 0.7917\n",
      "Epoch 477/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1648 - acc: 0.7639 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 478/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1646 - acc: 0.7577 - val_loss: 0.1609 - val_acc: 0.7778\n",
      "Epoch 479/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1630 - acc: 0.7731 - val_loss: 0.1610 - val_acc: 0.7778\n",
      "Epoch 480/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1688 - acc: 0.7623 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 481/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1577 - acc: 0.7855 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 482/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1645 - acc: 0.7701 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 483/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1610 - acc: 0.7824 - val_loss: 0.1614 - val_acc: 0.7917\n",
      "Epoch 484/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1638 - acc: 0.7793 - val_loss: 0.1610 - val_acc: 0.7778\n",
      "Epoch 485/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1620 - acc: 0.7670 - val_loss: 0.1615 - val_acc: 0.7917\n",
      "Epoch 486/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1622 - acc: 0.7762 - val_loss: 0.1615 - val_acc: 0.7917\n",
      "Epoch 487/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1664 - acc: 0.7500 - val_loss: 0.1619 - val_acc: 0.7917\n",
      "Epoch 488/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1658 - acc: 0.7593 - val_loss: 0.1607 - val_acc: 0.7917\n",
      "Epoch 489/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1580 - acc: 0.7978 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 490/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1577 - acc: 0.7793 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 491/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1636 - acc: 0.7685 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 492/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1617 - acc: 0.7685 - val_loss: 0.1608 - val_acc: 0.7778\n",
      "Epoch 493/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1625 - acc: 0.7654 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 494/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1634 - acc: 0.7747 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 495/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1592 - acc: 0.7793 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 496/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1616 - acc: 0.7840 - val_loss: 0.1626 - val_acc: 0.7917\n",
      "Epoch 497/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1626 - acc: 0.7793 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 498/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1585 - acc: 0.7855 - val_loss: 0.1615 - val_acc: 0.7917\n",
      "Epoch 499/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1619 - acc: 0.7778 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 500/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1630 - acc: 0.7809 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 501/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1559 - acc: 0.7809 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 502/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1604 - acc: 0.7762 - val_loss: 0.1618 - val_acc: 0.7917\n",
      "Epoch 503/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1661 - acc: 0.7701 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 504/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1656 - acc: 0.7577 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 505/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1575 - acc: 0.7870 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 506/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1640 - acc: 0.7562 - val_loss: 0.1610 - val_acc: 0.7917\n",
      "Epoch 507/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1572 - acc: 0.7870 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 508/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1587 - acc: 0.7747 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 509/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1640 - acc: 0.7639 - val_loss: 0.1617 - val_acc: 0.7917\n",
      "Epoch 510/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1590 - acc: 0.7747 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 511/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1618 - acc: 0.7731 - val_loss: 0.1613 - val_acc: 0.7917\n",
      "Epoch 512/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1574 - acc: 0.7731 - val_loss: 0.1622 - val_acc: 0.7917\n",
      "Epoch 513/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1637 - acc: 0.7608 - val_loss: 0.1621 - val_acc: 0.7917\n",
      "Epoch 514/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1602 - acc: 0.7716 - val_loss: 0.1612 - val_acc: 0.7917\n",
      "Epoch 515/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1559 - acc: 0.7793 - val_loss: 0.1610 - val_acc: 0.7917\n",
      "Epoch 516/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1586 - acc: 0.7639 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 517/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1584 - acc: 0.7747 - val_loss: 0.1610 - val_acc: 0.7917\n",
      "Epoch 518/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1566 - acc: 0.7824 - val_loss: 0.1619 - val_acc: 0.7917\n",
      "Epoch 519/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1660 - acc: 0.7593 - val_loss: 0.1616 - val_acc: 0.7917\n",
      "Epoch 520/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1578 - acc: 0.7978 - val_loss: 0.1614 - val_acc: 0.7778\n",
      "Epoch 521/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1589 - acc: 0.7623 - val_loss: 0.1615 - val_acc: 0.7917\n",
      "Epoch 522/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1619 - acc: 0.7623 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 523/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1596 - acc: 0.7793 - val_loss: 0.1621 - val_acc: 0.7917\n",
      "Epoch 524/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1565 - acc: 0.7731 - val_loss: 0.1619 - val_acc: 0.7917\n",
      "Epoch 525/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 0.1583 - acc: 0.7901 - val_loss: 0.1618 - val_acc: 0.7917\n",
      "Epoch 526/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1612 - acc: 0.7762 - val_loss: 0.1619 - val_acc: 0.7917\n",
      "Epoch 527/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1652 - acc: 0.7731 - val_loss: 0.1618 - val_acc: 0.7917\n",
      "Epoch 528/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1602 - acc: 0.7762 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 529/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1572 - acc: 0.7948 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 530/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1629 - acc: 0.7701 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 531/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1576 - acc: 0.7778 - val_loss: 0.1625 - val_acc: 0.7917\n",
      "Epoch 532/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1587 - acc: 0.7762 - val_loss: 0.1632 - val_acc: 0.7917\n",
      "Epoch 533/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1635 - acc: 0.7608 - val_loss: 0.1634 - val_acc: 0.7917\n",
      "Epoch 534/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1647 - acc: 0.7762 - val_loss: 0.1631 - val_acc: 0.7917\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 122us/step - loss: 0.1588 - acc: 0.7855 - val_loss: 0.1627 - val_acc: 0.7917\n",
      "Epoch 536/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1637 - acc: 0.7809 - val_loss: 0.1623 - val_acc: 0.7917\n",
      "Epoch 537/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1586 - acc: 0.7701 - val_loss: 0.1627 - val_acc: 0.7917\n",
      "Epoch 538/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1619 - acc: 0.7840 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 539/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1573 - acc: 0.7870 - val_loss: 0.1631 - val_acc: 0.7917\n",
      "Epoch 540/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1584 - acc: 0.7824 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 541/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1553 - acc: 0.7932 - val_loss: 0.1634 - val_acc: 0.7917\n",
      "Epoch 542/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1568 - acc: 0.7963 - val_loss: 0.1635 - val_acc: 0.7917\n",
      "Epoch 543/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1575 - acc: 0.7901 - val_loss: 0.1628 - val_acc: 0.7639\n",
      "Epoch 544/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1587 - acc: 0.7901 - val_loss: 0.1624 - val_acc: 0.7917\n",
      "Epoch 545/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1578 - acc: 0.7824 - val_loss: 0.1628 - val_acc: 0.7917\n",
      "Epoch 546/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1624 - acc: 0.7701 - val_loss: 0.1630 - val_acc: 0.7917\n",
      "Epoch 547/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1573 - acc: 0.7840 - val_loss: 0.1635 - val_acc: 0.7917\n",
      "Epoch 548/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1545 - acc: 0.7855 - val_loss: 0.1632 - val_acc: 0.7778\n",
      "Epoch 549/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1577 - acc: 0.7917 - val_loss: 0.1629 - val_acc: 0.7778\n",
      "Epoch 550/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1558 - acc: 0.7901 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 551/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1575 - acc: 0.7778 - val_loss: 0.1639 - val_acc: 0.7917\n",
      "Epoch 552/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1547 - acc: 0.8040 - val_loss: 0.1639 - val_acc: 0.7917\n",
      "Epoch 553/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1595 - acc: 0.7870 - val_loss: 0.1636 - val_acc: 0.7917\n",
      "Epoch 554/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1588 - acc: 0.7716 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 555/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1581 - acc: 0.7917 - val_loss: 0.1630 - val_acc: 0.7917\n",
      "Epoch 556/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1561 - acc: 0.7948 - val_loss: 0.1633 - val_acc: 0.7917\n",
      "Epoch 557/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1577 - acc: 0.7886 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 558/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1604 - acc: 0.7731 - val_loss: 0.1632 - val_acc: 0.7778\n",
      "Epoch 559/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1580 - acc: 0.8009 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 560/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1537 - acc: 0.8025 - val_loss: 0.1637 - val_acc: 0.8194\n",
      "Epoch 561/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1551 - acc: 0.7824 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 562/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1584 - acc: 0.7809 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 563/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1594 - acc: 0.7901 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 564/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1578 - acc: 0.7855 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 565/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1521 - acc: 0.8071 - val_loss: 0.1640 - val_acc: 0.7917\n",
      "Epoch 566/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1597 - acc: 0.7824 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 567/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1584 - acc: 0.7716 - val_loss: 0.1640 - val_acc: 0.7639\n",
      "Epoch 568/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1570 - acc: 0.7840 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 569/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1603 - acc: 0.7978 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 570/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1599 - acc: 0.7824 - val_loss: 0.1634 - val_acc: 0.7917\n",
      "Epoch 571/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1533 - acc: 0.7901 - val_loss: 0.1633 - val_acc: 0.7778\n",
      "Epoch 572/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1543 - acc: 0.7901 - val_loss: 0.1634 - val_acc: 0.7778\n",
      "Epoch 573/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1552 - acc: 0.7824 - val_loss: 0.1631 - val_acc: 0.7778\n",
      "Epoch 574/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1487 - acc: 0.8086 - val_loss: 0.1631 - val_acc: 0.7639\n",
      "Epoch 575/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1493 - acc: 0.7855 - val_loss: 0.1636 - val_acc: 0.7778\n",
      "Epoch 576/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1550 - acc: 0.7762 - val_loss: 0.1638 - val_acc: 0.8194\n",
      "Epoch 577/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1492 - acc: 0.8164 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 578/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1562 - acc: 0.7886 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 579/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1564 - acc: 0.7855 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 580/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1519 - acc: 0.8025 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 581/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1583 - acc: 0.7840 - val_loss: 0.1641 - val_acc: 0.7639\n",
      "Epoch 582/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1562 - acc: 0.7932 - val_loss: 0.1645 - val_acc: 0.7917\n",
      "Epoch 583/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1604 - acc: 0.8009 - val_loss: 0.1644 - val_acc: 0.7917\n",
      "Epoch 584/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1562 - acc: 0.7917 - val_loss: 0.1644 - val_acc: 0.8056\n",
      "Epoch 585/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1544 - acc: 0.7963 - val_loss: 0.1643 - val_acc: 0.7917\n",
      "Epoch 586/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1555 - acc: 0.7809 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 587/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1546 - acc: 0.8056 - val_loss: 0.1643 - val_acc: 0.7917\n",
      "Epoch 588/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1543 - acc: 0.7963 - val_loss: 0.1647 - val_acc: 0.8056\n",
      "Epoch 589/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1553 - acc: 0.7978 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 590/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1511 - acc: 0.8179 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 591/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1574 - acc: 0.8025 - val_loss: 0.1644 - val_acc: 0.7778\n",
      "Epoch 592/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1554 - acc: 0.7917 - val_loss: 0.1645 - val_acc: 0.7778\n",
      "Epoch 593/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1537 - acc: 0.7948 - val_loss: 0.1646 - val_acc: 0.7778\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 112us/step - loss: 0.1542 - acc: 0.7840 - val_loss: 0.1647 - val_acc: 0.7917\n",
      "Epoch 595/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1521 - acc: 0.8009 - val_loss: 0.1652 - val_acc: 0.8056\n",
      "Epoch 596/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1538 - acc: 0.8009 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 597/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1564 - acc: 0.7978 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 598/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1560 - acc: 0.7901 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 599/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1526 - acc: 0.8040 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 600/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1560 - acc: 0.7840 - val_loss: 0.1655 - val_acc: 0.8056\n",
      "Epoch 601/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1546 - acc: 0.7963 - val_loss: 0.1646 - val_acc: 0.7917\n",
      "Epoch 602/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1518 - acc: 0.8056 - val_loss: 0.1645 - val_acc: 0.7639\n",
      "Epoch 603/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1511 - acc: 0.8071 - val_loss: 0.1652 - val_acc: 0.8056\n",
      "Epoch 604/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1516 - acc: 0.7994 - val_loss: 0.1644 - val_acc: 0.7778\n",
      "Epoch 605/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1507 - acc: 0.7978 - val_loss: 0.1644 - val_acc: 0.7917\n",
      "Epoch 606/1000\n",
      "648/648 [==============================] - 0s 132us/step - loss: 0.1529 - acc: 0.7948 - val_loss: 0.1642 - val_acc: 0.7778\n",
      "Epoch 607/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1480 - acc: 0.8025 - val_loss: 0.1644 - val_acc: 0.8056\n",
      "Epoch 608/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1526 - acc: 0.8117 - val_loss: 0.1648 - val_acc: 0.8056\n",
      "Epoch 609/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1501 - acc: 0.8086 - val_loss: 0.1647 - val_acc: 0.7917\n",
      "Epoch 610/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1549 - acc: 0.8040 - val_loss: 0.1647 - val_acc: 0.7917\n",
      "Epoch 611/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1565 - acc: 0.7932 - val_loss: 0.1648 - val_acc: 0.8056\n",
      "Epoch 612/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1496 - acc: 0.8040 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 613/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1498 - acc: 0.7948 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 614/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1529 - acc: 0.7978 - val_loss: 0.1661 - val_acc: 0.7778\n",
      "Epoch 615/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1525 - acc: 0.8009 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 616/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1557 - acc: 0.7978 - val_loss: 0.1648 - val_acc: 0.7917\n",
      "Epoch 617/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1487 - acc: 0.8009 - val_loss: 0.1645 - val_acc: 0.7778\n",
      "Epoch 618/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1528 - acc: 0.7994 - val_loss: 0.1645 - val_acc: 0.7778\n",
      "Epoch 619/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1517 - acc: 0.7978 - val_loss: 0.1646 - val_acc: 0.7917\n",
      "Epoch 620/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1565 - acc: 0.7963 - val_loss: 0.1646 - val_acc: 0.7917\n",
      "Epoch 621/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1498 - acc: 0.8133 - val_loss: 0.1648 - val_acc: 0.7917\n",
      "Epoch 622/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1521 - acc: 0.8225 - val_loss: 0.1650 - val_acc: 0.7778\n",
      "Epoch 623/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1522 - acc: 0.8148 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 624/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1535 - acc: 0.8009 - val_loss: 0.1643 - val_acc: 0.7917\n",
      "Epoch 625/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1528 - acc: 0.7978 - val_loss: 0.1646 - val_acc: 0.7917\n",
      "Epoch 626/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1480 - acc: 0.8009 - val_loss: 0.1647 - val_acc: 0.7917\n",
      "Epoch 627/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1493 - acc: 0.8056 - val_loss: 0.1650 - val_acc: 0.7917\n",
      "Epoch 628/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1532 - acc: 0.8056 - val_loss: 0.1652 - val_acc: 0.7778\n",
      "Epoch 629/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1512 - acc: 0.7978 - val_loss: 0.1654 - val_acc: 0.7917\n",
      "Epoch 630/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1497 - acc: 0.8025 - val_loss: 0.1651 - val_acc: 0.8056\n",
      "Epoch 631/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1535 - acc: 0.7901 - val_loss: 0.1652 - val_acc: 0.7917\n",
      "Epoch 632/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1460 - acc: 0.8025 - val_loss: 0.1648 - val_acc: 0.7917\n",
      "Epoch 633/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1472 - acc: 0.8210 - val_loss: 0.1661 - val_acc: 0.7639\n",
      "Epoch 634/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1497 - acc: 0.8086 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 635/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1507 - acc: 0.8194 - val_loss: 0.1650 - val_acc: 0.7917\n",
      "Epoch 636/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1491 - acc: 0.7994 - val_loss: 0.1648 - val_acc: 0.8056\n",
      "Epoch 637/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1468 - acc: 0.8210 - val_loss: 0.1654 - val_acc: 0.7917\n",
      "Epoch 638/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1520 - acc: 0.8117 - val_loss: 0.1652 - val_acc: 0.7778\n",
      "Epoch 639/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1486 - acc: 0.8086 - val_loss: 0.1649 - val_acc: 0.7917\n",
      "Epoch 640/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1490 - acc: 0.8133 - val_loss: 0.1657 - val_acc: 0.7778\n",
      "Epoch 641/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1523 - acc: 0.8056 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 642/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1447 - acc: 0.8241 - val_loss: 0.1664 - val_acc: 0.7778\n",
      "Epoch 643/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1507 - acc: 0.8071 - val_loss: 0.1655 - val_acc: 0.8056\n",
      "Epoch 644/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1485 - acc: 0.8086 - val_loss: 0.1654 - val_acc: 0.7778\n",
      "Epoch 645/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1455 - acc: 0.8179 - val_loss: 0.1650 - val_acc: 0.7917\n",
      "Epoch 646/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1487 - acc: 0.8117 - val_loss: 0.1649 - val_acc: 0.7639\n",
      "Epoch 647/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1467 - acc: 0.8256 - val_loss: 0.1647 - val_acc: 0.7639\n",
      "Epoch 648/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1504 - acc: 0.8056 - val_loss: 0.1642 - val_acc: 0.8056\n",
      "Epoch 649/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1445 - acc: 0.8225 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 650/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1504 - acc: 0.8040 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 651/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1439 - acc: 0.8256 - val_loss: 0.1656 - val_acc: 0.7778\n",
      "Epoch 652/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1470 - acc: 0.8241 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 110us/step - loss: 0.1523 - acc: 0.8117 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 654/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1498 - acc: 0.8148 - val_loss: 0.1653 - val_acc: 0.7778\n",
      "Epoch 655/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1524 - acc: 0.7994 - val_loss: 0.1654 - val_acc: 0.7917\n",
      "Epoch 656/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1496 - acc: 0.8148 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 657/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1499 - acc: 0.8056 - val_loss: 0.1646 - val_acc: 0.7778\n",
      "Epoch 658/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1471 - acc: 0.8164 - val_loss: 0.1649 - val_acc: 0.7778\n",
      "Epoch 659/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1485 - acc: 0.8040 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 660/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1445 - acc: 0.8364 - val_loss: 0.1651 - val_acc: 0.7778\n",
      "Epoch 661/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1509 - acc: 0.8117 - val_loss: 0.1651 - val_acc: 0.7917\n",
      "Epoch 662/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1470 - acc: 0.8256 - val_loss: 0.1647 - val_acc: 0.7778\n",
      "Epoch 663/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1499 - acc: 0.8009 - val_loss: 0.1657 - val_acc: 0.7917\n",
      "Epoch 664/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1445 - acc: 0.8194 - val_loss: 0.1658 - val_acc: 0.7639\n",
      "Epoch 665/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1488 - acc: 0.8133 - val_loss: 0.1661 - val_acc: 0.7917\n",
      "Epoch 666/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1512 - acc: 0.8025 - val_loss: 0.1661 - val_acc: 0.7917\n",
      "Epoch 667/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1508 - acc: 0.8241 - val_loss: 0.1664 - val_acc: 0.7917\n",
      "Epoch 668/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1532 - acc: 0.8009 - val_loss: 0.1655 - val_acc: 0.7778\n",
      "Epoch 669/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1473 - acc: 0.8056 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 670/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1469 - acc: 0.8179 - val_loss: 0.1653 - val_acc: 0.7917\n",
      "Epoch 671/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1448 - acc: 0.8256 - val_loss: 0.1652 - val_acc: 0.8056\n",
      "Epoch 672/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1491 - acc: 0.8133 - val_loss: 0.1661 - val_acc: 0.7917\n",
      "Epoch 673/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1423 - acc: 0.8318 - val_loss: 0.1659 - val_acc: 0.7778\n",
      "Epoch 674/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1468 - acc: 0.8194 - val_loss: 0.1658 - val_acc: 0.7639\n",
      "Epoch 675/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1454 - acc: 0.8179 - val_loss: 0.1663 - val_acc: 0.7639\n",
      "Epoch 676/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1468 - acc: 0.8426 - val_loss: 0.1668 - val_acc: 0.7778\n",
      "Epoch 677/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1419 - acc: 0.8364 - val_loss: 0.1672 - val_acc: 0.7778\n",
      "Epoch 678/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1465 - acc: 0.8302 - val_loss: 0.1678 - val_acc: 0.7778\n",
      "Epoch 679/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1488 - acc: 0.8117 - val_loss: 0.1683 - val_acc: 0.7639\n",
      "Epoch 680/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1420 - acc: 0.8210 - val_loss: 0.1679 - val_acc: 0.7778\n",
      "Epoch 681/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1477 - acc: 0.8179 - val_loss: 0.1680 - val_acc: 0.7917\n",
      "Epoch 682/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1506 - acc: 0.8194 - val_loss: 0.1677 - val_acc: 0.7639\n",
      "Epoch 683/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1411 - acc: 0.8241 - val_loss: 0.1673 - val_acc: 0.7639\n",
      "Epoch 684/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1478 - acc: 0.8148 - val_loss: 0.1684 - val_acc: 0.7639\n",
      "Epoch 685/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1429 - acc: 0.8333 - val_loss: 0.1674 - val_acc: 0.7778\n",
      "Epoch 686/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1438 - acc: 0.8117 - val_loss: 0.1676 - val_acc: 0.7778\n",
      "Epoch 687/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1463 - acc: 0.8241 - val_loss: 0.1691 - val_acc: 0.7917\n",
      "Epoch 688/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1456 - acc: 0.8272 - val_loss: 0.1672 - val_acc: 0.7639\n",
      "Epoch 689/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1455 - acc: 0.8210 - val_loss: 0.1673 - val_acc: 0.7639\n",
      "Epoch 690/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1474 - acc: 0.8241 - val_loss: 0.1678 - val_acc: 0.7917\n",
      "Epoch 691/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1505 - acc: 0.8071 - val_loss: 0.1673 - val_acc: 0.7500\n",
      "Epoch 692/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1500 - acc: 0.8194 - val_loss: 0.1672 - val_acc: 0.7778\n",
      "Epoch 693/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1470 - acc: 0.8056 - val_loss: 0.1670 - val_acc: 0.7500\n",
      "Epoch 694/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1386 - acc: 0.8426 - val_loss: 0.1676 - val_acc: 0.7639\n",
      "Epoch 695/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1434 - acc: 0.8272 - val_loss: 0.1683 - val_acc: 0.7639\n",
      "Epoch 696/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1461 - acc: 0.8179 - val_loss: 0.1678 - val_acc: 0.7500\n",
      "Epoch 697/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1445 - acc: 0.8395 - val_loss: 0.1683 - val_acc: 0.7639\n",
      "Epoch 698/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1418 - acc: 0.8395 - val_loss: 0.1683 - val_acc: 0.7639\n",
      "Epoch 699/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1430 - acc: 0.8318 - val_loss: 0.1681 - val_acc: 0.7639\n",
      "Epoch 700/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1449 - acc: 0.8210 - val_loss: 0.1682 - val_acc: 0.7500\n",
      "Epoch 701/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1471 - acc: 0.8194 - val_loss: 0.1680 - val_acc: 0.7500\n",
      "Epoch 702/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1460 - acc: 0.8164 - val_loss: 0.1682 - val_acc: 0.7917\n",
      "Epoch 703/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1449 - acc: 0.8225 - val_loss: 0.1678 - val_acc: 0.7639\n",
      "Epoch 704/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1411 - acc: 0.8395 - val_loss: 0.1691 - val_acc: 0.7917\n",
      "Epoch 705/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1436 - acc: 0.8395 - val_loss: 0.1683 - val_acc: 0.7500\n",
      "Epoch 706/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1387 - acc: 0.8302 - val_loss: 0.1688 - val_acc: 0.7639\n",
      "Epoch 707/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1433 - acc: 0.8287 - val_loss: 0.1678 - val_acc: 0.7778\n",
      "Epoch 708/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1438 - acc: 0.8164 - val_loss: 0.1676 - val_acc: 0.7778\n",
      "Epoch 709/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1433 - acc: 0.8380 - val_loss: 0.1679 - val_acc: 0.7778\n",
      "Epoch 710/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1432 - acc: 0.8272 - val_loss: 0.1674 - val_acc: 0.7639\n",
      "Epoch 711/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1455 - acc: 0.8117 - val_loss: 0.1680 - val_acc: 0.7639\n",
      "Epoch 712/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1461 - acc: 0.8349 - val_loss: 0.1675 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1436 - acc: 0.8287 - val_loss: 0.1682 - val_acc: 0.7639\n",
      "Epoch 714/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1395 - acc: 0.8426 - val_loss: 0.1680 - val_acc: 0.7500\n",
      "Epoch 715/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1307 - acc: 0.875 - 0s 76us/step - loss: 0.1424 - acc: 0.8194 - val_loss: 0.1686 - val_acc: 0.7917\n",
      "Epoch 716/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1461 - acc: 0.8179 - val_loss: 0.1673 - val_acc: 0.7639\n",
      "Epoch 717/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1418 - acc: 0.8241 - val_loss: 0.1684 - val_acc: 0.7917\n",
      "Epoch 718/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1424 - acc: 0.8256 - val_loss: 0.1677 - val_acc: 0.7917\n",
      "Epoch 719/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1470 - acc: 0.8225 - val_loss: 0.1675 - val_acc: 0.7639\n",
      "Epoch 720/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1440 - acc: 0.8071 - val_loss: 0.1675 - val_acc: 0.7639\n",
      "Epoch 721/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1431 - acc: 0.8272 - val_loss: 0.1679 - val_acc: 0.7778\n",
      "Epoch 722/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1465 - acc: 0.8071 - val_loss: 0.1673 - val_acc: 0.7917\n",
      "Epoch 723/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1455 - acc: 0.8302 - val_loss: 0.1675 - val_acc: 0.7639\n",
      "Epoch 724/1000\n",
      "648/648 [==============================] - 0s 131us/step - loss: 0.1403 - acc: 0.8302 - val_loss: 0.1673 - val_acc: 0.7639\n",
      "Epoch 725/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.1461 - acc: 0.8194 - val_loss: 0.1674 - val_acc: 0.7639\n",
      "Epoch 726/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1447 - acc: 0.8349 - val_loss: 0.1682 - val_acc: 0.7500\n",
      "Epoch 727/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1418 - acc: 0.8256 - val_loss: 0.1681 - val_acc: 0.7500\n",
      "Epoch 728/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1408 - acc: 0.8364 - val_loss: 0.1690 - val_acc: 0.7778\n",
      "Epoch 729/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1454 - acc: 0.8179 - val_loss: 0.1688 - val_acc: 0.7361\n",
      "Epoch 730/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1439 - acc: 0.8210 - val_loss: 0.1683 - val_acc: 0.7639\n",
      "Epoch 731/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1404 - acc: 0.8302 - val_loss: 0.1676 - val_acc: 0.7361\n",
      "Epoch 732/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1428 - acc: 0.8133 - val_loss: 0.1682 - val_acc: 0.7500\n",
      "Epoch 733/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1413 - acc: 0.8287 - val_loss: 0.1684 - val_acc: 0.7500\n",
      "Epoch 734/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1421 - acc: 0.8086 - val_loss: 0.1687 - val_acc: 0.7500\n",
      "Epoch 735/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1410 - acc: 0.8349 - val_loss: 0.1699 - val_acc: 0.7917\n",
      "Epoch 736/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1391 - acc: 0.8272 - val_loss: 0.1696 - val_acc: 0.7500\n",
      "Epoch 737/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1434 - acc: 0.8272 - val_loss: 0.1705 - val_acc: 0.7778\n",
      "Epoch 738/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1419 - acc: 0.8318 - val_loss: 0.1699 - val_acc: 0.7500\n",
      "Epoch 739/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1426 - acc: 0.8225 - val_loss: 0.1696 - val_acc: 0.7639\n",
      "Epoch 740/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1448 - acc: 0.8302 - val_loss: 0.1703 - val_acc: 0.7778\n",
      "Epoch 741/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1404 - acc: 0.8333 - val_loss: 0.1702 - val_acc: 0.7639\n",
      "Epoch 742/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1422 - acc: 0.8302 - val_loss: 0.1700 - val_acc: 0.7639\n",
      "Epoch 743/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1416 - acc: 0.8349 - val_loss: 0.1701 - val_acc: 0.7500\n",
      "Epoch 744/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1412 - acc: 0.8179 - val_loss: 0.1703 - val_acc: 0.7500\n",
      "Epoch 745/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1427 - acc: 0.8225 - val_loss: 0.1700 - val_acc: 0.7500\n",
      "Epoch 746/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1423 - acc: 0.8364 - val_loss: 0.1698 - val_acc: 0.7500\n",
      "Epoch 747/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1381 - acc: 0.8287 - val_loss: 0.1691 - val_acc: 0.7361\n",
      "Epoch 748/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1402 - acc: 0.8302 - val_loss: 0.1693 - val_acc: 0.7361\n",
      "Epoch 749/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1382 - acc: 0.8318 - val_loss: 0.1696 - val_acc: 0.7778\n",
      "Epoch 750/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1413 - acc: 0.8241 - val_loss: 0.1691 - val_acc: 0.7500\n",
      "Epoch 751/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1424 - acc: 0.8164 - val_loss: 0.1691 - val_acc: 0.7500\n",
      "Epoch 752/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1434 - acc: 0.8302 - val_loss: 0.1695 - val_acc: 0.7361\n",
      "Epoch 753/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1438 - acc: 0.8256 - val_loss: 0.1697 - val_acc: 0.7361\n",
      "Epoch 754/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1435 - acc: 0.8333 - val_loss: 0.1701 - val_acc: 0.7500\n",
      "Epoch 755/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1421 - acc: 0.8225 - val_loss: 0.1699 - val_acc: 0.7500\n",
      "Epoch 756/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1405 - acc: 0.8410 - val_loss: 0.1693 - val_acc: 0.7500\n",
      "Epoch 757/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1347 - acc: 0.8457 - val_loss: 0.1692 - val_acc: 0.7361\n",
      "Epoch 758/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1370 - acc: 0.8333 - val_loss: 0.1693 - val_acc: 0.7639\n",
      "Epoch 759/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1372 - acc: 0.8364 - val_loss: 0.1698 - val_acc: 0.7639\n",
      "Epoch 760/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.1414 - acc: 0.8380 - val_loss: 0.1697 - val_acc: 0.7500\n",
      "Epoch 761/1000\n",
      "648/648 [==============================] - 0s 131us/step - loss: 0.1369 - acc: 0.8426 - val_loss: 0.1706 - val_acc: 0.7639\n",
      "Epoch 762/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1415 - acc: 0.8302 - val_loss: 0.1710 - val_acc: 0.7778\n",
      "Epoch 763/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1393 - acc: 0.8302 - val_loss: 0.1705 - val_acc: 0.7639\n",
      "Epoch 764/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1426 - acc: 0.8302 - val_loss: 0.1707 - val_acc: 0.7639\n",
      "Epoch 765/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1354 - acc: 0.8472 - val_loss: 0.1717 - val_acc: 0.7500\n",
      "Epoch 766/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1383 - acc: 0.8333 - val_loss: 0.1709 - val_acc: 0.7500\n",
      "Epoch 767/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1342 - acc: 0.8380 - val_loss: 0.1714 - val_acc: 0.7639\n",
      "Epoch 768/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1428 - acc: 0.8380 - val_loss: 0.1708 - val_acc: 0.7500\n",
      "Epoch 769/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1381 - acc: 0.8395 - val_loss: 0.1707 - val_acc: 0.7500\n",
      "Epoch 770/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1325 - acc: 0.8503 - val_loss: 0.1710 - val_acc: 0.7500\n",
      "Epoch 771/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1436 - acc: 0.8256 - val_loss: 0.1714 - val_acc: 0.7500\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 99us/step - loss: 0.1416 - acc: 0.8318 - val_loss: 0.1716 - val_acc: 0.7639\n",
      "Epoch 773/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1378 - acc: 0.8426 - val_loss: 0.1726 - val_acc: 0.7778\n",
      "Epoch 774/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1426 - acc: 0.8302 - val_loss: 0.1720 - val_acc: 0.7500\n",
      "Epoch 775/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1367 - acc: 0.8364 - val_loss: 0.1724 - val_acc: 0.7500\n",
      "Epoch 776/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1345 - acc: 0.8364 - val_loss: 0.1721 - val_acc: 0.7778\n",
      "Epoch 777/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1386 - acc: 0.8272 - val_loss: 0.1726 - val_acc: 0.7778\n",
      "Epoch 778/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1404 - acc: 0.8333 - val_loss: 0.1718 - val_acc: 0.7639\n",
      "Epoch 779/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1413 - acc: 0.8148 - val_loss: 0.1710 - val_acc: 0.7500\n",
      "Epoch 780/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1410 - acc: 0.8287 - val_loss: 0.1730 - val_acc: 0.7778\n",
      "Epoch 781/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1376 - acc: 0.8272 - val_loss: 0.1718 - val_acc: 0.7500\n",
      "Epoch 782/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1354 - acc: 0.8472 - val_loss: 0.1719 - val_acc: 0.7500\n",
      "Epoch 783/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 0.1409 - acc: 0.8395 - val_loss: 0.1706 - val_acc: 0.7361\n",
      "Epoch 784/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1341 - acc: 0.8395 - val_loss: 0.1728 - val_acc: 0.7778\n",
      "Epoch 785/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1365 - acc: 0.8194 - val_loss: 0.1709 - val_acc: 0.7500\n",
      "Epoch 786/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1324 - acc: 0.8488 - val_loss: 0.1721 - val_acc: 0.7500\n",
      "Epoch 787/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1379 - acc: 0.8225 - val_loss: 0.1717 - val_acc: 0.7500\n",
      "Epoch 788/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1344 - acc: 0.8302 - val_loss: 0.1719 - val_acc: 0.7500\n",
      "Epoch 789/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1379 - acc: 0.8364 - val_loss: 0.1713 - val_acc: 0.7500\n",
      "Epoch 790/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1416 - acc: 0.8256 - val_loss: 0.1708 - val_acc: 0.7500\n",
      "Epoch 791/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1396 - acc: 0.8318 - val_loss: 0.1707 - val_acc: 0.7500\n",
      "Epoch 792/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1306 - acc: 0.8534 - val_loss: 0.1718 - val_acc: 0.7500\n",
      "Epoch 793/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1363 - acc: 0.8349 - val_loss: 0.1717 - val_acc: 0.7500\n",
      "Epoch 794/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1361 - acc: 0.8503 - val_loss: 0.1711 - val_acc: 0.7361\n",
      "Epoch 795/1000\n",
      "648/648 [==============================] - 0s 133us/step - loss: 0.1390 - acc: 0.8395 - val_loss: 0.1715 - val_acc: 0.7500\n",
      "Epoch 796/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1341 - acc: 0.8457 - val_loss: 0.1715 - val_acc: 0.7500\n",
      "Epoch 797/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1359 - acc: 0.8349 - val_loss: 0.1708 - val_acc: 0.7500\n",
      "Epoch 798/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1336 - acc: 0.8457 - val_loss: 0.1712 - val_acc: 0.7500\n",
      "Epoch 799/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1344 - acc: 0.8426 - val_loss: 0.1707 - val_acc: 0.7500\n",
      "Epoch 800/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1340 - acc: 0.8349 - val_loss: 0.1707 - val_acc: 0.7500\n",
      "Epoch 801/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1341 - acc: 0.8472 - val_loss: 0.1718 - val_acc: 0.7639\n",
      "Epoch 802/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1357 - acc: 0.8410 - val_loss: 0.1714 - val_acc: 0.7361\n",
      "Epoch 803/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1377 - acc: 0.8256 - val_loss: 0.1722 - val_acc: 0.7639\n",
      "Epoch 804/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1372 - acc: 0.8380 - val_loss: 0.1720 - val_acc: 0.7222\n",
      "Epoch 805/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1355 - acc: 0.8441 - val_loss: 0.1726 - val_acc: 0.7500\n",
      "Epoch 806/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1324 - acc: 0.8410 - val_loss: 0.1726 - val_acc: 0.7500\n",
      "Epoch 807/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1397 - acc: 0.8426 - val_loss: 0.1726 - val_acc: 0.7500\n",
      "Epoch 808/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1328 - acc: 0.8395 - val_loss: 0.1724 - val_acc: 0.7361\n",
      "Epoch 809/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1359 - acc: 0.8349 - val_loss: 0.1728 - val_acc: 0.7361\n",
      "Epoch 810/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1351 - acc: 0.8272 - val_loss: 0.1732 - val_acc: 0.7361\n",
      "Epoch 811/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1366 - acc: 0.8287 - val_loss: 0.1734 - val_acc: 0.7361\n",
      "Epoch 812/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1376 - acc: 0.8364 - val_loss: 0.1731 - val_acc: 0.7361\n",
      "Epoch 813/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1354 - acc: 0.8302 - val_loss: 0.1732 - val_acc: 0.7361\n",
      "Epoch 814/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1384 - acc: 0.8287 - val_loss: 0.1751 - val_acc: 0.7778\n",
      "Epoch 815/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1387 - acc: 0.8241 - val_loss: 0.1728 - val_acc: 0.7361\n",
      "Epoch 816/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 0.1335 - acc: 0.8472 - val_loss: 0.1740 - val_acc: 0.7500\n",
      "Epoch 817/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1355 - acc: 0.8441 - val_loss: 0.1734 - val_acc: 0.7361\n",
      "Epoch 818/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1370 - acc: 0.8380 - val_loss: 0.1731 - val_acc: 0.7361\n",
      "Epoch 819/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1375 - acc: 0.8364 - val_loss: 0.1733 - val_acc: 0.7500\n",
      "Epoch 820/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1367 - acc: 0.8256 - val_loss: 0.1723 - val_acc: 0.7361\n",
      "Epoch 821/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1316 - acc: 0.8534 - val_loss: 0.1725 - val_acc: 0.7361\n",
      "Epoch 822/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1402 - acc: 0.8241 - val_loss: 0.1733 - val_acc: 0.7639\n",
      "Epoch 823/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1344 - acc: 0.8318 - val_loss: 0.1727 - val_acc: 0.7500\n",
      "Epoch 824/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1435 - acc: 0.8179 - val_loss: 0.1735 - val_acc: 0.7500\n",
      "Epoch 825/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1352 - acc: 0.8457 - val_loss: 0.1747 - val_acc: 0.7500\n",
      "Epoch 826/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1331 - acc: 0.8472 - val_loss: 0.1736 - val_acc: 0.7361\n",
      "Epoch 827/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1299 - acc: 0.8534 - val_loss: 0.1740 - val_acc: 0.7500\n",
      "Epoch 828/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1409 - acc: 0.8349 - val_loss: 0.1753 - val_acc: 0.7778\n",
      "Epoch 829/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1397 - acc: 0.8225 - val_loss: 0.1733 - val_acc: 0.7500\n",
      "Epoch 830/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1312 - acc: 0.8580 - val_loss: 0.1743 - val_acc: 0.7639\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 98us/step - loss: 0.1374 - acc: 0.8333 - val_loss: 0.1735 - val_acc: 0.7500\n",
      "Epoch 832/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1328 - acc: 0.8380 - val_loss: 0.1727 - val_acc: 0.7500\n",
      "Epoch 833/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1313 - acc: 0.8410 - val_loss: 0.1723 - val_acc: 0.7361\n",
      "Epoch 834/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1291 - acc: 0.8426 - val_loss: 0.1727 - val_acc: 0.7500\n",
      "Epoch 835/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1405 - acc: 0.8349 - val_loss: 0.1729 - val_acc: 0.7639\n",
      "Epoch 836/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1387 - acc: 0.8333 - val_loss: 0.1732 - val_acc: 0.7500\n",
      "Epoch 837/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1385 - acc: 0.8349 - val_loss: 0.1737 - val_acc: 0.7500\n",
      "Epoch 838/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1338 - acc: 0.8410 - val_loss: 0.1735 - val_acc: 0.7500\n",
      "Epoch 839/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1310 - acc: 0.8519 - val_loss: 0.1738 - val_acc: 0.7361\n",
      "Epoch 840/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1374 - acc: 0.8256 - val_loss: 0.1739 - val_acc: 0.7361\n",
      "Epoch 841/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1347 - acc: 0.8380 - val_loss: 0.1749 - val_acc: 0.7500\n",
      "Epoch 842/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1313 - acc: 0.8472 - val_loss: 0.1747 - val_acc: 0.7500\n",
      "Epoch 843/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1331 - acc: 0.8364 - val_loss: 0.1743 - val_acc: 0.7500\n",
      "Epoch 844/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1303 - acc: 0.8426 - val_loss: 0.1750 - val_acc: 0.7361\n",
      "Epoch 845/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1339 - acc: 0.8395 - val_loss: 0.1741 - val_acc: 0.7361\n",
      "Epoch 846/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1324 - acc: 0.8472 - val_loss: 0.1737 - val_acc: 0.7500\n",
      "Epoch 847/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1355 - acc: 0.8380 - val_loss: 0.1736 - val_acc: 0.7500\n",
      "Epoch 848/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1333 - acc: 0.8395 - val_loss: 0.1734 - val_acc: 0.7361\n",
      "Epoch 849/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1417 - acc: 0.8318 - val_loss: 0.1742 - val_acc: 0.7500\n",
      "Epoch 850/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1400 - acc: 0.8225 - val_loss: 0.1738 - val_acc: 0.7500\n",
      "Epoch 851/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1302 - acc: 0.8426 - val_loss: 0.1753 - val_acc: 0.7500\n",
      "Epoch 852/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1365 - acc: 0.8302 - val_loss: 0.1740 - val_acc: 0.7500\n",
      "Epoch 853/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1316 - acc: 0.8364 - val_loss: 0.1743 - val_acc: 0.7361\n",
      "Epoch 854/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1348 - acc: 0.8380 - val_loss: 0.1749 - val_acc: 0.7500\n",
      "Epoch 855/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1359 - acc: 0.8349 - val_loss: 0.1755 - val_acc: 0.7500\n",
      "Epoch 856/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1330 - acc: 0.8426 - val_loss: 0.1751 - val_acc: 0.7361\n",
      "Epoch 857/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1347 - acc: 0.8457 - val_loss: 0.1749 - val_acc: 0.7361\n",
      "Epoch 858/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1314 - acc: 0.8426 - val_loss: 0.1739 - val_acc: 0.7500\n",
      "Epoch 859/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1299 - acc: 0.8549 - val_loss: 0.1747 - val_acc: 0.7500\n",
      "Epoch 860/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1302 - acc: 0.8519 - val_loss: 0.1743 - val_acc: 0.7500\n",
      "Epoch 861/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1285 - acc: 0.8565 - val_loss: 0.1755 - val_acc: 0.7500\n",
      "Epoch 862/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1358 - acc: 0.8457 - val_loss: 0.1756 - val_acc: 0.7361\n",
      "Epoch 863/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1294 - acc: 0.8565 - val_loss: 0.1766 - val_acc: 0.7361\n",
      "Epoch 864/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1321 - acc: 0.8488 - val_loss: 0.1762 - val_acc: 0.7361\n",
      "Epoch 865/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1341 - acc: 0.8426 - val_loss: 0.1761 - val_acc: 0.7639\n",
      "Epoch 866/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1270 - acc: 0.8503 - val_loss: 0.1769 - val_acc: 0.7361\n",
      "Epoch 867/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1288 - acc: 0.8627 - val_loss: 0.1756 - val_acc: 0.7361\n",
      "Epoch 868/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1302 - acc: 0.8565 - val_loss: 0.1760 - val_acc: 0.7500\n",
      "Epoch 869/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1340 - acc: 0.8333 - val_loss: 0.1757 - val_acc: 0.7500\n",
      "Epoch 870/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1364 - acc: 0.8256 - val_loss: 0.1746 - val_acc: 0.7500\n",
      "Epoch 871/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1343 - acc: 0.8488 - val_loss: 0.1748 - val_acc: 0.7500\n",
      "Epoch 872/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1325 - acc: 0.8457 - val_loss: 0.1740 - val_acc: 0.7500\n",
      "Epoch 873/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1365 - acc: 0.8225 - val_loss: 0.1750 - val_acc: 0.7639\n",
      "Epoch 874/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1351 - acc: 0.8410 - val_loss: 0.1745 - val_acc: 0.7361\n",
      "Epoch 875/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1336 - acc: 0.8472 - val_loss: 0.1741 - val_acc: 0.7222\n",
      "Epoch 876/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1310 - acc: 0.8426 - val_loss: 0.1757 - val_acc: 0.7361\n",
      "Epoch 877/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1358 - acc: 0.8380 - val_loss: 0.1758 - val_acc: 0.7222\n",
      "Epoch 878/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1313 - acc: 0.8657 - val_loss: 0.1773 - val_acc: 0.7639\n",
      "Epoch 879/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1346 - acc: 0.8318 - val_loss: 0.1769 - val_acc: 0.7222\n",
      "Epoch 880/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1387 - acc: 0.8441 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 881/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1350 - acc: 0.8410 - val_loss: 0.1766 - val_acc: 0.7222\n",
      "Epoch 882/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1337 - acc: 0.8472 - val_loss: 0.1752 - val_acc: 0.7361\n",
      "Epoch 883/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1359 - acc: 0.8457 - val_loss: 0.1755 - val_acc: 0.7500\n",
      "Epoch 884/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1326 - acc: 0.8426 - val_loss: 0.1752 - val_acc: 0.7222\n",
      "Epoch 885/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1276 - acc: 0.8611 - val_loss: 0.1772 - val_acc: 0.7500\n",
      "Epoch 886/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1295 - acc: 0.8534 - val_loss: 0.1759 - val_acc: 0.7361\n",
      "Epoch 887/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1316 - acc: 0.8395 - val_loss: 0.1768 - val_acc: 0.7500\n",
      "Epoch 888/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1270 - acc: 0.8457 - val_loss: 0.1766 - val_acc: 0.7222\n",
      "Epoch 889/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1284 - acc: 0.8627 - val_loss: 0.1768 - val_acc: 0.7361\n",
      "Epoch 890/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 112us/step - loss: 0.1301 - acc: 0.8565 - val_loss: 0.1773 - val_acc: 0.7361\n",
      "Epoch 891/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1309 - acc: 0.8519 - val_loss: 0.1782 - val_acc: 0.7361\n",
      "Epoch 892/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1350 - acc: 0.8380 - val_loss: 0.1779 - val_acc: 0.7361\n",
      "Epoch 893/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1319 - acc: 0.8488 - val_loss: 0.1778 - val_acc: 0.7222\n",
      "Epoch 894/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1281 - acc: 0.8688 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 895/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1321 - acc: 0.8472 - val_loss: 0.1771 - val_acc: 0.7222\n",
      "Epoch 896/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1258 - acc: 0.8596 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 897/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1283 - acc: 0.8503 - val_loss: 0.1773 - val_acc: 0.7639\n",
      "Epoch 898/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1325 - acc: 0.8472 - val_loss: 0.1771 - val_acc: 0.7500\n",
      "Epoch 899/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1279 - acc: 0.8441 - val_loss: 0.1778 - val_acc: 0.7639\n",
      "Epoch 900/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1352 - acc: 0.8472 - val_loss: 0.1760 - val_acc: 0.7222\n",
      "Epoch 901/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1310 - acc: 0.8472 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 902/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1282 - acc: 0.8580 - val_loss: 0.1772 - val_acc: 0.7361\n",
      "Epoch 903/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1269 - acc: 0.8549 - val_loss: 0.1767 - val_acc: 0.7361\n",
      "Epoch 904/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1303 - acc: 0.8457 - val_loss: 0.1766 - val_acc: 0.7361\n",
      "Epoch 905/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1300 - acc: 0.8441 - val_loss: 0.1764 - val_acc: 0.7500\n",
      "Epoch 906/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1334 - acc: 0.8534 - val_loss: 0.1760 - val_acc: 0.7500\n",
      "Epoch 907/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1266 - acc: 0.8627 - val_loss: 0.1766 - val_acc: 0.7500\n",
      "Epoch 908/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1234 - acc: 0.8657 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 909/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1318 - acc: 0.8519 - val_loss: 0.1760 - val_acc: 0.7500\n",
      "Epoch 910/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1301 - acc: 0.8441 - val_loss: 0.1763 - val_acc: 0.7222\n",
      "Epoch 911/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1280 - acc: 0.8488 - val_loss: 0.1785 - val_acc: 0.7500\n",
      "Epoch 912/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1301 - acc: 0.8549 - val_loss: 0.1766 - val_acc: 0.7222\n",
      "Epoch 913/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1284 - acc: 0.8580 - val_loss: 0.1769 - val_acc: 0.7222\n",
      "Epoch 914/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1259 - acc: 0.8549 - val_loss: 0.1767 - val_acc: 0.7222\n",
      "Epoch 915/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1276 - acc: 0.8519 - val_loss: 0.1772 - val_acc: 0.7500\n",
      "Epoch 916/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1308 - acc: 0.8534 - val_loss: 0.1769 - val_acc: 0.7222\n",
      "Epoch 917/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1244 - acc: 0.8657 - val_loss: 0.1772 - val_acc: 0.7361\n",
      "Epoch 918/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1339 - acc: 0.8364 - val_loss: 0.1766 - val_acc: 0.7222\n",
      "Epoch 919/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1275 - acc: 0.8596 - val_loss: 0.1767 - val_acc: 0.7361\n",
      "Epoch 920/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1254 - acc: 0.8596 - val_loss: 0.1780 - val_acc: 0.7778\n",
      "Epoch 921/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1321 - acc: 0.8627 - val_loss: 0.1765 - val_acc: 0.7639\n",
      "Epoch 922/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1288 - acc: 0.8441 - val_loss: 0.1770 - val_acc: 0.7778\n",
      "Epoch 923/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1251 - acc: 0.8596 - val_loss: 0.1772 - val_acc: 0.7361\n",
      "Epoch 924/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1273 - acc: 0.8503 - val_loss: 0.1767 - val_acc: 0.7500\n",
      "Epoch 925/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1318 - acc: 0.8395 - val_loss: 0.1764 - val_acc: 0.7500\n",
      "Epoch 926/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1288 - acc: 0.8472 - val_loss: 0.1760 - val_acc: 0.7500\n",
      "Epoch 927/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1249 - acc: 0.8627 - val_loss: 0.1771 - val_acc: 0.7778\n",
      "Epoch 928/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1236 - acc: 0.8596 - val_loss: 0.1775 - val_acc: 0.7222\n",
      "Epoch 929/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1298 - acc: 0.8472 - val_loss: 0.1781 - val_acc: 0.7222\n",
      "Epoch 930/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1225 - acc: 0.8673 - val_loss: 0.1773 - val_acc: 0.7361\n",
      "Epoch 931/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1352 - acc: 0.8472 - val_loss: 0.1758 - val_acc: 0.7222\n",
      "Epoch 932/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1291 - acc: 0.8642 - val_loss: 0.1761 - val_acc: 0.7222\n",
      "Epoch 933/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1291 - acc: 0.8426 - val_loss: 0.1775 - val_acc: 0.7222\n",
      "Epoch 934/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1260 - acc: 0.8596 - val_loss: 0.1783 - val_acc: 0.7500\n",
      "Epoch 935/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1331 - acc: 0.8488 - val_loss: 0.1778 - val_acc: 0.7361\n",
      "Epoch 936/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1289 - acc: 0.8549 - val_loss: 0.1777 - val_acc: 0.7361\n",
      "Epoch 937/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1292 - acc: 0.8611 - val_loss: 0.1777 - val_acc: 0.7222\n",
      "Epoch 938/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1272 - acc: 0.8627 - val_loss: 0.1785 - val_acc: 0.7778\n",
      "Epoch 939/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1309 - acc: 0.8596 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 940/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1308 - acc: 0.8549 - val_loss: 0.1781 - val_acc: 0.7917\n",
      "Epoch 941/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1267 - acc: 0.8657 - val_loss: 0.1781 - val_acc: 0.7500\n",
      "Epoch 942/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1285 - acc: 0.8503 - val_loss: 0.1779 - val_acc: 0.7361\n",
      "Epoch 943/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1240 - acc: 0.8642 - val_loss: 0.1787 - val_acc: 0.7778\n",
      "Epoch 944/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1265 - acc: 0.8642 - val_loss: 0.1778 - val_acc: 0.7222\n",
      "Epoch 945/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1303 - acc: 0.8410 - val_loss: 0.1780 - val_acc: 0.7639\n",
      "Epoch 946/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1251 - acc: 0.8611 - val_loss: 0.1768 - val_acc: 0.7500\n",
      "Epoch 947/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1331 - acc: 0.8395 - val_loss: 0.1774 - val_acc: 0.7639\n",
      "Epoch 948/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1358 - acc: 0.8441 - val_loss: 0.1771 - val_acc: 0.7222\n",
      "Epoch 949/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 106us/step - loss: 0.1275 - acc: 0.8565 - val_loss: 0.1762 - val_acc: 0.7222\n",
      "Epoch 950/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1267 - acc: 0.8627 - val_loss: 0.1763 - val_acc: 0.7361\n",
      "Epoch 951/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1279 - acc: 0.8519 - val_loss: 0.1766 - val_acc: 0.7500\n",
      "Epoch 952/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1258 - acc: 0.8673 - val_loss: 0.1763 - val_acc: 0.7500\n",
      "Epoch 953/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1217 - acc: 0.8657 - val_loss: 0.1773 - val_acc: 0.7500\n",
      "Epoch 954/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1217 - acc: 0.8580 - val_loss: 0.1762 - val_acc: 0.7361\n",
      "Epoch 955/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1298 - acc: 0.8503 - val_loss: 0.1771 - val_acc: 0.7361\n",
      "Epoch 956/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1212 - acc: 0.8627 - val_loss: 0.1766 - val_acc: 0.7361\n",
      "Epoch 957/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1242 - acc: 0.8642 - val_loss: 0.1776 - val_acc: 0.7500\n",
      "Epoch 958/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1264 - acc: 0.8565 - val_loss: 0.1771 - val_acc: 0.7361\n",
      "Epoch 959/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1222 - acc: 0.8673 - val_loss: 0.1776 - val_acc: 0.7361\n",
      "Epoch 960/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1225 - acc: 0.8657 - val_loss: 0.1772 - val_acc: 0.7222\n",
      "Epoch 961/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1279 - acc: 0.8688 - val_loss: 0.1776 - val_acc: 0.7500\n",
      "Epoch 962/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1274 - acc: 0.8580 - val_loss: 0.1770 - val_acc: 0.7361\n",
      "Epoch 963/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1219 - acc: 0.8642 - val_loss: 0.1771 - val_acc: 0.7361\n",
      "Epoch 964/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1272 - acc: 0.8565 - val_loss: 0.1774 - val_acc: 0.7361\n",
      "Epoch 965/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1281 - acc: 0.8503 - val_loss: 0.1782 - val_acc: 0.7361\n",
      "Epoch 966/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1243 - acc: 0.8627 - val_loss: 0.1784 - val_acc: 0.7222\n",
      "Epoch 967/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1298 - acc: 0.8549 - val_loss: 0.1788 - val_acc: 0.7361\n",
      "Epoch 968/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1234 - acc: 0.8565 - val_loss: 0.1799 - val_acc: 0.7500\n",
      "Epoch 969/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1290 - acc: 0.8565 - val_loss: 0.1788 - val_acc: 0.7361\n",
      "Epoch 970/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1164 - acc: 0.8765 - val_loss: 0.1789 - val_acc: 0.7222\n",
      "Epoch 971/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1256 - acc: 0.8642 - val_loss: 0.1789 - val_acc: 0.7500\n",
      "Epoch 972/1000\n",
      "648/648 [==============================] - 0s 153us/step - loss: 0.1287 - acc: 0.8534 - val_loss: 0.1778 - val_acc: 0.7361\n",
      "Epoch 973/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1220 - acc: 0.8704 - val_loss: 0.1789 - val_acc: 0.7361\n",
      "Epoch 974/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1265 - acc: 0.8657 - val_loss: 0.1789 - val_acc: 0.7361\n",
      "Epoch 975/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1254 - acc: 0.8627 - val_loss: 0.1788 - val_acc: 0.7361\n",
      "Epoch 976/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1318 - acc: 0.8380 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 977/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1233 - acc: 0.8673 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 978/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1262 - acc: 0.8565 - val_loss: 0.1795 - val_acc: 0.7222\n",
      "Epoch 979/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1242 - acc: 0.8627 - val_loss: 0.1776 - val_acc: 0.7361\n",
      "Epoch 980/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1220 - acc: 0.8519 - val_loss: 0.1773 - val_acc: 0.7361\n",
      "Epoch 981/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1262 - acc: 0.8503 - val_loss: 0.1790 - val_acc: 0.7500\n",
      "Epoch 982/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1268 - acc: 0.8519 - val_loss: 0.1801 - val_acc: 0.7361\n",
      "Epoch 983/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1286 - acc: 0.8534 - val_loss: 0.1779 - val_acc: 0.7361\n",
      "Epoch 984/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1268 - acc: 0.8580 - val_loss: 0.1790 - val_acc: 0.7361\n",
      "Epoch 985/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1226 - acc: 0.8673 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 986/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1261 - acc: 0.8580 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 987/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1228 - acc: 0.8735 - val_loss: 0.1790 - val_acc: 0.7361\n",
      "Epoch 988/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1216 - acc: 0.8704 - val_loss: 0.1789 - val_acc: 0.7361\n",
      "Epoch 989/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1207 - acc: 0.8688 - val_loss: 0.1785 - val_acc: 0.7361\n",
      "Epoch 990/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1264 - acc: 0.8472 - val_loss: 0.1793 - val_acc: 0.7500\n",
      "Epoch 991/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1244 - acc: 0.8704 - val_loss: 0.1799 - val_acc: 0.7500\n",
      "Epoch 992/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1220 - acc: 0.8580 - val_loss: 0.1790 - val_acc: 0.7500\n",
      "Epoch 993/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1169 - acc: 0.8688 - val_loss: 0.1777 - val_acc: 0.7500\n",
      "Epoch 994/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1222 - acc: 0.8611 - val_loss: 0.1774 - val_acc: 0.7639\n",
      "Epoch 995/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1279 - acc: 0.8642 - val_loss: 0.1789 - val_acc: 0.7500\n",
      "Epoch 996/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1174 - acc: 0.8719 - val_loss: 0.1779 - val_acc: 0.7361\n",
      "Epoch 997/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1243 - acc: 0.8565 - val_loss: 0.1779 - val_acc: 0.7639\n",
      "Epoch 998/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1261 - acc: 0.8704 - val_loss: 0.1776 - val_acc: 0.7500\n",
      "Epoch 999/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1272 - acc: 0.8627 - val_loss: 0.1776 - val_acc: 0.7361\n",
      "Epoch 1000/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1208 - acc: 0.8673 - val_loss: 0.1774 - val_acc: 0.7361\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, validation_split=0.1, epochs=1000,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 41us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 76.11% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a27e00eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a280d7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(x_test)\n",
    "y_test= [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: yes</th>\n",
       "      <th>Pred: no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True:yes</th>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: no</th>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred: yes  Pred: no\n",
       "True:yes         90        25\n",
       "True: no         18        47"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                   index=['True:yes', 'True: no'],\n",
    "                   columns=['Pred: yes', 'Pred: no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1New.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_test_new',x_test)\n",
    "np.save('y_test_new',y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
