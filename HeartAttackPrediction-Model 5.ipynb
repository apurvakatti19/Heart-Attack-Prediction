{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected2D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.MinMaxScaler(feature_range=(0,1))\n",
    "#sb.set(rc={'figure.figsize':(10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['id', 'ccf', 'age', 'sex', 'painLocation', 'painExcertion', 'painResting', 'pncaden', 'chestPainType',\n",
    "        'restingBP','hyperTension', 'cholestrol', 'smoker', 'noOfCigarette' , 'smokingYears', 'bloodSugar',\n",
    "        'historyOfDiabetes', 'historyOfHA', 'restingECG', 'ekgmo', 'ekgday', 'ekgyr', 'dig',\n",
    "        'prop', 'nitr', 'pro' ,'diuretic', 'proto', 'stressTestDuration', 'stressTestSTTime', 'stressTestMet',\n",
    "        'stressTestMaxHR', 'stressTestRestingHR', 'stressTestMaxFirstBPS','stressTestMaxSecondBPS', 'dummy',\n",
    "        'stressTestRestingBP', 'exerciseAngina', 'xhypo', 'STDepressionExercise', 'STDepressionSlope',\n",
    "        'rldv5','rldv5e', 'coloredVesselsFluroscopy', 'restckm','exerckm','restef', 'restwm', 'exeref', 'exerwm',\n",
    "        'heartWallDamage', 'thalsev', 'thalpul', 'earlobe', 'cmo', 'cday', 'cyr', 'output', 'lmt',\n",
    " 'ladprox', 'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4',\n",
    " 'lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop=['id', 'ccf', 'painExcertion', 'painResting', 'pncaden','historyOfDiabetes', 'ekgmo', 'ekgday',\n",
    "               'ekgyr', 'dig', 'prop', 'nitr', 'pro' ,'diuretic', 'proto','stressTestMet', 'dummy', 'xhypo',\n",
    "               'rldv5','rldv5e','restckm','exerckm','restef', 'restwm', 'exeref','exerwm', 'thalsev', 'thalpul',\n",
    "               'earlobe', 'cmo', 'cday', 'cyr', 'lmt', 'ladprox', 'laddist', 'diag','cxmain', 'ramus', 'om1', 'om2',\n",
    "               'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4','lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting and Preprocessing the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleveland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedCleveland.txt', 'w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clevelandData=pd.read_csv(\"processedCleveland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "clevelandData=clevelandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hungarian.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedHungarian.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarianData=pd.read_csv(\"processedHungarian.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "hungarianData=hungarianData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('switzerland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedSwitzerland.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "switzerlandData=pd.read_csv(\"processedSwitzerland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "switzerlandData=switzerlandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long-beach-va.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedLongBeach.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "longBeachData=pd.read_csv(\"processedLongBeach.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "longBeachData=longBeachData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[clevelandData,hungarianData,longBeachData,switzerlandData]\n",
    "data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 76 columns):\n",
      "id                          900 non-null object\n",
      "ccf                         900 non-null object\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "painExcertion               900 non-null float64\n",
      "painResting                 900 non-null float64\n",
      "pncaden                     900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfDiabetes           900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "ekgmo                       900 non-null float64\n",
      "ekgday                      900 non-null float64\n",
      "ekgyr                       900 non-null object\n",
      "dig                         900 non-null float64\n",
      "prop                        900 non-null float64\n",
      "nitr                        900 non-null object\n",
      "pro                         900 non-null object\n",
      "diuretic                    900 non-null float64\n",
      "proto                       900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMet               900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "dummy                       900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "xhypo                       900 non-null object\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "rldv5                       900 non-null object\n",
      "rldv5e                      900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "restckm                     900 non-null object\n",
      "exerckm                     900 non-null float64\n",
      "restef                      900 non-null float64\n",
      "restwm                      900 non-null float64\n",
      "exeref                      900 non-null float64\n",
      "exerwm                      900 non-null float64\n",
      "heartWallDamage             900 non-null float64\n",
      "thalsev                     900 non-null float64\n",
      "thalpul                     900 non-null float64\n",
      "earlobe                     900 non-null object\n",
      "cmo                         900 non-null float64\n",
      "cday                        900 non-null float64\n",
      "cyr                         900 non-null float64\n",
      "output                      900 non-null float64\n",
      "lmt                         900 non-null float64\n",
      "ladprox                     900 non-null float64\n",
      "laddist                     900 non-null float64\n",
      "diag                        900 non-null float64\n",
      "cxmain                      900 non-null float64\n",
      "ramus                       900 non-null float64\n",
      "om1                         900 non-null float64\n",
      "om2                         900 non-null float64\n",
      "rcaprox                     900 non-null float64\n",
      "rcadist                     900 non-null float64\n",
      "lvx1                        900 non-null float64\n",
      "lvx2                        900 non-null object\n",
      "lvx3                        900 non-null float64\n",
      "lvx4                        900 non-null object\n",
      "lvf                         900 non-null object\n",
      "cathef                      900 non-null object\n",
      "junk                        900 non-null float64\n",
      "name                        900 non-null object\n",
      "dtypes: float64(56), object(20)\n",
      "memory usage: 541.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>painExcertion</th>\n",
       "      <th>painResting</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>...</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx1</th>\n",
       "      <th>lvx2</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "      <th>cathef</th>\n",
       "      <th>junk</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ccf age  sex  painLocation  painExcertion  painResting  pncaden  \\\n",
       "0  1   0  63  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "1  2   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "2  3   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "3  4   0  37  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "4  6   0  41  0.0          -9.0           -9.0         -9.0     -9.0   \n",
       "\n",
       "  chestPainType restingBP  ...  rcaprox  rcadist lvx1  lvx2  lvx3  lvx4  lvf  \\\n",
       "0             1       145  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "1             4       160  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "2             4       120  ...      2.0      2.0  1.0     1   1.0     7    3   \n",
       "3             3       130  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "4             2       130  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "\n",
       "   cathef  junk  name  \n",
       "0      -9  -9.0  name  \n",
       "1      -9  -9.0  name  \n",
       "2      -9  -9.0  name  \n",
       "3      -9  -9.0  name  \n",
       "4      -9  -9.0  name  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columnsToDrop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>...</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex  painLocation chestPainType restingBP hyperTension  cholestrol  \\\n",
       "0  63  1.0          -9.0             1       145            1       233.0   \n",
       "1  67  1.0          -9.0             4       160            1       286.0   \n",
       "2  67  1.0          -9.0             4       120            1       229.0   \n",
       "3  37  1.0          -9.0             3       130            0       250.0   \n",
       "4  41  0.0          -9.0             2       130            1       204.0   \n",
       "\n",
       "  smoker  noOfCigarette  smokingYears   ...    stressTestRestingHR  \\\n",
       "0     -9           50.0          20.0   ...                   60.0   \n",
       "1     -9           40.0          40.0   ...                   64.0   \n",
       "2     -9           20.0          35.0   ...                   78.0   \n",
       "3     -9            0.0           0.0   ...                   84.0   \n",
       "4     -9            0.0           0.0   ...                   71.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    90.0                 85.0   \n",
       "1                  160.0                    90.0                 90.0   \n",
       "2                  140.0                    80.0                 80.0   \n",
       "3                  195.0                    68.0                 78.0   \n",
       "4                  160.0                    74.0                 86.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  STDepressionSlope  \\\n",
       "0             0.0                   2.3                3.0   \n",
       "1             1.0                   1.5                2.0   \n",
       "2             1.0                   2.6                2.0   \n",
       "3             0.0                   3.5                3.0   \n",
       "4             0.0                   1.4                1.0   \n",
       "\n",
       "   coloredVesselsFluroscopy  heartWallDamage  output  \n",
       "0                         0              6.0     0.0  \n",
       "1                         3              3.0     2.0  \n",
       "2                         2              7.0     1.0  \n",
       "3                         0              3.0     0.0  \n",
       "4                         0              3.0     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "heartWallDamage             900 non-null float64\n",
      "output                      900 non-null float64\n",
      "dtypes: float64(20), object(6)\n",
      "memory usage: 189.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPainLocation(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>0):\n",
    "            if(columns[2]==1):\n",
    "                return 0\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceByMean(columns,mean):\n",
    "    if(columns[0]<1):\n",
    "        return int(mean)\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHypertension(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>120):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCholestrol(columns):\n",
    "    if(columns[0]<=200):\n",
    "        return 0\n",
    "    elif(columns[0]<=239):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSmoking(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(int(columns[1])>0):\n",
    "            return 1\n",
    "        elif(int(columns[1])==0):\n",
    "            return 0\n",
    "        if(int(columns[2])>0):\n",
    "            return 1\n",
    "        elif(int(columns[2])==0):\n",
    "            return 0\n",
    "    return int(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDummyCategory(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRestingECG(columns):\n",
    "    if(columns[0]==2):\n",
    "        return 1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processstressTestSTTime(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processExerciseAgnia(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]==1):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSTDepressionSlope(columns):\n",
    "    if(columns[0]<1):\n",
    "        return -1\n",
    "    if(columns[0]==1):\n",
    "        return 1\n",
    "    if(columns[0]==2):\n",
    "        return 0\n",
    "    if(columns[0]==3):\n",
    "        return 2\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processcoloredVesselsFluroscopy(columns):\n",
    "    if(columns[0]==-9 or columns[0]==9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHeartWallDamage(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    if(columns[0]<=3):\n",
    "        return 0\n",
    "    if(columns[0]<=6):\n",
    "        return 2\n",
    "    if(columns[0]==7):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(columns):\n",
    "    if(columns[0]>1):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age']=pd.to_numeric(data['age'])\n",
    "d=data[data.age !=-9]\n",
    "d=d[d.age != 0]\n",
    "mean=d['age'].mean()\n",
    "mean=data['age'].mean()\n",
    "data['age']=data[['age']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex']=pd.to_numeric(data['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['painLocation']=data[['painLocation','output','bloodSugar']].apply(processPainLocation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['chestPainType']=pd.to_numeric(data['chestPainType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['chestPainType'], prefix='chestPainType')\n",
    "data=data.drop('chestPainType',axis=1)\n",
    "data=data.join(dummyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingBP']=pd.to_numeric(data['restingBP'])\n",
    "d=data[data.restingBP !=-9]\n",
    "d=d[d.restingBP != 0]\n",
    "mean=d['restingBP'].mean()\n",
    "data['restingBP']=data[['restingBP']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hyperTension']=pd.to_numeric(data['hyperTension'])\n",
    "data['hyperTension']=data[['hyperTension','restingBP']].apply(processHypertension,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=pd.to_numeric(data['cholestrol'])\n",
    "d=data[data.cholestrol !=-9]\n",
    "d=d[d.cholestrol != 0]\n",
    "mean=d['cholestrol'].mean()\n",
    "data['cholestrol']=data[['cholestrol']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=data[['cholestrol']].apply(processCholestrol,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['cholestrol'], prefix='cholestrol')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('cholestrol',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=pd.to_numeric(data['smoker'])\n",
    "data['smoker']=data[['smoker','smokingYears','noOfCigarette']].apply(processSmoking,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=data[['smoker']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['smoker'], prefix='smoker')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('smoker',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bloodSugar']=pd.to_numeric(data['bloodSugar'])\n",
    "data['bloodSugar']=data[['bloodSugar']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.bloodSugar==40].index[0],'bloodSugar']=int(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['bloodSugar'], prefix='bloodSugar')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('bloodSugar',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['historyOfHA']=pd.to_numeric(data['historyOfHA'])\n",
    "data['historyOfHA']=data[['historyOfHA']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['historyOfHA'], prefix='historyOfHA')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('historyOfHA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingECG']=pd.to_numeric(data['restingECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==0.4].index[0],'restingECG']=int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['restingECG'], prefix='restingECG')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('restingECG',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['restingECG']=data[['restingECG']].apply(processRestingECG,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestDuration']=pd.to_numeric(data['stressTestDuration'])\n",
    "data['stressTestDuration']=data[['stressTestDuration']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestSTTime']=pd.to_numeric(data['stressTestSTTime'])\n",
    "data['stressTestSTTime']=data[['stressTestSTTime']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxHR']=pd.to_numeric(data['stressTestMaxHR'])\n",
    "d=data[data.stressTestMaxHR !=-9]\n",
    "mean=d['stressTestMaxHR'].mean()\n",
    "data['stressTestMaxHR']=data[['stressTestMaxHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxHR==8105].index[0],'stressTestMaxHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingHR']=pd.to_numeric(data['stressTestRestingHR'])\n",
    "d=data[data.stressTestRestingHR !=-9]\n",
    "mean=d['stressTestRestingHR'].mean()\n",
    "data['stressTestRestingHR']=data[['stressTestRestingHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingHR==1.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==37.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==39.0].index[0],'stressTestRestingHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxFirstBPS']=pd.to_numeric(data['stressTestMaxFirstBPS'])\n",
    "d=data[data.stressTestMaxFirstBPS !=-9]\n",
    "mean=d['stressTestMaxFirstBPS'].mean()\n",
    "data['stressTestMaxFirstBPS']=data[['stressTestMaxFirstBPS']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxSecondBPS']=pd.to_numeric(data['stressTestMaxSecondBPS'])\n",
    "d=data[data.stressTestMaxSecondBPS !=-9]\n",
    "mean=d['stressTestMaxSecondBPS'].mean()\n",
    "data['stressTestMaxSecondBPS']=data[['stressTestMaxSecondBPS']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxSecondBPS==1.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==11.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==26.0].index[0],'stressTestMaxSecondBPS']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingBP']=pd.to_numeric(data['stressTestRestingBP'])\n",
    "d=data[data.stressTestRestingBP !=-9]\n",
    "mean=d['stressTestRestingBP'].mean()\n",
    "data['stressTestRestingBP']=data[['stressTestRestingBP']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingBP==1018].index[0],'stressTestRestingBP']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exerciseAngina']=pd.to_numeric(data['exerciseAngina'])\n",
    "data['exerciseAngina']=data[['exerciseAngina','painLocation']].apply(processExerciseAgnia,axis=1)\n",
    "data.at[data[data.exerciseAngina==101881].index[0],'exerciseAngina']=int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionExercise']=pd.to_numeric(data['STDepressionExercise'])\n",
    "d=data[data.STDepressionExercise !=-9]\n",
    "mean=d['STDepressionExercise'].mean()\n",
    "data['STDepressionExercise']=data[['STDepressionExercise']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionSlope']=pd.to_numeric(data['STDepressionSlope'])\n",
    "data['STDepressionSlope']=data[['STDepressionSlope']].apply(processSTDepressionSlope,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['STDepressionSlope'], prefix='STDepressionSlope')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('STDepressionSlope',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coloredVesselsFluroscopy']=pd.to_numeric(data['coloredVesselsFluroscopy'])\n",
    "data['coloredVesselsFluroscopy']=data[['coloredVesselsFluroscopy']].apply(processcoloredVesselsFluroscopy,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['coloredVesselsFluroscopy'], prefix='coloredVesselsFluroscopy')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('coloredVesselsFluroscopy',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heartWallDamage']=pd.to_numeric(data['heartWallDamage'])\n",
    "data['heartWallDamage']=data[['heartWallDamage']].apply(processHeartWallDamage,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['heartWallDamage'], prefix='heartWallDamage')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('heartWallDamage',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output']=pd.to_numeric(data['output'])\n",
    "data['output']=data[['output']].apply(processOutput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOutput=pd.DataFrame(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 1 columns):\n",
      "output    900 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataOutput.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['noOfCigarette' , 'smokingYears'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['output'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   72  1.0           1.0        120             1                 9.0   \n",
       "1   54  1.0           0.0        120             0                13.0   \n",
       "2   54  1.0           0.0        150             0                 9.5   \n",
       "3   65  1.0           1.0        135             1                 9.0   \n",
       "4   58  1.0           1.0        128             1                 4.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0              -1.0            102.0                 58.0   \n",
       "1              10.0            137.0                 68.0   \n",
       "2               9.0            165.0                 56.0   \n",
       "3               6.0            127.0                 59.0   \n",
       "4               3.0            130.0                 56.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    96.0                 80.0   \n",
       "1                  182.0                   110.0                 82.0   \n",
       "2                  170.0                    95.0                100.0   \n",
       "3                  170.0                    75.0                 70.0   \n",
       "4                  165.0                   100.0                 90.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             1.0                   1.0                0                0   \n",
       "1             0.0                   2.0                1                0   \n",
       "2             0.0                   1.6                0                0   \n",
       "3             0.0                   2.8                0                0   \n",
       "4             1.0                   3.0                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             0             1             0   \n",
       "1                0                0             1             0             0   \n",
       "2                1                0             0             1             0   \n",
       "3                0                1             0             0             1   \n",
       "4                0                1             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          0         1         0                0               1   \n",
       "1          1         0         0                0               1   \n",
       "2          0         0         1                0               1   \n",
       "3          0         0         1                0               1   \n",
       "4          0         0         1                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 0                0                1   \n",
       "1               0                 1                0                0   \n",
       "2               0                 0                1                0   \n",
       "3               0                 0                0                1   \n",
       "4               0                 0                1                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               1               0               0                     0   \n",
       "2               0               0               1                     0   \n",
       "3               0               0               1                     0   \n",
       "4               0               0               1                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    1                    0                    0   \n",
       "1                    0                    1                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            0                           1   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           1                           0   \n",
       "4                           0                           1   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   1                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   0                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   0                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  1                  0  \n",
       "3                  1                  0  \n",
       "4                  1                  0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop(['smoker_-1','bloodSugar_-1.0','historyOfHA_-1.0','STDepressionSlope_-1',\n",
    "#               'coloredVesselsFluroscopy_-1','heartWallDamage_-1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   72  1.0           1.0        120             1                 9.0   \n",
       "1   54  1.0           0.0        120             0                13.0   \n",
       "2   54  1.0           0.0        150             0                 9.5   \n",
       "3   65  1.0           1.0        135             1                 9.0   \n",
       "4   58  1.0           1.0        128             1                 4.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0              -1.0            102.0                 58.0   \n",
       "1              10.0            137.0                 68.0   \n",
       "2               9.0            165.0                 56.0   \n",
       "3               6.0            127.0                 59.0   \n",
       "4               3.0            130.0                 56.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    96.0                 80.0   \n",
       "1                  182.0                   110.0                 82.0   \n",
       "2                  170.0                    95.0                100.0   \n",
       "3                  170.0                    75.0                 70.0   \n",
       "4                  165.0                   100.0                 90.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             1.0                   1.0                0                0   \n",
       "1             0.0                   2.0                1                0   \n",
       "2             0.0                   1.6                0                0   \n",
       "3             0.0                   2.8                0                0   \n",
       "4             1.0                   3.0                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             0             1             0   \n",
       "1                0                0             1             0             0   \n",
       "2                1                0             0             1             0   \n",
       "3                0                1             0             0             1   \n",
       "4                0                1             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          0         1         0                0               1   \n",
       "1          1         0         0                0               1   \n",
       "2          0         0         1                0               1   \n",
       "3          0         0         1                0               1   \n",
       "4          0         0         1                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 0                0                1   \n",
       "1               0                 1                0                0   \n",
       "2               0                 0                1                0   \n",
       "3               0                 0                0                1   \n",
       "4               0                 0                1                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               1               0               0                     0   \n",
       "2               0               0               1                     0   \n",
       "3               0               0               1                     0   \n",
       "4               0               0               1                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    1                    0                    0   \n",
       "1                    0                    1                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            0                           1   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           1                           0   \n",
       "4                           0                           1   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   1                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   0                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   0                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  1                  0  \n",
       "3                  1                  0  \n",
       "4                  1                  0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 46 columns):\n",
      "age                            900 non-null int64\n",
      "sex                            900 non-null float64\n",
      "painLocation                   900 non-null float64\n",
      "restingBP                      900 non-null int64\n",
      "hyperTension                   900 non-null int64\n",
      "stressTestDuration             900 non-null float64\n",
      "stressTestSTTime               900 non-null float64\n",
      "stressTestMaxHR                900 non-null float64\n",
      "stressTestRestingHR            900 non-null float64\n",
      "stressTestMaxFirstBPS          900 non-null float64\n",
      "stressTestMaxSecondBPS         900 non-null float64\n",
      "stressTestRestingBP            900 non-null float64\n",
      "exerciseAngina                 900 non-null float64\n",
      "STDepressionExercise           900 non-null float64\n",
      "chestPainType_1                900 non-null uint8\n",
      "chestPainType_2                900 non-null uint8\n",
      "chestPainType_3                900 non-null uint8\n",
      "chestPainType_4                900 non-null uint8\n",
      "cholestrol_0                   900 non-null uint8\n",
      "cholestrol_1                   900 non-null uint8\n",
      "cholestrol_2                   900 non-null uint8\n",
      "smoker_-1                      900 non-null uint8\n",
      "smoker_0                       900 non-null uint8\n",
      "smoker_1                       900 non-null uint8\n",
      "bloodSugar_-1.0                900 non-null uint8\n",
      "bloodSugar_0.0                 900 non-null uint8\n",
      "bloodSugar_1.0                 900 non-null uint8\n",
      "historyOfHA_-1.0               900 non-null uint8\n",
      "historyOfHA_0.0                900 non-null uint8\n",
      "historyOfHA_1.0                900 non-null uint8\n",
      "restingECG_0.0                 900 non-null uint8\n",
      "restingECG_1.0                 900 non-null uint8\n",
      "restingECG_2.0                 900 non-null uint8\n",
      "STDepressionSlope_-1           900 non-null uint8\n",
      "STDepressionSlope_0            900 non-null uint8\n",
      "STDepressionSlope_1            900 non-null uint8\n",
      "STDepressionSlope_2            900 non-null uint8\n",
      "coloredVesselsFluroscopy_-1    900 non-null uint8\n",
      "coloredVesselsFluroscopy_0     900 non-null uint8\n",
      "coloredVesselsFluroscopy_1     900 non-null uint8\n",
      "coloredVesselsFluroscopy_2     900 non-null uint8\n",
      "coloredVesselsFluroscopy_3     900 non-null uint8\n",
      "heartWallDamage_-1             900 non-null uint8\n",
      "heartWallDamage_0              900 non-null uint8\n",
      "heartWallDamage_1              900 non-null uint8\n",
      "heartWallDamage_2              900 non-null uint8\n",
      "dtypes: float64(11), int64(3), uint8(32)\n",
      "memory usage: 126.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_X, testingData_X, trainingData_Y, testingData_Y = train_test_split(data,\n",
    "                                                                                dataOutput,\n",
    "                                                                                test_size = 0.2,\n",
    "                                                                                random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=trainingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=trainingData_Y.values\n",
    "y_test=testingData_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "y_train=y_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "y_test=y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLayer=x_train.shape[1]\n",
    "secondLayer=int(x_train.shape[1]/2)\n",
    "thirdLayer=int(secondLayer/2)\n",
    "fourthLayer=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46   23   11   1\n"
     ]
    }
   ],
   "source": [
    "print(firstLayer,\" \",secondLayer,\" \",thirdLayer,\" \",fourthLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(firstLayer, input_dim=x_train.shape[1], activation='tanh',\n",
    "                kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(secondLayer,activation='relu',\n",
    "                kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0),\n",
    "               kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(fourthLayer, activation='sigmoid',kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=RMSprop(lr=0.0002),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 23)                1081      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 3,267\n",
      "Trainable params: 3,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/1000\n",
      "648/648 [==============================] - 0s 248us/step - loss: 1.7710 - acc: 0.4676 - val_loss: 1.7045 - val_acc: 0.5139\n",
      "Epoch 2/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 1.6567 - acc: 0.5679 - val_loss: 1.6113 - val_acc: 0.6528\n",
      "Epoch 3/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 1.5747 - acc: 0.6188 - val_loss: 1.5303 - val_acc: 0.6528\n",
      "Epoch 4/1000\n",
      "648/648 [==============================] - 0s 129us/step - loss: 1.4968 - acc: 0.6358 - val_loss: 1.4539 - val_acc: 0.6389\n",
      "Epoch 5/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 1.4214 - acc: 0.6528 - val_loss: 1.3816 - val_acc: 0.5972\n",
      "Epoch 6/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 1.3518 - acc: 0.6605 - val_loss: 1.3134 - val_acc: 0.5972\n",
      "Epoch 7/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 1.2806 - acc: 0.6713 - val_loss: 1.2479 - val_acc: 0.6389\n",
      "Epoch 8/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.2141 - acc: 0.6806 - val_loss: 1.1847 - val_acc: 0.6528\n",
      "Epoch 9/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 1.1494 - acc: 0.6728 - val_loss: 1.1241 - val_acc: 0.6528\n",
      "Epoch 10/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 1.0886 - acc: 0.6960 - val_loss: 1.0648 - val_acc: 0.6389\n",
      "Epoch 11/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 1.0331 - acc: 0.7176 - val_loss: 1.0076 - val_acc: 0.6250\n",
      "Epoch 12/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.9734 - acc: 0.6836 - val_loss: 0.9521 - val_acc: 0.6250\n",
      "Epoch 13/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.9201 - acc: 0.6975 - val_loss: 0.8986 - val_acc: 0.6250\n",
      "Epoch 14/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.8611 - acc: 0.7176 - val_loss: 0.8472 - val_acc: 0.6389\n",
      "Epoch 15/1000\n",
      "648/648 [==============================] - 0s 155us/step - loss: 0.8128 - acc: 0.7145 - val_loss: 0.7984 - val_acc: 0.6250\n",
      "Epoch 16/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.7710 - acc: 0.6836 - val_loss: 0.7514 - val_acc: 0.6250\n",
      "Epoch 17/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.7253 - acc: 0.6975 - val_loss: 0.7068 - val_acc: 0.6389\n",
      "Epoch 18/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.6795 - acc: 0.7068 - val_loss: 0.6645 - val_acc: 0.6528\n",
      "Epoch 19/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.6392 - acc: 0.7145 - val_loss: 0.6248 - val_acc: 0.6528\n",
      "Epoch 20/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.5983 - acc: 0.7052 - val_loss: 0.5875 - val_acc: 0.6806\n",
      "Epoch 21/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.5633 - acc: 0.7114 - val_loss: 0.5516 - val_acc: 0.6806\n",
      "Epoch 22/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.5242 - acc: 0.7130 - val_loss: 0.5178 - val_acc: 0.6944\n",
      "Epoch 23/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.4929 - acc: 0.6883 - val_loss: 0.4868 - val_acc: 0.6944\n",
      "Epoch 24/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.4583 - acc: 0.7377 - val_loss: 0.4585 - val_acc: 0.6806\n",
      "Epoch 25/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.4363 - acc: 0.7145 - val_loss: 0.4321 - val_acc: 0.6806\n",
      "Epoch 26/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.4098 - acc: 0.7315 - val_loss: 0.4073 - val_acc: 0.6667\n",
      "Epoch 27/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.3866 - acc: 0.7238 - val_loss: 0.3853 - val_acc: 0.6806\n",
      "Epoch 28/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.3634 - acc: 0.7083 - val_loss: 0.3645 - val_acc: 0.6944\n",
      "Epoch 29/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.3449 - acc: 0.7191 - val_loss: 0.3450 - val_acc: 0.6667\n",
      "Epoch 30/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.3265 - acc: 0.7099 - val_loss: 0.3272 - val_acc: 0.6667\n",
      "Epoch 31/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.3061 - acc: 0.7238 - val_loss: 0.3116 - val_acc: 0.6806\n",
      "Epoch 32/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.2937 - acc: 0.7315 - val_loss: 0.2975 - val_acc: 0.6806\n",
      "Epoch 33/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.2812 - acc: 0.7160 - val_loss: 0.2858 - val_acc: 0.6806\n",
      "Epoch 34/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.2661 - acc: 0.7037 - val_loss: 0.2753 - val_acc: 0.6667\n",
      "Epoch 35/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.2580 - acc: 0.7222 - val_loss: 0.2679 - val_acc: 0.6667\n",
      "Epoch 36/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.2489 - acc: 0.7176 - val_loss: 0.2622 - val_acc: 0.6667\n",
      "Epoch 37/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.2497 - acc: 0.6960 - val_loss: 0.2578 - val_acc: 0.6667\n",
      "Epoch 38/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2434 - acc: 0.7222 - val_loss: 0.2538 - val_acc: 0.6667\n",
      "Epoch 39/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.2412 - acc: 0.7238 - val_loss: 0.2506 - val_acc: 0.6667\n",
      "Epoch 40/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2363 - acc: 0.7407 - val_loss: 0.2479 - val_acc: 0.6389\n",
      "Epoch 41/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.2321 - acc: 0.7269 - val_loss: 0.2459 - val_acc: 0.6667\n",
      "Epoch 42/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2356 - acc: 0.6883 - val_loss: 0.2433 - val_acc: 0.6528\n",
      "Epoch 43/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2302 - acc: 0.7207 - val_loss: 0.2416 - val_acc: 0.6667\n",
      "Epoch 44/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2265 - acc: 0.7299 - val_loss: 0.2401 - val_acc: 0.6667\n",
      "Epoch 45/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.2279 - acc: 0.7130 - val_loss: 0.2378 - val_acc: 0.6667\n",
      "Epoch 46/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.2253 - acc: 0.7176 - val_loss: 0.2365 - val_acc: 0.6667\n",
      "Epoch 47/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.2216 - acc: 0.7083 - val_loss: 0.2349 - val_acc: 0.6667\n",
      "Epoch 48/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.2225 - acc: 0.7361 - val_loss: 0.2338 - val_acc: 0.6528\n",
      "Epoch 49/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2203 - acc: 0.7377 - val_loss: 0.2333 - val_acc: 0.6667\n",
      "Epoch 50/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.2246 - acc: 0.7145 - val_loss: 0.2320 - val_acc: 0.6528\n",
      "Epoch 51/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.2216 - acc: 0.6975 - val_loss: 0.2309 - val_acc: 0.6528\n",
      "Epoch 52/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.2168 - acc: 0.7284 - val_loss: 0.2295 - val_acc: 0.6389\n",
      "Epoch 53/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.2163 - acc: 0.7006 - val_loss: 0.2299 - val_acc: 0.6528\n",
      "Epoch 54/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2131 - acc: 0.7299 - val_loss: 0.2286 - val_acc: 0.6667\n",
      "Epoch 55/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2174 - acc: 0.7068 - val_loss: 0.2284 - val_acc: 0.6528\n",
      "Epoch 56/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2143 - acc: 0.7083 - val_loss: 0.2267 - val_acc: 0.6389\n",
      "Epoch 57/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.2132 - acc: 0.7284 - val_loss: 0.2265 - val_acc: 0.6528\n",
      "Epoch 58/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2148 - acc: 0.7207 - val_loss: 0.2254 - val_acc: 0.6528\n",
      "Epoch 59/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2145 - acc: 0.7160 - val_loss: 0.2246 - val_acc: 0.6389\n",
      "Epoch 60/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2140 - acc: 0.7145 - val_loss: 0.2243 - val_acc: 0.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2084 - acc: 0.7130 - val_loss: 0.2239 - val_acc: 0.6667\n",
      "Epoch 62/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2133 - acc: 0.7191 - val_loss: 0.2233 - val_acc: 0.6667\n",
      "Epoch 63/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.2080 - acc: 0.7500 - val_loss: 0.2224 - val_acc: 0.6667\n",
      "Epoch 64/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.2101 - acc: 0.7191 - val_loss: 0.2226 - val_acc: 0.6528\n",
      "Epoch 65/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.2110 - acc: 0.7207 - val_loss: 0.2221 - val_acc: 0.6528\n",
      "Epoch 66/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.2094 - acc: 0.7238 - val_loss: 0.2227 - val_acc: 0.6806\n",
      "Epoch 67/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.2070 - acc: 0.7407 - val_loss: 0.2220 - val_acc: 0.6806\n",
      "Epoch 68/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.2081 - acc: 0.7361 - val_loss: 0.2209 - val_acc: 0.6806\n",
      "Epoch 69/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.2073 - acc: 0.7330 - val_loss: 0.2206 - val_acc: 0.6806\n",
      "Epoch 70/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.2053 - acc: 0.7284 - val_loss: 0.2200 - val_acc: 0.6806\n",
      "Epoch 71/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.2034 - acc: 0.7423 - val_loss: 0.2203 - val_acc: 0.6806\n",
      "Epoch 72/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.2069 - acc: 0.7407 - val_loss: 0.2189 - val_acc: 0.6806\n",
      "Epoch 73/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.2081 - acc: 0.7160 - val_loss: 0.2184 - val_acc: 0.6667\n",
      "Epoch 74/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.2060 - acc: 0.7361 - val_loss: 0.2179 - val_acc: 0.6667\n",
      "Epoch 75/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.2030 - acc: 0.7377 - val_loss: 0.2178 - val_acc: 0.6806\n",
      "Epoch 76/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.2078 - acc: 0.7238 - val_loss: 0.2176 - val_acc: 0.6806\n",
      "Epoch 77/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2012 - acc: 0.7485 - val_loss: 0.2174 - val_acc: 0.6667\n",
      "Epoch 78/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2041 - acc: 0.7284 - val_loss: 0.2169 - val_acc: 0.6806\n",
      "Epoch 79/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2028 - acc: 0.7361 - val_loss: 0.2174 - val_acc: 0.6806\n",
      "Epoch 80/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2037 - acc: 0.7500 - val_loss: 0.2172 - val_acc: 0.7083\n",
      "Epoch 81/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2027 - acc: 0.7315 - val_loss: 0.2163 - val_acc: 0.6806\n",
      "Epoch 82/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.2023 - acc: 0.7330 - val_loss: 0.2160 - val_acc: 0.6944\n",
      "Epoch 83/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2006 - acc: 0.7469 - val_loss: 0.2158 - val_acc: 0.6806\n",
      "Epoch 84/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2018 - acc: 0.7238 - val_loss: 0.2154 - val_acc: 0.7083\n",
      "Epoch 85/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1993 - acc: 0.7407 - val_loss: 0.2155 - val_acc: 0.7083\n",
      "Epoch 86/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1992 - acc: 0.7546 - val_loss: 0.2146 - val_acc: 0.6806\n",
      "Epoch 87/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1979 - acc: 0.7515 - val_loss: 0.2148 - val_acc: 0.7083\n",
      "Epoch 88/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1989 - acc: 0.7531 - val_loss: 0.2149 - val_acc: 0.7222\n",
      "Epoch 89/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1977 - acc: 0.7639 - val_loss: 0.2146 - val_acc: 0.7222\n",
      "Epoch 90/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1939 - acc: 0.7485 - val_loss: 0.2141 - val_acc: 0.6806\n",
      "Epoch 91/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.2000 - acc: 0.7176 - val_loss: 0.2134 - val_acc: 0.6806\n",
      "Epoch 92/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1995 - acc: 0.7438 - val_loss: 0.2133 - val_acc: 0.7083\n",
      "Epoch 93/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1964 - acc: 0.7469 - val_loss: 0.2129 - val_acc: 0.6806\n",
      "Epoch 94/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1954 - acc: 0.7485 - val_loss: 0.2132 - val_acc: 0.7083\n",
      "Epoch 95/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1953 - acc: 0.7392 - val_loss: 0.2132 - val_acc: 0.7222\n",
      "Epoch 96/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1953 - acc: 0.7469 - val_loss: 0.2130 - val_acc: 0.7222\n",
      "Epoch 97/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1961 - acc: 0.7407 - val_loss: 0.2127 - val_acc: 0.7222\n",
      "Epoch 98/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1957 - acc: 0.7207 - val_loss: 0.2119 - val_acc: 0.7222\n",
      "Epoch 99/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1964 - acc: 0.7392 - val_loss: 0.2113 - val_acc: 0.6806\n",
      "Epoch 100/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1966 - acc: 0.7438 - val_loss: 0.2112 - val_acc: 0.7222\n",
      "Epoch 101/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1943 - acc: 0.7469 - val_loss: 0.2115 - val_acc: 0.7222\n",
      "Epoch 102/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1929 - acc: 0.7546 - val_loss: 0.2119 - val_acc: 0.7083\n",
      "Epoch 103/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1936 - acc: 0.7330 - val_loss: 0.2110 - val_acc: 0.7222\n",
      "Epoch 104/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1934 - acc: 0.7469 - val_loss: 0.2106 - val_acc: 0.7222\n",
      "Epoch 105/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1936 - acc: 0.7639 - val_loss: 0.2103 - val_acc: 0.7083\n",
      "Epoch 106/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1922 - acc: 0.7330 - val_loss: 0.2098 - val_acc: 0.7222\n",
      "Epoch 107/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1898 - acc: 0.7593 - val_loss: 0.2118 - val_acc: 0.6806\n",
      "Epoch 108/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1923 - acc: 0.7454 - val_loss: 0.2099 - val_acc: 0.7222\n",
      "Epoch 109/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1922 - acc: 0.7485 - val_loss: 0.2098 - val_acc: 0.7222\n",
      "Epoch 110/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1936 - acc: 0.7562 - val_loss: 0.2104 - val_acc: 0.7083\n",
      "Epoch 111/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1907 - acc: 0.7546 - val_loss: 0.2098 - val_acc: 0.7083\n",
      "Epoch 112/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1873 - acc: 0.7747 - val_loss: 0.2106 - val_acc: 0.6806\n",
      "Epoch 113/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1923 - acc: 0.7361 - val_loss: 0.2095 - val_acc: 0.7083\n",
      "Epoch 114/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1889 - acc: 0.7423 - val_loss: 0.2092 - val_acc: 0.7222\n",
      "Epoch 115/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1946 - acc: 0.7330 - val_loss: 0.2092 - val_acc: 0.7083\n",
      "Epoch 116/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1882 - acc: 0.7608 - val_loss: 0.2090 - val_acc: 0.7083\n",
      "Epoch 117/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1875 - acc: 0.7639 - val_loss: 0.2103 - val_acc: 0.7083\n",
      "Epoch 118/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1903 - acc: 0.7423 - val_loss: 0.2098 - val_acc: 0.7083\n",
      "Epoch 119/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1874 - acc: 0.7701 - val_loss: 0.2091 - val_acc: 0.6806\n",
      "Epoch 120/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1916 - acc: 0.7454 - val_loss: 0.2080 - val_acc: 0.7222\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 94us/step - loss: 0.1883 - acc: 0.7593 - val_loss: 0.2098 - val_acc: 0.7083\n",
      "Epoch 122/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1872 - acc: 0.7716 - val_loss: 0.2090 - val_acc: 0.6806\n",
      "Epoch 123/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1877 - acc: 0.7593 - val_loss: 0.2081 - val_acc: 0.7222\n",
      "Epoch 124/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1859 - acc: 0.7639 - val_loss: 0.2083 - val_acc: 0.6944\n",
      "Epoch 125/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1903 - acc: 0.7485 - val_loss: 0.2080 - val_acc: 0.7222\n",
      "Epoch 126/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1904 - acc: 0.7423 - val_loss: 0.2070 - val_acc: 0.7222\n",
      "Epoch 127/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1905 - acc: 0.7500 - val_loss: 0.2071 - val_acc: 0.7222\n",
      "Epoch 128/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1858 - acc: 0.7546 - val_loss: 0.2072 - val_acc: 0.7222\n",
      "Epoch 129/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1860 - acc: 0.7762 - val_loss: 0.2074 - val_acc: 0.7222\n",
      "Epoch 130/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1887 - acc: 0.7670 - val_loss: 0.2070 - val_acc: 0.7083\n",
      "Epoch 131/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1895 - acc: 0.7639 - val_loss: 0.2065 - val_acc: 0.7083\n",
      "Epoch 132/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1884 - acc: 0.7346 - val_loss: 0.2077 - val_acc: 0.7083\n",
      "Epoch 133/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1836 - acc: 0.7515 - val_loss: 0.2069 - val_acc: 0.7083\n",
      "Epoch 134/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1878 - acc: 0.7562 - val_loss: 0.2074 - val_acc: 0.7083\n",
      "Epoch 135/1000\n",
      "648/648 [==============================] - 0s 132us/step - loss: 0.1869 - acc: 0.7593 - val_loss: 0.2060 - val_acc: 0.7083\n",
      "Epoch 136/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1884 - acc: 0.7454 - val_loss: 0.2062 - val_acc: 0.7222\n",
      "Epoch 137/1000\n",
      "648/648 [==============================] - 0s 137us/step - loss: 0.1829 - acc: 0.7701 - val_loss: 0.2061 - val_acc: 0.7083\n",
      "Epoch 138/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1879 - acc: 0.7485 - val_loss: 0.2062 - val_acc: 0.7083\n",
      "Epoch 139/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1877 - acc: 0.7377 - val_loss: 0.2059 - val_acc: 0.7222\n",
      "Epoch 140/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1800 - acc: 0.7701 - val_loss: 0.2063 - val_acc: 0.7083\n",
      "Epoch 141/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1844 - acc: 0.7654 - val_loss: 0.2075 - val_acc: 0.7083\n",
      "Epoch 142/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1838 - acc: 0.7716 - val_loss: 0.2069 - val_acc: 0.6944\n",
      "Epoch 143/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1834 - acc: 0.7701 - val_loss: 0.2060 - val_acc: 0.7083\n",
      "Epoch 144/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.1869 - acc: 0.7593 - val_loss: 0.2060 - val_acc: 0.7222\n",
      "Epoch 145/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1864 - acc: 0.7423 - val_loss: 0.2067 - val_acc: 0.7222\n",
      "Epoch 146/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1831 - acc: 0.7747 - val_loss: 0.2066 - val_acc: 0.6944\n",
      "Epoch 147/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1825 - acc: 0.7793 - val_loss: 0.2067 - val_acc: 0.7083\n",
      "Epoch 148/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1821 - acc: 0.7685 - val_loss: 0.2064 - val_acc: 0.7083\n",
      "Epoch 149/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1847 - acc: 0.7500 - val_loss: 0.2063 - val_acc: 0.7083\n",
      "Epoch 150/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1794 - acc: 0.7701 - val_loss: 0.2065 - val_acc: 0.6944\n",
      "Epoch 151/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1805 - acc: 0.7917 - val_loss: 0.2065 - val_acc: 0.6944\n",
      "Epoch 152/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1783 - acc: 0.7546 - val_loss: 0.2059 - val_acc: 0.6944\n",
      "Epoch 153/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1832 - acc: 0.7747 - val_loss: 0.2084 - val_acc: 0.6806\n",
      "Epoch 154/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1829 - acc: 0.7654 - val_loss: 0.2065 - val_acc: 0.7083\n",
      "Epoch 155/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1848 - acc: 0.7562 - val_loss: 0.2077 - val_acc: 0.6806\n",
      "Epoch 156/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1815 - acc: 0.7623 - val_loss: 0.2065 - val_acc: 0.6944\n",
      "Epoch 157/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1818 - acc: 0.7731 - val_loss: 0.2058 - val_acc: 0.7083\n",
      "Epoch 158/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1838 - acc: 0.7654 - val_loss: 0.2058 - val_acc: 0.7083\n",
      "Epoch 159/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1811 - acc: 0.7747 - val_loss: 0.2058 - val_acc: 0.7222\n",
      "Epoch 160/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1815 - acc: 0.7608 - val_loss: 0.2047 - val_acc: 0.6944\n",
      "Epoch 161/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1865 - acc: 0.7577 - val_loss: 0.2053 - val_acc: 0.7083\n",
      "Epoch 162/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1866 - acc: 0.7515 - val_loss: 0.2041 - val_acc: 0.6944\n",
      "Epoch 163/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1833 - acc: 0.7562 - val_loss: 0.2047 - val_acc: 0.7222\n",
      "Epoch 164/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1787 - acc: 0.7685 - val_loss: 0.2053 - val_acc: 0.6944\n",
      "Epoch 165/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1868 - acc: 0.7485 - val_loss: 0.2055 - val_acc: 0.7083\n",
      "Epoch 166/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1799 - acc: 0.7654 - val_loss: 0.2052 - val_acc: 0.6944\n",
      "Epoch 167/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1858 - acc: 0.7593 - val_loss: 0.2046 - val_acc: 0.7083\n",
      "Epoch 168/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1867 - acc: 0.7423 - val_loss: 0.2049 - val_acc: 0.7083\n",
      "Epoch 169/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1805 - acc: 0.7623 - val_loss: 0.2067 - val_acc: 0.6806\n",
      "Epoch 170/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1843 - acc: 0.7670 - val_loss: 0.2044 - val_acc: 0.7083\n",
      "Epoch 171/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1833 - acc: 0.7654 - val_loss: 0.2057 - val_acc: 0.7222\n",
      "Epoch 172/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1854 - acc: 0.7531 - val_loss: 0.2044 - val_acc: 0.7222\n",
      "Epoch 173/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1812 - acc: 0.7608 - val_loss: 0.2042 - val_acc: 0.7222\n",
      "Epoch 174/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1757 - acc: 0.7685 - val_loss: 0.2041 - val_acc: 0.7083\n",
      "Epoch 175/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1801 - acc: 0.7577 - val_loss: 0.2039 - val_acc: 0.7083\n",
      "Epoch 176/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1815 - acc: 0.7731 - val_loss: 0.2047 - val_acc: 0.7083\n",
      "Epoch 177/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1797 - acc: 0.7670 - val_loss: 0.2052 - val_acc: 0.7222\n",
      "Epoch 178/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1782 - acc: 0.7515 - val_loss: 0.2043 - val_acc: 0.7083\n",
      "Epoch 179/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1805 - acc: 0.7546 - val_loss: 0.2039 - val_acc: 0.7083\n",
      "Epoch 180/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1836 - acc: 0.7546 - val_loss: 0.2051 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1801 - acc: 0.7685 - val_loss: 0.2041 - val_acc: 0.6944\n",
      "Epoch 182/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1836 - acc: 0.7593 - val_loss: 0.2053 - val_acc: 0.6944\n",
      "Epoch 183/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1784 - acc: 0.7731 - val_loss: 0.2049 - val_acc: 0.7083\n",
      "Epoch 184/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1740 - acc: 0.7793 - val_loss: 0.2055 - val_acc: 0.6944\n",
      "Epoch 185/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1804 - acc: 0.7546 - val_loss: 0.2050 - val_acc: 0.6806\n",
      "Epoch 186/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1728 - acc: 0.7840 - val_loss: 0.2071 - val_acc: 0.6806\n",
      "Epoch 187/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1776 - acc: 0.7701 - val_loss: 0.2057 - val_acc: 0.6944\n",
      "Epoch 188/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1786 - acc: 0.7824 - val_loss: 0.2049 - val_acc: 0.6944\n",
      "Epoch 189/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1805 - acc: 0.7793 - val_loss: 0.2060 - val_acc: 0.6806\n",
      "Epoch 190/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1718 - acc: 0.7809 - val_loss: 0.2041 - val_acc: 0.7083\n",
      "Epoch 191/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1804 - acc: 0.7469 - val_loss: 0.2045 - val_acc: 0.7083\n",
      "Epoch 192/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1807 - acc: 0.7639 - val_loss: 0.2044 - val_acc: 0.6944\n",
      "Epoch 193/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1819 - acc: 0.7454 - val_loss: 0.2057 - val_acc: 0.6806\n",
      "Epoch 194/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1809 - acc: 0.7716 - val_loss: 0.2044 - val_acc: 0.6944\n",
      "Epoch 195/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1744 - acc: 0.7778 - val_loss: 0.2038 - val_acc: 0.6944\n",
      "Epoch 196/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1777 - acc: 0.7793 - val_loss: 0.2041 - val_acc: 0.6944\n",
      "Epoch 197/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1798 - acc: 0.7608 - val_loss: 0.2039 - val_acc: 0.6944\n",
      "Epoch 198/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1763 - acc: 0.7608 - val_loss: 0.2052 - val_acc: 0.6806\n",
      "Epoch 199/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1706 - acc: 0.7824 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 200/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1761 - acc: 0.7608 - val_loss: 0.2049 - val_acc: 0.6806\n",
      "Epoch 201/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1776 - acc: 0.7701 - val_loss: 0.2051 - val_acc: 0.6944\n",
      "Epoch 202/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1792 - acc: 0.7639 - val_loss: 0.2036 - val_acc: 0.7083\n",
      "Epoch 203/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1775 - acc: 0.7778 - val_loss: 0.2073 - val_acc: 0.6806\n",
      "Epoch 204/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1823 - acc: 0.7593 - val_loss: 0.2037 - val_acc: 0.6944\n",
      "Epoch 205/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1725 - acc: 0.7809 - val_loss: 0.2041 - val_acc: 0.6944\n",
      "Epoch 206/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1774 - acc: 0.7793 - val_loss: 0.2047 - val_acc: 0.6944\n",
      "Epoch 207/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1767 - acc: 0.7778 - val_loss: 0.2043 - val_acc: 0.7083\n",
      "Epoch 208/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1793 - acc: 0.7762 - val_loss: 0.2037 - val_acc: 0.7083\n",
      "Epoch 209/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1771 - acc: 0.7716 - val_loss: 0.2038 - val_acc: 0.6944\n",
      "Epoch 210/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1767 - acc: 0.7531 - val_loss: 0.2064 - val_acc: 0.6667\n",
      "Epoch 211/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1807 - acc: 0.7654 - val_loss: 0.2042 - val_acc: 0.6806\n",
      "Epoch 212/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1736 - acc: 0.7793 - val_loss: 0.2067 - val_acc: 0.6806\n",
      "Epoch 213/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1781 - acc: 0.7639 - val_loss: 0.2040 - val_acc: 0.6944\n",
      "Epoch 214/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1735 - acc: 0.7731 - val_loss: 0.2046 - val_acc: 0.6667\n",
      "Epoch 215/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1746 - acc: 0.7809 - val_loss: 0.2054 - val_acc: 0.6667\n",
      "Epoch 216/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1696 - acc: 0.7978 - val_loss: 0.2051 - val_acc: 0.6667\n",
      "Epoch 217/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1742 - acc: 0.7793 - val_loss: 0.2040 - val_acc: 0.7083\n",
      "Epoch 218/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1726 - acc: 0.7654 - val_loss: 0.2038 - val_acc: 0.6944\n",
      "Epoch 219/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1700 - acc: 0.7978 - val_loss: 0.2043 - val_acc: 0.6806\n",
      "Epoch 220/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1750 - acc: 0.7685 - val_loss: 0.2042 - val_acc: 0.6944\n",
      "Epoch 221/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1726 - acc: 0.7623 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 222/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1793 - acc: 0.7731 - val_loss: 0.2038 - val_acc: 0.6667\n",
      "Epoch 223/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1773 - acc: 0.7670 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 224/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1782 - acc: 0.7654 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 225/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1717 - acc: 0.7948 - val_loss: 0.2035 - val_acc: 0.6944\n",
      "Epoch 226/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1754 - acc: 0.7747 - val_loss: 0.2030 - val_acc: 0.6806\n",
      "Epoch 227/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1777 - acc: 0.7515 - val_loss: 0.2028 - val_acc: 0.6944\n",
      "Epoch 228/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1753 - acc: 0.7731 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 229/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1749 - acc: 0.7870 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 230/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1727 - acc: 0.7685 - val_loss: 0.2044 - val_acc: 0.6667\n",
      "Epoch 231/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1746 - acc: 0.7809 - val_loss: 0.2040 - val_acc: 0.6806\n",
      "Epoch 232/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1818 - acc: 0.7546 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 233/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1721 - acc: 0.7701 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 234/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1736 - acc: 0.7793 - val_loss: 0.2044 - val_acc: 0.6667\n",
      "Epoch 235/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1751 - acc: 0.7809 - val_loss: 0.2032 - val_acc: 0.6944\n",
      "Epoch 236/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1782 - acc: 0.7685 - val_loss: 0.2028 - val_acc: 0.6944\n",
      "Epoch 237/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1759 - acc: 0.7809 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 238/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1755 - acc: 0.7546 - val_loss: 0.2044 - val_acc: 0.6667\n",
      "Epoch 239/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1758 - acc: 0.7747 - val_loss: 0.2060 - val_acc: 0.6806\n",
      "Epoch 240/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1761 - acc: 0.7778 - val_loss: 0.2034 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1718 - acc: 0.7978 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 242/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1768 - acc: 0.7701 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 243/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1700 - acc: 0.7840 - val_loss: 0.2047 - val_acc: 0.6667\n",
      "Epoch 244/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1729 - acc: 0.7778 - val_loss: 0.2045 - val_acc: 0.6667\n",
      "Epoch 245/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1725 - acc: 0.7994 - val_loss: 0.2043 - val_acc: 0.6806\n",
      "Epoch 246/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1687 - acc: 0.7824 - val_loss: 0.2059 - val_acc: 0.6667\n",
      "Epoch 247/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1799 - acc: 0.7608 - val_loss: 0.2032 - val_acc: 0.6806\n",
      "Epoch 248/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1716 - acc: 0.7963 - val_loss: 0.2043 - val_acc: 0.6806\n",
      "Epoch 249/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1770 - acc: 0.7778 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 250/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1738 - acc: 0.7824 - val_loss: 0.2045 - val_acc: 0.6667\n",
      "Epoch 251/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1759 - acc: 0.7855 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 252/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1721 - acc: 0.7917 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 253/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1726 - acc: 0.7747 - val_loss: 0.2046 - val_acc: 0.6667\n",
      "Epoch 254/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1732 - acc: 0.7855 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 255/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1746 - acc: 0.7855 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 256/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1740 - acc: 0.7639 - val_loss: 0.2061 - val_acc: 0.6528\n",
      "Epoch 257/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1743 - acc: 0.7716 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 258/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1719 - acc: 0.7901 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 259/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1693 - acc: 0.7978 - val_loss: 0.2042 - val_acc: 0.6667\n",
      "Epoch 260/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1776 - acc: 0.7546 - val_loss: 0.2040 - val_acc: 0.6667\n",
      "Epoch 261/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1739 - acc: 0.7747 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 262/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1699 - acc: 0.7886 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 263/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1726 - acc: 0.7762 - val_loss: 0.2045 - val_acc: 0.6667\n",
      "Epoch 264/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1749 - acc: 0.7747 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 265/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1689 - acc: 0.7886 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 266/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1715 - acc: 0.7840 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 267/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1730 - acc: 0.7824 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 268/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1687 - acc: 0.7809 - val_loss: 0.2038 - val_acc: 0.6667\n",
      "Epoch 269/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1683 - acc: 0.7824 - val_loss: 0.2051 - val_acc: 0.6667\n",
      "Epoch 270/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1730 - acc: 0.7701 - val_loss: 0.2045 - val_acc: 0.6667\n",
      "Epoch 271/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1750 - acc: 0.7886 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 272/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1735 - acc: 0.7747 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 273/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1750 - acc: 0.7623 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 274/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1715 - acc: 0.7824 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 275/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1709 - acc: 0.7994 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 276/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1739 - acc: 0.7762 - val_loss: 0.2032 - val_acc: 0.6944\n",
      "Epoch 277/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1671 - acc: 0.7870 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 278/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1711 - acc: 0.7824 - val_loss: 0.2045 - val_acc: 0.6528\n",
      "Epoch 279/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1691 - acc: 0.7901 - val_loss: 0.2032 - val_acc: 0.6667\n",
      "Epoch 280/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1727 - acc: 0.7793 - val_loss: 0.2054 - val_acc: 0.6528\n",
      "Epoch 281/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1727 - acc: 0.7731 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 282/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1713 - acc: 0.7886 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 283/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1715 - acc: 0.7701 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 284/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1704 - acc: 0.7731 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 285/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1785 - acc: 0.7623 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 286/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1712 - acc: 0.7809 - val_loss: 0.2024 - val_acc: 0.6806\n",
      "Epoch 287/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1708 - acc: 0.7840 - val_loss: 0.2015 - val_acc: 0.7083\n",
      "Epoch 288/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1687 - acc: 0.7855 - val_loss: 0.2049 - val_acc: 0.6667\n",
      "Epoch 289/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1704 - acc: 0.7840 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 290/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1712 - acc: 0.7840 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 291/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1694 - acc: 0.7731 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 292/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1749 - acc: 0.7731 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 293/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1703 - acc: 0.7701 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 294/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1653 - acc: 0.7778 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 295/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1716 - acc: 0.7840 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 296/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1707 - acc: 0.7731 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 297/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1740 - acc: 0.7747 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 298/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1692 - acc: 0.7809 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 299/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1664 - acc: 0.7809 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 300/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1683 - acc: 0.7932 - val_loss: 0.2027 - val_acc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1696 - acc: 0.7809 - val_loss: 0.2054 - val_acc: 0.6528\n",
      "Epoch 302/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1714 - acc: 0.7855 - val_loss: 0.2032 - val_acc: 0.6667\n",
      "Epoch 303/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1736 - acc: 0.7809 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 304/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1697 - acc: 0.7901 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 305/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1642 - acc: 0.7886 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 306/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1719 - acc: 0.7978 - val_loss: 0.2049 - val_acc: 0.6667\n",
      "Epoch 307/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1702 - acc: 0.7994 - val_loss: 0.2055 - val_acc: 0.6528\n",
      "Epoch 308/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1719 - acc: 0.7824 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 309/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1663 - acc: 0.7870 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 310/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1691 - acc: 0.7855 - val_loss: 0.2064 - val_acc: 0.6528\n",
      "Epoch 311/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1689 - acc: 0.7855 - val_loss: 0.2032 - val_acc: 0.6806\n",
      "Epoch 312/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1675 - acc: 0.7840 - val_loss: 0.2055 - val_acc: 0.6528\n",
      "Epoch 313/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1716 - acc: 0.7809 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 314/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1729 - acc: 0.7809 - val_loss: 0.2023 - val_acc: 0.6667\n",
      "Epoch 315/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1664 - acc: 0.8009 - val_loss: 0.2052 - val_acc: 0.6528\n",
      "Epoch 316/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1710 - acc: 0.7824 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 317/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1692 - acc: 0.7824 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 318/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1704 - acc: 0.7886 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 319/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1702 - acc: 0.7716 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 320/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1672 - acc: 0.7870 - val_loss: 0.2032 - val_acc: 0.6667\n",
      "Epoch 321/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1702 - acc: 0.7762 - val_loss: 0.2041 - val_acc: 0.6528\n",
      "Epoch 322/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1718 - acc: 0.7747 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 323/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1685 - acc: 0.7701 - val_loss: 0.2041 - val_acc: 0.6528\n",
      "Epoch 324/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1668 - acc: 0.7901 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 325/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1719 - acc: 0.7793 - val_loss: 0.2029 - val_acc: 0.6528\n",
      "Epoch 326/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1708 - acc: 0.7762 - val_loss: 0.2036 - val_acc: 0.6806\n",
      "Epoch 327/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1684 - acc: 0.7886 - val_loss: 0.2054 - val_acc: 0.6528\n",
      "Epoch 328/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1661 - acc: 0.7978 - val_loss: 0.2044 - val_acc: 0.6528\n",
      "Epoch 329/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1663 - acc: 0.7840 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 330/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1702 - acc: 0.7778 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 331/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1671 - acc: 0.7685 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 332/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1712 - acc: 0.7870 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 333/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1676 - acc: 0.7886 - val_loss: 0.2040 - val_acc: 0.6667\n",
      "Epoch 334/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1681 - acc: 0.7886 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 335/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1657 - acc: 0.7932 - val_loss: 0.2027 - val_acc: 0.6528\n",
      "Epoch 336/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1654 - acc: 0.7778 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 337/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1629 - acc: 0.7917 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 338/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1668 - acc: 0.7917 - val_loss: 0.2062 - val_acc: 0.6528\n",
      "Epoch 339/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1664 - acc: 0.7917 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 340/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1623 - acc: 0.7978 - val_loss: 0.2016 - val_acc: 0.6667\n",
      "Epoch 341/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1686 - acc: 0.7901 - val_loss: 0.2031 - val_acc: 0.6528\n",
      "Epoch 342/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1718 - acc: 0.7840 - val_loss: 0.2031 - val_acc: 0.6528\n",
      "Epoch 343/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1718 - acc: 0.7731 - val_loss: 0.2018 - val_acc: 0.6528\n",
      "Epoch 344/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1663 - acc: 0.7809 - val_loss: 0.2032 - val_acc: 0.6528\n",
      "Epoch 345/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1634 - acc: 0.7994 - val_loss: 0.2020 - val_acc: 0.6528\n",
      "Epoch 346/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1701 - acc: 0.7840 - val_loss: 0.2036 - val_acc: 0.6528\n",
      "Epoch 347/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1665 - acc: 0.7901 - val_loss: 0.2018 - val_acc: 0.7083\n",
      "Epoch 348/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1647 - acc: 0.7963 - val_loss: 0.2067 - val_acc: 0.6528\n",
      "Epoch 349/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1684 - acc: 0.7978 - val_loss: 0.2052 - val_acc: 0.6528\n",
      "Epoch 350/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1682 - acc: 0.7932 - val_loss: 0.2042 - val_acc: 0.6528\n",
      "Epoch 351/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1693 - acc: 0.7855 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 352/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1626 - acc: 0.7870 - val_loss: 0.2046 - val_acc: 0.6528\n",
      "Epoch 353/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1716 - acc: 0.7932 - val_loss: 0.2031 - val_acc: 0.6528\n",
      "Epoch 354/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1686 - acc: 0.7716 - val_loss: 0.2021 - val_acc: 0.6528\n",
      "Epoch 355/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1659 - acc: 0.7762 - val_loss: 0.2020 - val_acc: 0.6528\n",
      "Epoch 356/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1732 - acc: 0.7870 - val_loss: 0.2034 - val_acc: 0.6667\n",
      "Epoch 357/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1729 - acc: 0.7855 - val_loss: 0.2029 - val_acc: 0.6528\n",
      "Epoch 358/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1739 - acc: 0.7840 - val_loss: 0.2013 - val_acc: 0.6667\n",
      "Epoch 359/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1673 - acc: 0.7793 - val_loss: 0.2031 - val_acc: 0.6528\n",
      "Epoch 360/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1646 - acc: 0.7855 - val_loss: 0.2025 - val_acc: 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1695 - acc: 0.7778 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 362/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1638 - acc: 0.7948 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 363/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1669 - acc: 0.7855 - val_loss: 0.2033 - val_acc: 0.6528\n",
      "Epoch 364/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1663 - acc: 0.7901 - val_loss: 0.2039 - val_acc: 0.6806\n",
      "Epoch 365/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1678 - acc: 0.7778 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 366/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1644 - acc: 0.7963 - val_loss: 0.2041 - val_acc: 0.6528\n",
      "Epoch 367/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1698 - acc: 0.7778 - val_loss: 0.2041 - val_acc: 0.6528\n",
      "Epoch 368/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1668 - acc: 0.7824 - val_loss: 0.2028 - val_acc: 0.6528\n",
      "Epoch 369/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1649 - acc: 0.8071 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 370/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1709 - acc: 0.7809 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 371/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1677 - acc: 0.7809 - val_loss: 0.2050 - val_acc: 0.6528\n",
      "Epoch 372/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1661 - acc: 0.7886 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 373/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1638 - acc: 0.7870 - val_loss: 0.2024 - val_acc: 0.6528\n",
      "Epoch 374/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1691 - acc: 0.7701 - val_loss: 0.2025 - val_acc: 0.6528\n",
      "Epoch 375/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1681 - acc: 0.7747 - val_loss: 0.2025 - val_acc: 0.6667\n",
      "Epoch 376/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1633 - acc: 0.7886 - val_loss: 0.2039 - val_acc: 0.6528\n",
      "Epoch 377/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1668 - acc: 0.7855 - val_loss: 0.2034 - val_acc: 0.6528\n",
      "Epoch 378/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1632 - acc: 0.7978 - val_loss: 0.2061 - val_acc: 0.6528\n",
      "Epoch 379/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1651 - acc: 0.7948 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 380/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1637 - acc: 0.7932 - val_loss: 0.2049 - val_acc: 0.6528\n",
      "Epoch 381/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1658 - acc: 0.7901 - val_loss: 0.2032 - val_acc: 0.6528\n",
      "Epoch 382/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1675 - acc: 0.7917 - val_loss: 0.2052 - val_acc: 0.6528\n",
      "Epoch 383/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1699 - acc: 0.7685 - val_loss: 0.2037 - val_acc: 0.6528\n",
      "Epoch 384/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1657 - acc: 0.7901 - val_loss: 0.2037 - val_acc: 0.6528\n",
      "Epoch 385/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1672 - acc: 0.7917 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 386/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1657 - acc: 0.7917 - val_loss: 0.2022 - val_acc: 0.6528\n",
      "Epoch 387/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1644 - acc: 0.8025 - val_loss: 0.2030 - val_acc: 0.6528\n",
      "Epoch 388/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1633 - acc: 0.7978 - val_loss: 0.2047 - val_acc: 0.6528\n",
      "Epoch 389/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1630 - acc: 0.7948 - val_loss: 0.2036 - val_acc: 0.6528\n",
      "Epoch 390/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1639 - acc: 0.8056 - val_loss: 0.2051 - val_acc: 0.6528\n",
      "Epoch 391/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1672 - acc: 0.7963 - val_loss: 0.2029 - val_acc: 0.6528\n",
      "Epoch 392/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1663 - acc: 0.7824 - val_loss: 0.2032 - val_acc: 0.6667\n",
      "Epoch 393/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1663 - acc: 0.7840 - val_loss: 0.2041 - val_acc: 0.6528\n",
      "Epoch 394/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1627 - acc: 0.7978 - val_loss: 0.2030 - val_acc: 0.6528\n",
      "Epoch 395/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1656 - acc: 0.7855 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 396/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1662 - acc: 0.7793 - val_loss: 0.2026 - val_acc: 0.6528\n",
      "Epoch 397/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1634 - acc: 0.8009 - val_loss: 0.2020 - val_acc: 0.6528\n",
      "Epoch 398/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1607 - acc: 0.7963 - val_loss: 0.2033 - val_acc: 0.6528\n",
      "Epoch 399/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1681 - acc: 0.7747 - val_loss: 0.2027 - val_acc: 0.6528\n",
      "Epoch 400/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1650 - acc: 0.7963 - val_loss: 0.2040 - val_acc: 0.6528\n",
      "Epoch 401/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1619 - acc: 0.7917 - val_loss: 0.2021 - val_acc: 0.6528\n",
      "Epoch 402/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1652 - acc: 0.7932 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 403/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1689 - acc: 0.7917 - val_loss: 0.2018 - val_acc: 0.6528\n",
      "Epoch 404/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1935 - acc: 0.687 - 0s 60us/step - loss: 0.1677 - acc: 0.7870 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 405/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1634 - acc: 0.7870 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 406/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1683 - acc: 0.7994 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 407/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1672 - acc: 0.7901 - val_loss: 0.2014 - val_acc: 0.6528\n",
      "Epoch 408/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1625 - acc: 0.7886 - val_loss: 0.2018 - val_acc: 0.6528\n",
      "Epoch 409/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1698 - acc: 0.7855 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 410/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1676 - acc: 0.7948 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 411/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1640 - acc: 0.7855 - val_loss: 0.2020 - val_acc: 0.6528\n",
      "Epoch 412/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1649 - acc: 0.7870 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 413/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1653 - acc: 0.7901 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 414/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1642 - acc: 0.7994 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 415/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1616 - acc: 0.7978 - val_loss: 0.2033 - val_acc: 0.6528\n",
      "Epoch 416/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1692 - acc: 0.7654 - val_loss: 0.2031 - val_acc: 0.6528\n",
      "Epoch 417/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1676 - acc: 0.7840 - val_loss: 0.2030 - val_acc: 0.6528\n",
      "Epoch 418/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1676 - acc: 0.7716 - val_loss: 0.2009 - val_acc: 0.6528\n",
      "Epoch 419/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1651 - acc: 0.7948 - val_loss: 0.2008 - val_acc: 0.6667\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 75us/step - loss: 0.1649 - acc: 0.8102 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 421/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1663 - acc: 0.7901 - val_loss: 0.2034 - val_acc: 0.6667\n",
      "Epoch 422/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1647 - acc: 0.8025 - val_loss: 0.2032 - val_acc: 0.6528\n",
      "Epoch 423/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1644 - acc: 0.7917 - val_loss: 0.2035 - val_acc: 0.6528\n",
      "Epoch 424/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1654 - acc: 0.7963 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 425/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1647 - acc: 0.7855 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 426/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1668 - acc: 0.7778 - val_loss: 0.2013 - val_acc: 0.6528\n",
      "Epoch 427/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1662 - acc: 0.8009 - val_loss: 0.2057 - val_acc: 0.6528\n",
      "Epoch 428/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1656 - acc: 0.7778 - val_loss: 0.2033 - val_acc: 0.6528\n",
      "Epoch 429/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1667 - acc: 0.7932 - val_loss: 0.2075 - val_acc: 0.6667\n",
      "Epoch 430/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1602 - acc: 0.7994 - val_loss: 0.2049 - val_acc: 0.6667\n",
      "Epoch 431/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1629 - acc: 0.8071 - val_loss: 0.2035 - val_acc: 0.6528\n",
      "Epoch 432/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1608 - acc: 0.8040 - val_loss: 0.2029 - val_acc: 0.6528\n",
      "Epoch 433/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1631 - acc: 0.7793 - val_loss: 0.2030 - val_acc: 0.6528\n",
      "Epoch 434/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1641 - acc: 0.7978 - val_loss: 0.2014 - val_acc: 0.6528\n",
      "Epoch 435/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1620 - acc: 0.7948 - val_loss: 0.2017 - val_acc: 0.6528\n",
      "Epoch 436/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1645 - acc: 0.8056 - val_loss: 0.2015 - val_acc: 0.6944\n",
      "Epoch 437/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1611 - acc: 0.7901 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 438/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1641 - acc: 0.8086 - val_loss: 0.2041 - val_acc: 0.6667\n",
      "Epoch 439/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1604 - acc: 0.7901 - val_loss: 0.2048 - val_acc: 0.6528\n",
      "Epoch 440/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1661 - acc: 0.7901 - val_loss: 0.2045 - val_acc: 0.6667\n",
      "Epoch 441/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1648 - acc: 0.8009 - val_loss: 0.2026 - val_acc: 0.6528\n",
      "Epoch 442/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1680 - acc: 0.7855 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 443/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1640 - acc: 0.7932 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 444/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1614 - acc: 0.8056 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 445/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1660 - acc: 0.7948 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 446/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1625 - acc: 0.7932 - val_loss: 0.2030 - val_acc: 0.6528\n",
      "Epoch 447/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1639 - acc: 0.8071 - val_loss: 0.2043 - val_acc: 0.6667\n",
      "Epoch 448/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1565 - acc: 0.8179 - val_loss: 0.2038 - val_acc: 0.6667\n",
      "Epoch 449/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1650 - acc: 0.7855 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 450/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1679 - acc: 0.7948 - val_loss: 0.2003 - val_acc: 0.6806\n",
      "Epoch 451/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1679 - acc: 0.7762 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 452/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1608 - acc: 0.7978 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 453/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1642 - acc: 0.7886 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 454/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1656 - acc: 0.7978 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 455/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1634 - acc: 0.7917 - val_loss: 0.2016 - val_acc: 0.6667\n",
      "Epoch 456/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1655 - acc: 0.7948 - val_loss: 0.2023 - val_acc: 0.6667\n",
      "Epoch 457/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1648 - acc: 0.7948 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 458/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1657 - acc: 0.8056 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 459/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1629 - acc: 0.7886 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 460/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1631 - acc: 0.7886 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 461/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1694 - acc: 0.7901 - val_loss: 0.2010 - val_acc: 0.6667\n",
      "Epoch 462/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1621 - acc: 0.7932 - val_loss: 0.2036 - val_acc: 0.6667\n",
      "Epoch 463/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1630 - acc: 0.7978 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 464/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1591 - acc: 0.8040 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 465/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1584 - acc: 0.7994 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 466/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1613 - acc: 0.7855 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 467/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1599 - acc: 0.8040 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 468/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1624 - acc: 0.8009 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 469/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1616 - acc: 0.8056 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 470/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1631 - acc: 0.7901 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 471/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1676 - acc: 0.7855 - val_loss: 0.2011 - val_acc: 0.6806\n",
      "Epoch 472/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1634 - acc: 0.7840 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 473/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1634 - acc: 0.7948 - val_loss: 0.2011 - val_acc: 0.6667\n",
      "Epoch 474/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1629 - acc: 0.7948 - val_loss: 0.2010 - val_acc: 0.6667\n",
      "Epoch 475/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1693 - acc: 0.7855 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 476/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1664 - acc: 0.7685 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 477/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1607 - acc: 0.7994 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 478/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1615 - acc: 0.7948 - val_loss: 0.2042 - val_acc: 0.6667\n",
      "Epoch 479/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1641 - acc: 0.7994 - val_loss: 0.2027 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1576 - acc: 0.8071 - val_loss: 0.2010 - val_acc: 0.6667\n",
      "Epoch 481/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1644 - acc: 0.8025 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 482/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1633 - acc: 0.8009 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 483/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1634 - acc: 0.7840 - val_loss: 0.2017 - val_acc: 0.6806\n",
      "Epoch 484/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1601 - acc: 0.7886 - val_loss: 0.2002 - val_acc: 0.6667\n",
      "Epoch 485/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1627 - acc: 0.7948 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 486/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1604 - acc: 0.7994 - val_loss: 0.2005 - val_acc: 0.6667\n",
      "Epoch 487/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1610 - acc: 0.7994 - val_loss: 0.2016 - val_acc: 0.6806\n",
      "Epoch 488/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1590 - acc: 0.7978 - val_loss: 0.2022 - val_acc: 0.6806\n",
      "Epoch 489/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1584 - acc: 0.7963 - val_loss: 0.2030 - val_acc: 0.6667\n",
      "Epoch 490/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1607 - acc: 0.7978 - val_loss: 0.2013 - val_acc: 0.6806\n",
      "Epoch 491/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1595 - acc: 0.7978 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 492/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1618 - acc: 0.7978 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 493/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1600 - acc: 0.8009 - val_loss: 0.2034 - val_acc: 0.6806\n",
      "Epoch 494/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1635 - acc: 0.8071 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 495/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1610 - acc: 0.8117 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 496/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1622 - acc: 0.8025 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 497/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1579 - acc: 0.7917 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 498/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1632 - acc: 0.7994 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 499/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1614 - acc: 0.8009 - val_loss: 0.2028 - val_acc: 0.6806\n",
      "Epoch 500/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1594 - acc: 0.8102 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 501/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1624 - acc: 0.7948 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 502/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1616 - acc: 0.8071 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 503/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1647 - acc: 0.7855 - val_loss: 0.2014 - val_acc: 0.6667\n",
      "Epoch 504/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1637 - acc: 0.7840 - val_loss: 0.2003 - val_acc: 0.6806\n",
      "Epoch 505/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1651 - acc: 0.7948 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 506/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1621 - acc: 0.7870 - val_loss: 0.2011 - val_acc: 0.7083\n",
      "Epoch 507/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1631 - acc: 0.7994 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 508/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1623 - acc: 0.7840 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 509/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1626 - acc: 0.8194 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 510/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1623 - acc: 0.8025 - val_loss: 0.1999 - val_acc: 0.7083\n",
      "Epoch 511/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1660 - acc: 0.7778 - val_loss: 0.2013 - val_acc: 0.6667\n",
      "Epoch 512/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1596 - acc: 0.8117 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 513/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1619 - acc: 0.7870 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 514/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1608 - acc: 0.8009 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 515/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1578 - acc: 0.8086 - val_loss: 0.2052 - val_acc: 0.6667\n",
      "Epoch 516/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1556 - acc: 0.8133 - val_loss: 0.2030 - val_acc: 0.6667\n",
      "Epoch 517/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1586 - acc: 0.8040 - val_loss: 0.2034 - val_acc: 0.6667\n",
      "Epoch 518/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1602 - acc: 0.8040 - val_loss: 0.2032 - val_acc: 0.6667\n",
      "Epoch 519/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1588 - acc: 0.8117 - val_loss: 0.2011 - val_acc: 0.6806\n",
      "Epoch 520/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1592 - acc: 0.8025 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 521/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1589 - acc: 0.8056 - val_loss: 0.2014 - val_acc: 0.7083\n",
      "Epoch 522/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1599 - acc: 0.7994 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 523/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1614 - acc: 0.7948 - val_loss: 0.2046 - val_acc: 0.6667\n",
      "Epoch 524/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1646 - acc: 0.7932 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 525/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1588 - acc: 0.8025 - val_loss: 0.2043 - val_acc: 0.6667\n",
      "Epoch 526/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1585 - acc: 0.7994 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 527/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1603 - acc: 0.8025 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 528/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1589 - acc: 0.8056 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 529/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1596 - acc: 0.7978 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 530/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1583 - acc: 0.7932 - val_loss: 0.2043 - val_acc: 0.6667\n",
      "Epoch 531/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1642 - acc: 0.7855 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 532/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1606 - acc: 0.7963 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 533/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1612 - acc: 0.7963 - val_loss: 0.2008 - val_acc: 0.7083\n",
      "Epoch 534/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1570 - acc: 0.8040 - val_loss: 0.2026 - val_acc: 0.6806\n",
      "Epoch 535/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1635 - acc: 0.8040 - val_loss: 0.2028 - val_acc: 0.6806\n",
      "Epoch 536/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1654 - acc: 0.7886 - val_loss: 0.2012 - val_acc: 0.6944\n",
      "Epoch 537/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1596 - acc: 0.8025 - val_loss: 0.2009 - val_acc: 0.6667\n",
      "Epoch 538/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1606 - acc: 0.7978 - val_loss: 0.2001 - val_acc: 0.7083\n",
      "Epoch 539/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1599 - acc: 0.8040 - val_loss: 0.2012 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1601 - acc: 0.7994 - val_loss: 0.2016 - val_acc: 0.6667\n",
      "Epoch 541/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1602 - acc: 0.8164 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 542/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1644 - acc: 0.7948 - val_loss: 0.2011 - val_acc: 0.7083\n",
      "Epoch 543/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1603 - acc: 0.7963 - val_loss: 0.2008 - val_acc: 0.6806\n",
      "Epoch 544/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1590 - acc: 0.8056 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 545/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1636 - acc: 0.8071 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 546/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1619 - acc: 0.7978 - val_loss: 0.1985 - val_acc: 0.7083\n",
      "Epoch 547/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1580 - acc: 0.8071 - val_loss: 0.2003 - val_acc: 0.7083\n",
      "Epoch 548/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1587 - acc: 0.7886 - val_loss: 0.2013 - val_acc: 0.6806\n",
      "Epoch 549/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1644 - acc: 0.7994 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 550/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1663 - acc: 0.7762 - val_loss: 0.2016 - val_acc: 0.7083\n",
      "Epoch 551/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1635 - acc: 0.7886 - val_loss: 0.2026 - val_acc: 0.6806\n",
      "Epoch 552/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1607 - acc: 0.7978 - val_loss: 0.1987 - val_acc: 0.6944\n",
      "Epoch 553/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1664 - acc: 0.7809 - val_loss: 0.2025 - val_acc: 0.6667\n",
      "Epoch 554/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1605 - acc: 0.7994 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 555/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1572 - acc: 0.8009 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 556/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1617 - acc: 0.8025 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 557/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1600 - acc: 0.7855 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 558/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1559 - acc: 0.8102 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 559/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1608 - acc: 0.7994 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 560/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1584 - acc: 0.7978 - val_loss: 0.2025 - val_acc: 0.6806\n",
      "Epoch 561/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1590 - acc: 0.8086 - val_loss: 0.2010 - val_acc: 0.7083\n",
      "Epoch 562/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1606 - acc: 0.7978 - val_loss: 0.1988 - val_acc: 0.7083\n",
      "Epoch 563/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1621 - acc: 0.7901 - val_loss: 0.2009 - val_acc: 0.6667\n",
      "Epoch 564/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1598 - acc: 0.7932 - val_loss: 0.2002 - val_acc: 0.6667\n",
      "Epoch 565/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1625 - acc: 0.7948 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 566/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1625 - acc: 0.8071 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 567/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1567 - acc: 0.7901 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 568/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1607 - acc: 0.7994 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 569/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1592 - acc: 0.7948 - val_loss: 0.1995 - val_acc: 0.6944\n",
      "Epoch 570/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1610 - acc: 0.8102 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 571/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1589 - acc: 0.7932 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 572/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1630 - acc: 0.7870 - val_loss: 0.1986 - val_acc: 0.7083\n",
      "Epoch 573/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1607 - acc: 0.8040 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 574/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1580 - acc: 0.8148 - val_loss: 0.2011 - val_acc: 0.6667\n",
      "Epoch 575/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1563 - acc: 0.7963 - val_loss: 0.2013 - val_acc: 0.6667\n",
      "Epoch 576/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1587 - acc: 0.7948 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 577/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1576 - acc: 0.7963 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 578/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1597 - acc: 0.8025 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 579/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1577 - acc: 0.7917 - val_loss: 0.2014 - val_acc: 0.6667\n",
      "Epoch 580/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1638 - acc: 0.7994 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 581/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1570 - acc: 0.7978 - val_loss: 0.2050 - val_acc: 0.6667\n",
      "Epoch 582/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1595 - acc: 0.7917 - val_loss: 0.2043 - val_acc: 0.6667\n",
      "Epoch 583/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1580 - acc: 0.7994 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 584/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1561 - acc: 0.7978 - val_loss: 0.2006 - val_acc: 0.7083\n",
      "Epoch 585/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1602 - acc: 0.7870 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 586/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1644 - acc: 0.7824 - val_loss: 0.2016 - val_acc: 0.6667\n",
      "Epoch 587/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1580 - acc: 0.7994 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 588/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1581 - acc: 0.8025 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 589/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1566 - acc: 0.8225 - val_loss: 0.2008 - val_acc: 0.6806\n",
      "Epoch 590/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1581 - acc: 0.8056 - val_loss: 0.2034 - val_acc: 0.6806\n",
      "Epoch 591/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1597 - acc: 0.7948 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 592/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1594 - acc: 0.7994 - val_loss: 0.2049 - val_acc: 0.6667\n",
      "Epoch 593/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1621 - acc: 0.8071 - val_loss: 0.2018 - val_acc: 0.6667\n",
      "Epoch 594/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1639 - acc: 0.7948 - val_loss: 0.2059 - val_acc: 0.6667\n",
      "Epoch 595/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1572 - acc: 0.8086 - val_loss: 0.2041 - val_acc: 0.6806\n",
      "Epoch 596/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1622 - acc: 0.7948 - val_loss: 0.2025 - val_acc: 0.7083\n",
      "Epoch 597/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1550 - acc: 0.7963 - val_loss: 0.2006 - val_acc: 0.7083\n",
      "Epoch 598/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1537 - acc: 0.8009 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 599/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1640 - acc: 0.7994 - val_loss: 0.2006 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1585 - acc: 0.8117 - val_loss: 0.2021 - val_acc: 0.7083\n",
      "Epoch 601/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1547 - acc: 0.7948 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 602/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1604 - acc: 0.8025 - val_loss: 0.2028 - val_acc: 0.6806\n",
      "Epoch 603/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1567 - acc: 0.8056 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 604/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1496 - acc: 0.8009 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 605/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1554 - acc: 0.8086 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 606/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1576 - acc: 0.7994 - val_loss: 0.2000 - val_acc: 0.6806\n",
      "Epoch 607/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1581 - acc: 0.8148 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 608/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1563 - acc: 0.8056 - val_loss: 0.2033 - val_acc: 0.6667\n",
      "Epoch 609/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1536 - acc: 0.8086 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 610/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1557 - acc: 0.8086 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 611/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1619 - acc: 0.7762 - val_loss: 0.2004 - val_acc: 0.7083\n",
      "Epoch 612/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1553 - acc: 0.8025 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 613/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1536 - acc: 0.7963 - val_loss: 0.2024 - val_acc: 0.6667\n",
      "Epoch 614/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1596 - acc: 0.8102 - val_loss: 0.2004 - val_acc: 0.6806\n",
      "Epoch 615/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1538 - acc: 0.8133 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 616/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1582 - acc: 0.8040 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 617/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1598 - acc: 0.8117 - val_loss: 0.2020 - val_acc: 0.6667\n",
      "Epoch 618/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1621 - acc: 0.7901 - val_loss: 0.2003 - val_acc: 0.6667\n",
      "Epoch 619/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1542 - acc: 0.8071 - val_loss: 0.1996 - val_acc: 0.6667\n",
      "Epoch 620/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1619 - acc: 0.7978 - val_loss: 0.2017 - val_acc: 0.6806\n",
      "Epoch 621/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1615 - acc: 0.7840 - val_loss: 0.2011 - val_acc: 0.6667\n",
      "Epoch 622/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1571 - acc: 0.8117 - val_loss: 0.2001 - val_acc: 0.6806\n",
      "Epoch 623/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1585 - acc: 0.8009 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 624/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1552 - acc: 0.7963 - val_loss: 0.2038 - val_acc: 0.6667\n",
      "Epoch 625/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1570 - acc: 0.7978 - val_loss: 0.2020 - val_acc: 0.6944\n",
      "Epoch 626/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1544 - acc: 0.8102 - val_loss: 0.2003 - val_acc: 0.6806\n",
      "Epoch 627/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1576 - acc: 0.8040 - val_loss: 0.1996 - val_acc: 0.6806\n",
      "Epoch 628/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1568 - acc: 0.8009 - val_loss: 0.2012 - val_acc: 0.6667\n",
      "Epoch 629/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1576 - acc: 0.8102 - val_loss: 0.2016 - val_acc: 0.6944\n",
      "Epoch 630/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1580 - acc: 0.8102 - val_loss: 0.1995 - val_acc: 0.6944\n",
      "Epoch 631/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1535 - acc: 0.8117 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 632/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1567 - acc: 0.8009 - val_loss: 0.2022 - val_acc: 0.6667\n",
      "Epoch 633/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1580 - acc: 0.8102 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 634/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1600 - acc: 0.7948 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 635/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1536 - acc: 0.8164 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 636/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1565 - acc: 0.8025 - val_loss: 0.2022 - val_acc: 0.6806\n",
      "Epoch 637/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1576 - acc: 0.7963 - val_loss: 0.2023 - val_acc: 0.6667\n",
      "Epoch 638/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1549 - acc: 0.8117 - val_loss: 0.2009 - val_acc: 0.6667\n",
      "Epoch 639/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1567 - acc: 0.7963 - val_loss: 0.1990 - val_acc: 0.6944\n",
      "Epoch 640/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1573 - acc: 0.8009 - val_loss: 0.1993 - val_acc: 0.6944\n",
      "Epoch 641/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1604 - acc: 0.7978 - val_loss: 0.2007 - val_acc: 0.6667\n",
      "Epoch 642/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1541 - acc: 0.8210 - val_loss: 0.2005 - val_acc: 0.6806\n",
      "Epoch 643/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1596 - acc: 0.7948 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 644/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1591 - acc: 0.8009 - val_loss: 0.2002 - val_acc: 0.6806\n",
      "Epoch 645/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1584 - acc: 0.8025 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 646/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1539 - acc: 0.8056 - val_loss: 0.2038 - val_acc: 0.6806\n",
      "Epoch 647/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1579 - acc: 0.8009 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 648/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1612 - acc: 0.8009 - val_loss: 0.2048 - val_acc: 0.6667\n",
      "Epoch 649/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1580 - acc: 0.7886 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 650/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1597 - acc: 0.7948 - val_loss: 0.2030 - val_acc: 0.6667\n",
      "Epoch 651/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1549 - acc: 0.8009 - val_loss: 0.2016 - val_acc: 0.6944\n",
      "Epoch 652/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1577 - acc: 0.7994 - val_loss: 0.2002 - val_acc: 0.7083\n",
      "Epoch 653/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1558 - acc: 0.8102 - val_loss: 0.2039 - val_acc: 0.6667\n",
      "Epoch 654/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1584 - acc: 0.8040 - val_loss: 0.2005 - val_acc: 0.6806\n",
      "Epoch 655/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1505 - acc: 0.8086 - val_loss: 0.2007 - val_acc: 0.7083\n",
      "Epoch 656/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1583 - acc: 0.8040 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 657/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1553 - acc: 0.7963 - val_loss: 0.1986 - val_acc: 0.6944\n",
      "Epoch 658/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1562 - acc: 0.7963 - val_loss: 0.2027 - val_acc: 0.6806\n",
      "Epoch 659/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1559 - acc: 0.8117 - val_loss: 0.2023 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1561 - acc: 0.8009 - val_loss: 0.2077 - val_acc: 0.6667\n",
      "Epoch 661/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1589 - acc: 0.7994 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 662/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1574 - acc: 0.8117 - val_loss: 0.2017 - val_acc: 0.6944\n",
      "Epoch 663/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1539 - acc: 0.8148 - val_loss: 0.2034 - val_acc: 0.6806\n",
      "Epoch 664/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1583 - acc: 0.7948 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 665/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1552 - acc: 0.8179 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 666/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1554 - acc: 0.8102 - val_loss: 0.2021 - val_acc: 0.6667\n",
      "Epoch 667/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1575 - acc: 0.7994 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 668/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1557 - acc: 0.8009 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 669/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1517 - acc: 0.8102 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 670/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1612 - acc: 0.7917 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 671/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1563 - acc: 0.7886 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 672/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1551 - acc: 0.7994 - val_loss: 0.2044 - val_acc: 0.6667\n",
      "Epoch 673/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1553 - acc: 0.8056 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 674/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1562 - acc: 0.8056 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 675/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1557 - acc: 0.8009 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 676/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1557 - acc: 0.8164 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 677/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1553 - acc: 0.8117 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 678/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1589 - acc: 0.7917 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 679/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1555 - acc: 0.8009 - val_loss: 0.2015 - val_acc: 0.6944\n",
      "Epoch 680/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1539 - acc: 0.7978 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 681/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1580 - acc: 0.7901 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 682/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1558 - acc: 0.8056 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 683/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1537 - acc: 0.8164 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 684/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1520 - acc: 0.8164 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 685/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1555 - acc: 0.7994 - val_loss: 0.1995 - val_acc: 0.7083\n",
      "Epoch 686/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1558 - acc: 0.8117 - val_loss: 0.2029 - val_acc: 0.6944\n",
      "Epoch 687/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1540 - acc: 0.7963 - val_loss: 0.2033 - val_acc: 0.6944\n",
      "Epoch 688/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1558 - acc: 0.8056 - val_loss: 0.2023 - val_acc: 0.6944\n",
      "Epoch 689/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1547 - acc: 0.8133 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 690/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1531 - acc: 0.8148 - val_loss: 0.2022 - val_acc: 0.6944\n",
      "Epoch 691/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1545 - acc: 0.8117 - val_loss: 0.2028 - val_acc: 0.6806\n",
      "Epoch 692/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1547 - acc: 0.8102 - val_loss: 0.2023 - val_acc: 0.6944\n",
      "Epoch 693/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1595 - acc: 0.7917 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 694/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1566 - acc: 0.8086 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 695/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1548 - acc: 0.7994 - val_loss: 0.2006 - val_acc: 0.6806\n",
      "Epoch 696/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1598 - acc: 0.8056 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 697/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1535 - acc: 0.8133 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 698/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1527 - acc: 0.8102 - val_loss: 0.2025 - val_acc: 0.6667\n",
      "Epoch 699/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1572 - acc: 0.8040 - val_loss: 0.2032 - val_acc: 0.6806\n",
      "Epoch 700/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1573 - acc: 0.7963 - val_loss: 0.2023 - val_acc: 0.6667\n",
      "Epoch 701/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1557 - acc: 0.8086 - val_loss: 0.2025 - val_acc: 0.6667\n",
      "Epoch 702/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1584 - acc: 0.8040 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 703/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1586 - acc: 0.8056 - val_loss: 0.1990 - val_acc: 0.6944\n",
      "Epoch 704/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1559 - acc: 0.7963 - val_loss: 0.2006 - val_acc: 0.6667\n",
      "Epoch 705/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1553 - acc: 0.7963 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 706/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1576 - acc: 0.8025 - val_loss: 0.2017 - val_acc: 0.6944\n",
      "Epoch 707/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1561 - acc: 0.8009 - val_loss: 0.1999 - val_acc: 0.6944\n",
      "Epoch 708/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1525 - acc: 0.8148 - val_loss: 0.2035 - val_acc: 0.6667\n",
      "Epoch 709/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1552 - acc: 0.7901 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 710/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1582 - acc: 0.8133 - val_loss: 0.2020 - val_acc: 0.6944\n",
      "Epoch 711/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1571 - acc: 0.7994 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 712/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1532 - acc: 0.7901 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 713/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1598 - acc: 0.8009 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 714/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1524 - acc: 0.8164 - val_loss: 0.2044 - val_acc: 0.6806\n",
      "Epoch 715/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1548 - acc: 0.8040 - val_loss: 0.2013 - val_acc: 0.6806\n",
      "Epoch 716/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1542 - acc: 0.8148 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 717/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1590 - acc: 0.8086 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 718/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1543 - acc: 0.8071 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 719/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1554 - acc: 0.8148 - val_loss: 0.2025 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1513 - acc: 0.8164 - val_loss: 0.1988 - val_acc: 0.6944\n",
      "Epoch 721/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1521 - acc: 0.8071 - val_loss: 0.2007 - val_acc: 0.6944\n",
      "Epoch 722/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1526 - acc: 0.8056 - val_loss: 0.2031 - val_acc: 0.6667\n",
      "Epoch 723/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1536 - acc: 0.8009 - val_loss: 0.2044 - val_acc: 0.6806\n",
      "Epoch 724/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1530 - acc: 0.7994 - val_loss: 0.2019 - val_acc: 0.6667\n",
      "Epoch 725/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1575 - acc: 0.8117 - val_loss: 0.1988 - val_acc: 0.6944\n",
      "Epoch 726/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1561 - acc: 0.8040 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 727/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1533 - acc: 0.8056 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 728/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1552 - acc: 0.8164 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 729/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1577 - acc: 0.7963 - val_loss: 0.1994 - val_acc: 0.6944\n",
      "Epoch 730/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1552 - acc: 0.8056 - val_loss: 0.1988 - val_acc: 0.6944\n",
      "Epoch 731/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1533 - acc: 0.8133 - val_loss: 0.1984 - val_acc: 0.7083\n",
      "Epoch 732/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1469 - acc: 0.8164 - val_loss: 0.1999 - val_acc: 0.7083\n",
      "Epoch 733/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1587 - acc: 0.7994 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 734/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1596 - acc: 0.8086 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 735/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1513 - acc: 0.8102 - val_loss: 0.2041 - val_acc: 0.6806\n",
      "Epoch 736/1000\n",
      "648/648 [==============================] - 0s 136us/step - loss: 0.1506 - acc: 0.8318 - val_loss: 0.2046 - val_acc: 0.6806\n",
      "Epoch 737/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1568 - acc: 0.7917 - val_loss: 0.2033 - val_acc: 0.6806\n",
      "Epoch 738/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1542 - acc: 0.7901 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 739/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1609 - acc: 0.8056 - val_loss: 0.2013 - val_acc: 0.6944\n",
      "Epoch 740/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1571 - acc: 0.8133 - val_loss: 0.1980 - val_acc: 0.6944\n",
      "Epoch 741/1000\n",
      "648/648 [==============================] - 0s 131us/step - loss: 0.1521 - acc: 0.8102 - val_loss: 0.1993 - val_acc: 0.6944\n",
      "Epoch 742/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1555 - acc: 0.8086 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 743/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1561 - acc: 0.8086 - val_loss: 0.2025 - val_acc: 0.6806\n",
      "Epoch 744/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1561 - acc: 0.7994 - val_loss: 0.2005 - val_acc: 0.6806\n",
      "Epoch 745/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1534 - acc: 0.8086 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 746/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1521 - acc: 0.7963 - val_loss: 0.2004 - val_acc: 0.6806\n",
      "Epoch 747/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1543 - acc: 0.8179 - val_loss: 0.1995 - val_acc: 0.6944\n",
      "Epoch 748/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1582 - acc: 0.8086 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 749/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1519 - acc: 0.8117 - val_loss: 0.1980 - val_acc: 0.6944\n",
      "Epoch 750/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1532 - acc: 0.8194 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 751/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1533 - acc: 0.8086 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 752/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1589 - acc: 0.7978 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 753/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1548 - acc: 0.8040 - val_loss: 0.2007 - val_acc: 0.6944\n",
      "Epoch 754/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1536 - acc: 0.8009 - val_loss: 0.2032 - val_acc: 0.6806\n",
      "Epoch 755/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1568 - acc: 0.8117 - val_loss: 0.2036 - val_acc: 0.6806\n",
      "Epoch 756/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1565 - acc: 0.7932 - val_loss: 0.2043 - val_acc: 0.6806\n",
      "Epoch 757/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1565 - acc: 0.8056 - val_loss: 0.2026 - val_acc: 0.6667\n",
      "Epoch 758/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1539 - acc: 0.8071 - val_loss: 0.2052 - val_acc: 0.6667\n",
      "Epoch 759/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1516 - acc: 0.8117 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 760/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1562 - acc: 0.8056 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 761/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1544 - acc: 0.8194 - val_loss: 0.1999 - val_acc: 0.6944\n",
      "Epoch 762/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1544 - acc: 0.8086 - val_loss: 0.2037 - val_acc: 0.6806\n",
      "Epoch 763/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1537 - acc: 0.8040 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 764/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1534 - acc: 0.8025 - val_loss: 0.2022 - val_acc: 0.6806\n",
      "Epoch 765/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1533 - acc: 0.7963 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 766/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1594 - acc: 0.7994 - val_loss: 0.1978 - val_acc: 0.7083\n",
      "Epoch 767/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1534 - acc: 0.8194 - val_loss: 0.2044 - val_acc: 0.6667\n",
      "Epoch 768/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1531 - acc: 0.8179 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 769/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1533 - acc: 0.8086 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 770/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1532 - acc: 0.8256 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 771/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1511 - acc: 0.8040 - val_loss: 0.2037 - val_acc: 0.6667\n",
      "Epoch 772/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1560 - acc: 0.8086 - val_loss: 0.2026 - val_acc: 0.6806\n",
      "Epoch 773/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1520 - acc: 0.8056 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 774/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1541 - acc: 0.8164 - val_loss: 0.2030 - val_acc: 0.6667\n",
      "Epoch 775/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1498 - acc: 0.8086 - val_loss: 0.2028 - val_acc: 0.6667\n",
      "Epoch 776/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1537 - acc: 0.8225 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 777/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1510 - acc: 0.8241 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 778/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1526 - acc: 0.8148 - val_loss: 0.2037 - val_acc: 0.6806\n",
      "Epoch 779/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1522 - acc: 0.8133 - val_loss: 0.1985 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1553 - acc: 0.7917 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 781/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1533 - acc: 0.8133 - val_loss: 0.1985 - val_acc: 0.6944\n",
      "Epoch 782/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1541 - acc: 0.8040 - val_loss: 0.1982 - val_acc: 0.7083\n",
      "Epoch 783/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1536 - acc: 0.8102 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 784/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1550 - acc: 0.8102 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 785/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1487 - acc: 0.8225 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 786/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1535 - acc: 0.8117 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 787/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1545 - acc: 0.8102 - val_loss: 0.2035 - val_acc: 0.6806\n",
      "Epoch 788/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1565 - acc: 0.7978 - val_loss: 0.2032 - val_acc: 0.6806\n",
      "Epoch 789/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1549 - acc: 0.8117 - val_loss: 0.1994 - val_acc: 0.6944\n",
      "Epoch 790/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1541 - acc: 0.8086 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 791/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1578 - acc: 0.8025 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 792/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1552 - acc: 0.8056 - val_loss: 0.2007 - val_acc: 0.6944\n",
      "Epoch 793/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1508 - acc: 0.8133 - val_loss: 0.2022 - val_acc: 0.6806\n",
      "Epoch 794/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1523 - acc: 0.8148 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 795/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1547 - acc: 0.7963 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 796/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1541 - acc: 0.7963 - val_loss: 0.2030 - val_acc: 0.7083\n",
      "Epoch 797/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1504 - acc: 0.8117 - val_loss: 0.2058 - val_acc: 0.6806\n",
      "Epoch 798/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1563 - acc: 0.8117 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 799/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1566 - acc: 0.7948 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 800/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1506 - acc: 0.8102 - val_loss: 0.2007 - val_acc: 0.6944\n",
      "Epoch 801/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1528 - acc: 0.8194 - val_loss: 0.1987 - val_acc: 0.6944\n",
      "Epoch 802/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1499 - acc: 0.8164 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 803/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1520 - acc: 0.7978 - val_loss: 0.2023 - val_acc: 0.6944\n",
      "Epoch 804/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1526 - acc: 0.8117 - val_loss: 0.2012 - val_acc: 0.6944\n",
      "Epoch 805/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1506 - acc: 0.8056 - val_loss: 0.2033 - val_acc: 0.6806\n",
      "Epoch 806/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1512 - acc: 0.8117 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 807/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1543 - acc: 0.8102 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 808/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1540 - acc: 0.8102 - val_loss: 0.2012 - val_acc: 0.6944\n",
      "Epoch 809/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1528 - acc: 0.8040 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 810/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1535 - acc: 0.8117 - val_loss: 0.2030 - val_acc: 0.6806\n",
      "Epoch 811/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1532 - acc: 0.8179 - val_loss: 0.2005 - val_acc: 0.6806\n",
      "Epoch 812/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1532 - acc: 0.8102 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 813/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1541 - acc: 0.8056 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 814/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1544 - acc: 0.7978 - val_loss: 0.2016 - val_acc: 0.6806\n",
      "Epoch 815/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1558 - acc: 0.7917 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 816/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1513 - acc: 0.8102 - val_loss: 0.2017 - val_acc: 0.6667\n",
      "Epoch 817/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1545 - acc: 0.8086 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 818/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1539 - acc: 0.8102 - val_loss: 0.2029 - val_acc: 0.6667\n",
      "Epoch 819/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1534 - acc: 0.8056 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 820/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1533 - acc: 0.8086 - val_loss: 0.1981 - val_acc: 0.6944\n",
      "Epoch 821/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1521 - acc: 0.8164 - val_loss: 0.2025 - val_acc: 0.6806\n",
      "Epoch 822/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1527 - acc: 0.8040 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 823/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1510 - acc: 0.8210 - val_loss: 0.2025 - val_acc: 0.6806\n",
      "Epoch 824/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1555 - acc: 0.8009 - val_loss: 0.1996 - val_acc: 0.6944\n",
      "Epoch 825/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1535 - acc: 0.8040 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 826/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1537 - acc: 0.7963 - val_loss: 0.2026 - val_acc: 0.6806\n",
      "Epoch 827/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1523 - acc: 0.7978 - val_loss: 0.2017 - val_acc: 0.6944\n",
      "Epoch 828/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1537 - acc: 0.8117 - val_loss: 0.1993 - val_acc: 0.6944\n",
      "Epoch 829/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1540 - acc: 0.8086 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 830/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1522 - acc: 0.8102 - val_loss: 0.2026 - val_acc: 0.6944\n",
      "Epoch 831/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1510 - acc: 0.8194 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 832/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1501 - acc: 0.7994 - val_loss: 0.2036 - val_acc: 0.6806\n",
      "Epoch 833/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1484 - acc: 0.8225 - val_loss: 0.2050 - val_acc: 0.6806\n",
      "Epoch 834/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1543 - acc: 0.8102 - val_loss: 0.2013 - val_acc: 0.6944\n",
      "Epoch 835/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1532 - acc: 0.7963 - val_loss: 0.1972 - val_acc: 0.7083\n",
      "Epoch 836/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1573 - acc: 0.7978 - val_loss: 0.1995 - val_acc: 0.6944\n",
      "Epoch 837/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1514 - acc: 0.8086 - val_loss: 0.1986 - val_acc: 0.6944\n",
      "Epoch 838/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1485 - acc: 0.8009 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 839/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1535 - acc: 0.8148 - val_loss: 0.1995 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1520 - acc: 0.8117 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 841/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1522 - acc: 0.8025 - val_loss: 0.2028 - val_acc: 0.6806\n",
      "Epoch 842/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1472 - acc: 0.8164 - val_loss: 0.2008 - val_acc: 0.6667\n",
      "Epoch 843/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1551 - acc: 0.8102 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 844/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1573 - acc: 0.7978 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 845/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1509 - acc: 0.8194 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 846/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1507 - acc: 0.8102 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 847/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1541 - acc: 0.8164 - val_loss: 0.2017 - val_acc: 0.6806\n",
      "Epoch 848/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1540 - acc: 0.7994 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 849/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1504 - acc: 0.8133 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 850/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1530 - acc: 0.8102 - val_loss: 0.2015 - val_acc: 0.6944\n",
      "Epoch 851/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1568 - acc: 0.8040 - val_loss: 0.2025 - val_acc: 0.6667\n",
      "Epoch 852/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1565 - acc: 0.8102 - val_loss: 0.1982 - val_acc: 0.7083\n",
      "Epoch 853/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1488 - acc: 0.8117 - val_loss: 0.1998 - val_acc: 0.6944\n",
      "Epoch 854/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1485 - acc: 0.8210 - val_loss: 0.2040 - val_acc: 0.6806\n",
      "Epoch 855/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1550 - acc: 0.8117 - val_loss: 0.2027 - val_acc: 0.6944\n",
      "Epoch 856/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1481 - acc: 0.7978 - val_loss: 0.2027 - val_acc: 0.6667\n",
      "Epoch 857/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1496 - acc: 0.8102 - val_loss: 0.2043 - val_acc: 0.6667\n",
      "Epoch 858/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1479 - acc: 0.8179 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 859/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1508 - acc: 0.8194 - val_loss: 0.2018 - val_acc: 0.6944\n",
      "Epoch 860/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1559 - acc: 0.7948 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 861/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1537 - acc: 0.8071 - val_loss: 0.2019 - val_acc: 0.6944\n",
      "Epoch 862/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1533 - acc: 0.8117 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 863/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1527 - acc: 0.8179 - val_loss: 0.2026 - val_acc: 0.6944\n",
      "Epoch 864/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1535 - acc: 0.8056 - val_loss: 0.2013 - val_acc: 0.6944\n",
      "Epoch 865/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1546 - acc: 0.7932 - val_loss: 0.2010 - val_acc: 0.6806\n",
      "Epoch 866/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1486 - acc: 0.8194 - val_loss: 0.2016 - val_acc: 0.6806\n",
      "Epoch 867/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1568 - acc: 0.8102 - val_loss: 0.1987 - val_acc: 0.6944\n",
      "Epoch 868/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1491 - acc: 0.8102 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 869/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1506 - acc: 0.8133 - val_loss: 0.1980 - val_acc: 0.6944\n",
      "Epoch 870/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1512 - acc: 0.8102 - val_loss: 0.2008 - val_acc: 0.6806\n",
      "Epoch 871/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1579 - acc: 0.8133 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 872/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1565 - acc: 0.8009 - val_loss: 0.2013 - val_acc: 0.6944\n",
      "Epoch 873/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1492 - acc: 0.8086 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 874/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1477 - acc: 0.8241 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 875/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1527 - acc: 0.8102 - val_loss: 0.1998 - val_acc: 0.6944\n",
      "Epoch 876/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1508 - acc: 0.8148 - val_loss: 0.2007 - val_acc: 0.6944\n",
      "Epoch 877/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1496 - acc: 0.8133 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 878/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1544 - acc: 0.7870 - val_loss: 0.2013 - val_acc: 0.7083\n",
      "Epoch 879/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1512 - acc: 0.8164 - val_loss: 0.2016 - val_acc: 0.6944\n",
      "Epoch 880/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1525 - acc: 0.8117 - val_loss: 0.2030 - val_acc: 0.6806\n",
      "Epoch 881/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1502 - acc: 0.8210 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 882/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1501 - acc: 0.8241 - val_loss: 0.2030 - val_acc: 0.6806\n",
      "Epoch 883/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1513 - acc: 0.8025 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 884/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1565 - acc: 0.8133 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 885/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1534 - acc: 0.8102 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 886/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1518 - acc: 0.8086 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 887/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1520 - acc: 0.8194 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 888/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1539 - acc: 0.8056 - val_loss: 0.1996 - val_acc: 0.6944\n",
      "Epoch 889/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1526 - acc: 0.8194 - val_loss: 0.2026 - val_acc: 0.6944\n",
      "Epoch 890/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1574 - acc: 0.8179 - val_loss: 0.2020 - val_acc: 0.6944\n",
      "Epoch 891/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1530 - acc: 0.8025 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 892/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1499 - acc: 0.8086 - val_loss: 0.1976 - val_acc: 0.6944\n",
      "Epoch 893/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1510 - acc: 0.8148 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 894/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1570 - acc: 0.8056 - val_loss: 0.2030 - val_acc: 0.6944\n",
      "Epoch 895/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1550 - acc: 0.8040 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 896/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1533 - acc: 0.8071 - val_loss: 0.1990 - val_acc: 0.6944\n",
      "Epoch 897/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1475 - acc: 0.8225 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 898/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1507 - acc: 0.8056 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 899/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1511 - acc: 0.8194 - val_loss: 0.2033 - val_acc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1518 - acc: 0.8102 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 901/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1498 - acc: 0.8148 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 902/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1554 - acc: 0.7948 - val_loss: 0.2025 - val_acc: 0.6806\n",
      "Epoch 903/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1498 - acc: 0.8210 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 904/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1514 - acc: 0.8086 - val_loss: 0.2011 - val_acc: 0.6806\n",
      "Epoch 905/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1512 - acc: 0.8102 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 906/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1483 - acc: 0.8102 - val_loss: 0.2028 - val_acc: 0.6944\n",
      "Epoch 907/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1503 - acc: 0.8086 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 908/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1471 - acc: 0.8148 - val_loss: 0.2051 - val_acc: 0.6806\n",
      "Epoch 909/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1539 - acc: 0.8164 - val_loss: 0.2018 - val_acc: 0.6944\n",
      "Epoch 910/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1534 - acc: 0.7870 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 911/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1492 - acc: 0.8272 - val_loss: 0.2031 - val_acc: 0.6944\n",
      "Epoch 912/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1503 - acc: 0.8040 - val_loss: 0.2045 - val_acc: 0.6944\n",
      "Epoch 913/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1481 - acc: 0.8241 - val_loss: 0.2049 - val_acc: 0.6944\n",
      "Epoch 914/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1439 - acc: 0.8364 - val_loss: 0.2060 - val_acc: 0.6806\n",
      "Epoch 915/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1502 - acc: 0.8025 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 916/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1541 - acc: 0.8256 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 917/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1496 - acc: 0.8194 - val_loss: 0.2041 - val_acc: 0.6944\n",
      "Epoch 918/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1532 - acc: 0.8040 - val_loss: 0.2034 - val_acc: 0.6944\n",
      "Epoch 919/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1440 - acc: 0.8148 - val_loss: 0.2058 - val_acc: 0.6806\n",
      "Epoch 920/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1524 - acc: 0.8086 - val_loss: 0.2031 - val_acc: 0.6806\n",
      "Epoch 921/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1500 - acc: 0.8194 - val_loss: 0.2046 - val_acc: 0.6806\n",
      "Epoch 922/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1514 - acc: 0.7978 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 923/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1502 - acc: 0.8148 - val_loss: 0.2093 - val_acc: 0.6806\n",
      "Epoch 924/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1490 - acc: 0.8256 - val_loss: 0.1997 - val_acc: 0.6806\n",
      "Epoch 925/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1472 - acc: 0.8287 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 926/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1502 - acc: 0.8148 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 927/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1543 - acc: 0.8040 - val_loss: 0.2026 - val_acc: 0.6806\n",
      "Epoch 928/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1504 - acc: 0.8040 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 929/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1520 - acc: 0.8210 - val_loss: 0.2023 - val_acc: 0.6944\n",
      "Epoch 930/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1522 - acc: 0.8148 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 931/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1485 - acc: 0.8117 - val_loss: 0.2024 - val_acc: 0.6944\n",
      "Epoch 932/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1520 - acc: 0.8148 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 933/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1543 - acc: 0.8025 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 934/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1496 - acc: 0.8071 - val_loss: 0.1989 - val_acc: 0.6944\n",
      "Epoch 935/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1484 - acc: 0.8071 - val_loss: 0.2054 - val_acc: 0.6944\n",
      "Epoch 936/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1510 - acc: 0.8071 - val_loss: 0.2019 - val_acc: 0.6806\n",
      "Epoch 937/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1500 - acc: 0.8025 - val_loss: 0.2010 - val_acc: 0.6806\n",
      "Epoch 938/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1533 - acc: 0.8086 - val_loss: 0.2010 - val_acc: 0.6944\n",
      "Epoch 939/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1562 - acc: 0.8025 - val_loss: 0.1971 - val_acc: 0.6944\n",
      "Epoch 940/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1463 - acc: 0.8194 - val_loss: 0.2008 - val_acc: 0.6944\n",
      "Epoch 941/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1540 - acc: 0.8040 - val_loss: 0.1995 - val_acc: 0.6944\n",
      "Epoch 942/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1514 - acc: 0.8040 - val_loss: 0.1973 - val_acc: 0.6944\n",
      "Epoch 943/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1565 - acc: 0.7978 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 944/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1474 - acc: 0.8164 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 945/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1518 - acc: 0.8117 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 946/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1456 - acc: 0.8210 - val_loss: 0.1999 - val_acc: 0.6806\n",
      "Epoch 947/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1517 - acc: 0.8148 - val_loss: 0.2030 - val_acc: 0.6944\n",
      "Epoch 948/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1469 - acc: 0.8086 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 949/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1504 - acc: 0.8194 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 950/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1566 - acc: 0.8194 - val_loss: 0.1996 - val_acc: 0.6944\n",
      "Epoch 951/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1457 - acc: 0.8148 - val_loss: 0.2022 - val_acc: 0.6806\n",
      "Epoch 952/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1448 - acc: 0.8194 - val_loss: 0.2047 - val_acc: 0.6806\n",
      "Epoch 953/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1520 - acc: 0.8225 - val_loss: 0.1996 - val_acc: 0.6806\n",
      "Epoch 954/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1505 - acc: 0.8086 - val_loss: 0.2016 - val_acc: 0.6806\n",
      "Epoch 955/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1519 - acc: 0.8071 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 956/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1530 - acc: 0.8102 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 957/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1498 - acc: 0.8071 - val_loss: 0.2018 - val_acc: 0.6806\n",
      "Epoch 958/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1512 - acc: 0.8025 - val_loss: 0.2036 - val_acc: 0.6806\n",
      "Epoch 959/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1487 - acc: 0.8179 - val_loss: 0.2044 - val_acc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1503 - acc: 0.8071 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 961/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1502 - acc: 0.8117 - val_loss: 0.2044 - val_acc: 0.6806\n",
      "Epoch 962/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1498 - acc: 0.8148 - val_loss: 0.2010 - val_acc: 0.6806\n",
      "Epoch 963/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1534 - acc: 0.8148 - val_loss: 0.1994 - val_acc: 0.6944\n",
      "Epoch 964/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1512 - acc: 0.8241 - val_loss: 0.2006 - val_acc: 0.6806\n",
      "Epoch 965/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1490 - acc: 0.8117 - val_loss: 0.2045 - val_acc: 0.6944\n",
      "Epoch 966/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1544 - acc: 0.8148 - val_loss: 0.2012 - val_acc: 0.6806\n",
      "Epoch 967/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1499 - acc: 0.8086 - val_loss: 0.2009 - val_acc: 0.6806\n",
      "Epoch 968/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1472 - acc: 0.8225 - val_loss: 0.2033 - val_acc: 0.6806\n",
      "Epoch 969/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1495 - acc: 0.8256 - val_loss: 0.2039 - val_acc: 0.6944\n",
      "Epoch 970/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1535 - acc: 0.8086 - val_loss: 0.2023 - val_acc: 0.6944\n",
      "Epoch 971/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1528 - acc: 0.8117 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 972/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1512 - acc: 0.8179 - val_loss: 0.2013 - val_acc: 0.6806\n",
      "Epoch 973/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1487 - acc: 0.8194 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 974/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1495 - acc: 0.8194 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 975/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1438 - acc: 0.8164 - val_loss: 0.2005 - val_acc: 0.6944\n",
      "Epoch 976/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1480 - acc: 0.8133 - val_loss: 0.2021 - val_acc: 0.6806\n",
      "Epoch 977/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1496 - acc: 0.8071 - val_loss: 0.1999 - val_acc: 0.6944\n",
      "Epoch 978/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1502 - acc: 0.8117 - val_loss: 0.2063 - val_acc: 0.6944\n",
      "Epoch 979/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1529 - acc: 0.8210 - val_loss: 0.2078 - val_acc: 0.6806\n",
      "Epoch 980/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1520 - acc: 0.8133 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 981/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1497 - acc: 0.8102 - val_loss: 0.2003 - val_acc: 0.6806\n",
      "Epoch 982/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1484 - acc: 0.8272 - val_loss: 0.2030 - val_acc: 0.6806\n",
      "Epoch 983/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1483 - acc: 0.8117 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 984/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1522 - acc: 0.8086 - val_loss: 0.2007 - val_acc: 0.6806\n",
      "Epoch 985/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1487 - acc: 0.8071 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 986/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1463 - acc: 0.8225 - val_loss: 0.2029 - val_acc: 0.6806\n",
      "Epoch 987/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1557 - acc: 0.8009 - val_loss: 0.2040 - val_acc: 0.6944\n",
      "Epoch 988/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1529 - acc: 0.8086 - val_loss: 0.1990 - val_acc: 0.6944\n",
      "Epoch 989/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1488 - acc: 0.8272 - val_loss: 0.2014 - val_acc: 0.6944\n",
      "Epoch 990/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1511 - acc: 0.8179 - val_loss: 0.2039 - val_acc: 0.6944\n",
      "Epoch 991/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1505 - acc: 0.8179 - val_loss: 0.2022 - val_acc: 0.6944\n",
      "Epoch 992/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1475 - acc: 0.8210 - val_loss: 0.1985 - val_acc: 0.6806\n",
      "Epoch 993/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1500 - acc: 0.8086 - val_loss: 0.1975 - val_acc: 0.6944\n",
      "Epoch 994/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1503 - acc: 0.8164 - val_loss: 0.2024 - val_acc: 0.6806\n",
      "Epoch 995/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1502 - acc: 0.8071 - val_loss: 0.2023 - val_acc: 0.6806\n",
      "Epoch 996/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1556 - acc: 0.8102 - val_loss: 0.1991 - val_acc: 0.6944\n",
      "Epoch 997/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1471 - acc: 0.8148 - val_loss: 0.2027 - val_acc: 0.6806\n",
      "Epoch 998/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1486 - acc: 0.8133 - val_loss: 0.2020 - val_acc: 0.6806\n",
      "Epoch 999/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1486 - acc: 0.8056 - val_loss: 0.2036 - val_acc: 0.6944\n",
      "Epoch 1000/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1462 - acc: 0.8194 - val_loss: 0.2053 - val_acc: 0.6806\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, validation_split=0.1, epochs=1000,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 75.00% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b1791d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcXHWZ7/HPU3vvS7qzNqETCCELWdo2gqAEIwiooMgIGRkEl7yGcb0494qOV5TRO8wdR+PCiKjAnRkHLooKIoJzHRSQNdEkZCEkZO2kSS9Jeu9an/vH73Sl0ql0Oumurk7X8369+pWqc37nnOfUqdS3fuecOkdUFWOMMQbAl+8CjDHGjB8WCsYYY9IsFIwxxqRZKBhjjEmzUDDGGJNmoWCMMSbNQsGYIYhIvYioiASG0fYmEXl2LOoyJlcsFMyEISK7RCQmIjWDhq/zPtjr81PZyYWLMflkoWAmmp3AyoEnInIeUJS/cow5vVgomInm34AbM55/GPjXzAYiUiEi/yoirSKyW0S+JCI+b5xfRL4hIm0isgN4d5ZpfywizSKyT0S+JiL+kRQsImERWS0i+72/1SIS9sbViMhjInJYRA6KyDMZtX7eq6FLRLaKyIqR1GEMWCiYiecFoFxE5nkf1tcB/z6ozXeBCmA2cDEuRG72xn0ceA+wFGgErh007f8BEsDZXpvLgI+NsOa/A84HlgCLgWXAl7xxnwOagFpgCvBFQEVkLvBJ4M2qWga8C9g1wjqMsVAwE9JAb+FS4FVg38CIjKD4gqp2qeou4J+Bv/KafBBYrap7VfUg8A8Z004BrgA+q6o9qtoCfAu4foT1fgi4Q1VbVLUV+GpGPXFgGnCmqsZV9Rl1FyxLAmFgvogEVXWXqr4+wjqMsVAwE9K/AX8J3MSgXUdADRACdmcM2w3M8B5PB/YOGjfgTCAINHu7cw4DPwAmj7De6Vnqme49/idgO/BbEdkhIrcBqOp24LPAV4AWEXlQRKZjzAhZKJgJR1V34w44Xwn8fNDoNty37zMzhs3kSG+iGThj0LgBe4EoUKOqld5fuaouGGHJ+7PUs99bly5V/ZyqzgbeC9w6cOxAVf9DVS/yplXgH0dYhzEWCmbC+ijwDlXtyRyoqkngIeDrIlImImcCt3LkuMNDwKdFpE5EqoDbMqZtBn4L/LOIlIuIT0TOEpGLT6KusIhEMv58wAPAl0Sk1jud9ssD9YjIe0TkbBERoBO32ygpInNF5B3eAel+oM8bZ8yIWCiYCUlVX1fVNccZ/SmgB9gBPAv8B3CvN+6HwJPAeuBPHNvTuBG3+2kzcAj4GW6f/3B14z7AB/7eAXwNWANsAF7xlvs1r/0c4P950z0P/Iuq/h53POFOXM/nDdwurC+eRB3GZCV2kx1jjDEDrKdgjDEmzULBGGNMmoWCMcaYNAsFY4wxaafdFRtramq0vr4+32UYY8xpZe3atW2qWnuidqddKNTX17NmzfHONDTGGJONiOw+cSvbfWSMMSaDhYIxxpi0nIWCiNwrIi0isvE44ytE5Fcisl5ENonIzdnaGWOMGTu5PKZwP/A9jr1K5YBPAJtV9b0iUgtsFZGfqGrsZBcUj8dpamqiv7//1Ks1x4hEItTV1REMBvNdijFmjOQsFFT16RPcE1eBMu9CX6XAQdzNS05aU1MTZWVl1NfX42ZnRkpVaW9vp6mpiVmzZuW7HGPMGMnnMYXvAfNwlwh+BfiMqqayNRSRVSKyRkTWtLa2HjO+v7+fSZMmWSCMIhFh0qRJ1vsypsDkMxTeBazD3UxkCfA9ESnP1lBV71HVRlVtrK3NfpqtBcLos9fUmMKTz1C4Gfi5OttxN0U5N1cL648neaOjn0Qya2fEGGMM+Q2FPcAKSN/7di7u+vY5EY0naenqJ5Ea/UuFt7e3s2TJEpYsWcLUqVOZMWNG+nksNrzj5jfffDNbt24dss1dd93FT37yk9Eo2RhjssrZgWYReQBYDtSISBNwO+7+tqjq3cDfA/eLyCuAAJ9X1bYc1gNAKgf3j5g0aRLr1q0D4Ctf+QqlpaX87d/+7VFtVBVVxefLnsP33XffCZfziU98YuTFGmPMEHLWU1DVlao6TVWDqlqnqj9W1bu9QEBV96vqZap6nqouVNV/P9E8R2Jg9/hY3lNo+/btLFy4kL/+67+moaGB5uZmVq1aRWNjIwsWLOCOO+5It73oootYt24diUSCyspKbrvtNhYvXswFF1xAS0sLAF/60pdYvXp1uv1tt93GsmXLmDt3Ls899xwAPT09fOADH2Dx4sWsXLmSxsbGdGAZY8yJnHbXPjqRr/5qE5v3dx4zPJlS+uNJIkE/ft/JHUCdP72c2997avdm37x5M/fddx933303AHfeeSfV1dUkEgkuueQSrr32WubPn3/UNB0dHVx88cXceeed3Hrrrdx7773cdtttx8xbVXnppZd49NFHueOOO3jiiSf47ne/y9SpU3n44YdZv349DQ0Np1S3MaYwFcxlLvJ1Is1ZZ53Fm9/85vTzBx54gIaGBhoaGtiyZQubN28+ZpqioiKuuOIKAN70pjexa9eurPO+5pprjmnz7LPPcv311wOwePFiFiw4tTAzxhSmCddTON43+t5Ygu0t3dRPKqG8aOx+oVtSUpJ+vG3bNr797W/z0ksvUVlZyQ033JD1dwChUCj92O/3k0hk/01fOBw+po3dc9sYMxIF1FNwXYV8fmh2dnZSVlZGeXk5zc3NPPnkk6O+jIsuuoiHHnoIgFdeeSVrT8QYY45nwvUUjsefjFIjnaDhvNXQ0NDA/PnzWbhwIbNnz+bCCy8c9WV86lOf4sYbb2TRokU0NDSwcOFCKioqRn05xpiJSU633Q2NjY06+CY7W7ZsYd68eUNOF+8+SLBzNx2lZ1FRnvWH0xNCIpEgkUgQiUTYtm0bl112Gdu2bSMQOLX8H85ra4wZ/0Rkrao2nqhdwfQUZOD3AadZCJ6s7u5uVqxYQSKRQFX5wQ9+cMqBYIwpPAXzaXHkmMLEvsxFZWUla9euzXcZxpjTVAEdaB7oKUzsUDDGmJEomFBACmP3kTHGjETBhIIM/IrZegrGGHNchRMK6VW1noIxxhxPwYTCkSvijX5PYfny5cf8EG316tX8zd/8zXGnKS0tBWD//v1ce+21x53v4NNvB1u9ejW9vb3p51deeSWHDx8ebunGGHOUAgqF3B1TWLlyJQ8++OBRwx588EFWrlx5wmmnT5/Oz372s1Ne9uBQePzxx6msrDzl+RljClsBhULurp197bXX8thjjxGNRgHYtWsX+/fvZ8mSJaxYsYKGhgbOO+88HnnkkWOm3bVrFwsXLgSgr6+P66+/nkWLFnHdddfR19eXbnfLLbekL7l9++23A/Cd73yH/fv3c8kll3DJJZcAUF9fT1ubuy3FN7/5TRYuXMjChQvTl9zetWsX8+bN4+Mf/zgLFizgsssuO2o5xpjClsub7NwLvAdoUdWFx2mzHFiNu/lOm6pePOIF/+Y2eOOVLCMUYt2UShCCkZOb59Tz4Io7jzt60qRJLFu2jCeeeIKrr76aBx98kOuuu46ioiJ+8YtfUF5eTltbG+effz5XXXXVce99/P3vf5/i4mI2bNjAhg0bjrrs9de//nWqq6tJJpOsWLGCDRs28OlPf5pvfvObPPXUU9TU1Bw1r7Vr13Lffffx4osvoqq85S1v4eKLL6aqqopt27bxwAMP8MMf/pAPfvCDPPzww9xwww0n95oYYyakXPYU7gcuP95IEakE/gW4SlUXAH+Rw1pyLnMX0sCuI1Xli1/8IosWLeKd73wn+/bt48CBA8edx9NPP53+cF60aBGLFi1Kj3vooYdoaGhg6dKlbNq06YQXunv22Wd5//vfT0lJCaWlpVxzzTU888wzAMyaNYslS5YAQ1+a2xhTeHLWU1DVp0Wkfogmfwn8XFX3eO1bRmXBQ3yjT+1fR4+/ioopZ47KojK9733v49Zbb+VPf/oTfX19NDQ0cP/999Pa2sratWsJBoPU19dnvVR2pmy9iJ07d/KNb3yDl19+maqqKm666aYTzmeoa1oNXHIb3GW3bfeRMWZAPo8pnANUicjvRWStiNx4vIYiskpE1ojImtbW1lNeoCI5+51CaWkpy5cv5yMf+Uj6AHNHRweTJ08mGAzy1FNPsXv37iHn8fa3v52f/OQnAGzcuJENGzYA7pLbJSUlVFRUcODAAX7zm9+kpykrK6OrqyvrvH75y1/S29tLT08Pv/jFL3jb2942WqtrjJmg8nntowDwJmAFUAQ8LyIvqOprgxuq6j3APeCuknqqC1QEyeHvFFauXMk111yT3o30oQ99iPe+9700NjayZMkSzj333CGnv+WWW7j55ptZtGgRS5YsYdmyZYC7g9rSpUtZsGDBMZfcXrVqFVdccQXTpk3jqaeeSg9vaGjgpptuSs/jYx/7GEuXLrVdRcaYIeX00tne7qPHsh1oFpHbgIiqfsV7/mPgCVX96VDzPNVLZwPE979CnxRTPu2s4a5CwbNLZxszMQz30tn53H30CPA2EQmISDHwFmBLbhcpCHaZC2OMOZ5cnpL6ALAcqBGRJuB23KmnqOrdqrpFRJ4ANgAp4EequjFX9QCoCGIXxDPGmOPK5dlHJ/w5r6r+E/BPo7S8457/n26DD7v20fCdbnflM8aM3IT4RXMkEqG9vf3EH2KS2wPNE4mq0t7eTiRykj/0M8ac1ibEndfq6upoamriRKerxjsPoKkUoQ4LhuGIRCLU1dXluwxjzBiaEKEQDAaZNWvWCdttW/05Yof2Me+r68egKmOMOf1MiN1Hw6X+MEGN275yY4w5joILhTBxogk7LdUYY7IpqFAgECYscaJxCwVjjMmmwEIhQog40UQy35UYY8y4VFChIAG3+6jfegrGGJNVYYVCMOJCwXoKxhiTVWGFQiBCQFJEo7F8l2KMMeNSQYWCP+huLhOL2k1ljDEmm4IKBV/IXbIh1t+T50qMMWZ8KqhQ8IeKAYhHh76VpTHGFKrCCoWwC4VktDvPlRhjzPhUUKEQ8HoKCTumYIwxWeUsFETkXhFpEZEhb5wjIm8WkaSIXJurWgYEIyUAJKO9uV6UMcaclnLZU7gfuHyoBiLiB/4ReDKHdaQFBnYfxSwUjDEmm5yFgqo+DRw8QbNPAQ8DLbmqI1OwyPUUNG6hYIwx2eTtmIKIzADeD9w9jLarRGSNiKw50Y10hhKKuJ6CxuyYgjHGZJPPA82rgc+r6gmvOaGq96hqo6o21tbWnvICJehCgbiFgjHGZJPPO681Ag+KCEANcKWIJFT1lzlbYrAIAE1YKBhjTDZ5CwVVTd8/U0TuBx7LaSBAOhR81lMwxpischYKIvIAsByoEZEm4HYgCKCqJzyOkBMBFwok7BfNxhiTTc5CQVVXnkTbm3JVx1H8QZL48NnuI2OMyaqgftGMCFEJ40tG812JMcaMS4UVCkBMwviT1lMwxphsCi4U4hImkLRjCsYYk03hhYIvTCBlu4+MMSabgguFhC9CMGU9BWOMyabwQsEfIWg9BWOMyargQiHpjxBSCwVjjMmm4EIh5Y8QtFAwxpisCi4Ukv4IEY2iqvkuxRhjxp2CCwUCEcISJ560UDDGmMEKLhQ0WEQRUfriJ7xitzHGFJyCCwUJFhMhRl/MQsEYYwYrvFAIFRGROH2xeL5LMcaYcafgQsEXcndf6+vtznMlxhgz/hRsKMT6e/JciTHGjD85CwURuVdEWkRk43HGf0hENnh/z4nI4lzVkskfdqEQ7+sdi8UZY8xpJZc9hfuBy4cYvxO4WFUXAX8P3JPDWtKCXihE+233kTHGDJbLO689LSL1Q4x/LuPpC0BdrmrJFAiXAJCw3UfGGHOM8XJM4aPAb8ZiQcGI6ykkonajHWOMGSxnPYXhEpFLcKFw0RBtVgGrAGbOnDmi5YWLvJ5C1HoKxhgzWF57CiKyCPgRcLWqth+vnareo6qNqtpYW1s7omWGikoBSMXsQLMxxgyWt1AQkZnAz4G/UtXXxmq5oYjrKaj1FIwx5hg5230kIg8Ay4EaEWkCbgeCAKp6N/BlYBLwLyICkFDVxlzVk64r7HoKaj0FY4w5Ri7PPlp5gvEfAz6Wq+UfV9AdaCZuPQVjjBlsvJx9NHZCbveRxK2nYIwxgxVeKPhDJPHhT1goGGPMYIUXCiL0SwSfhYIxxhyj8EIBiEoR/oT9eM0YYwYryFCI+SIEkxYKxhgzWEGGQtxfRDBloWCMMYMVZij4ighZKBhjzDEKMhQSgSLCqf58l2GMMeNOQYZCKlBMWC0UjDFmsAINhSKK6EdV812KMcaMK4UZCsFiiogSTaTyXYoxxowrBRkKBEsoJkpvLJnvSowxZlwpzFAIlVAkMfpi8XxXYowx40pBhoJ4F8Xr7+3KcyXGGDO+FGQo+MIuFKI9nXmuxBhjxpeCDAW/Fwqxvu48V2KMMePLsEJBRM4SkbD3eLmIfFpEKk8wzb0i0iIiG48zXkTkOyKyXUQ2iEjDyZd/agJFZYCFgjHGDDbcnsLDQFJEzgZ+DMwC/uME09wPXD7E+CuAOd7fKuD7w6xlxIIRd0vOWJ8dUzDGmEzDDYWUqiaA9wOrVfW/AdOGmkBVnwYODtHkauBf1XkBqBSRIec5WkJFLhSS/dZTMMaYTMMNhbiIrAQ+DDzmDQuOcNkzgL0Zz5u8YccQkVUiskZE1rS2to5wsRApcbuPLBSMMeZoww2Fm4ELgK+r6k4RmQX8+wiXLVmGZb3uhKreo6qNqtpYW1s7wsVCpNgLhVjPiOdljDETSWA4jVR1M/BpABGpAspU9c4RLrsJOCPjeR2wf4TzHJaQd6BZo3ZLTmOMyTTcs49+LyLlIlINrAfuE5FvjnDZjwI3emchnQ90qGrzCOc5LAM/XlPrKRhjzFGG1VMAKlS1U0Q+BtynqreLyIahJhCRB4DlQI2INAG34x2HUNW7gceBK4HtQC9uF9XY8EJBLBSMMeYoww2FgHdm0AeBvxvOBKq68gTjFfjEMJc/uvxB4gSQhO0+MsaYTMM90HwH8CTwuqq+LCKzgW25Kyv3+iWCL26hYIwxmYZ7oPmnwE8znu8APpCrosZCVCL4E3afZmOMyTTcA811IvIL77IVB0TkYRGpy3VxuRTzFRFIWk/BGGMyDXf30X24s4Wm435g9itv2Gkr4Y8QTNl9mo0xJtNwQ6FWVe9T1YT3dz8w8l+R5VHcX0QwabuPjDEm03BDoU1EbhARv/d3A9Cey8JyLRkoJqzWUzDGmEzDDYWP4E5HfQNoBq5lLH9XkAOpQDERtZ6CMcZkGlYoqOoeVb1KVWtVdbKqvg+4Jse15VQyWEox/cSTqXyXYowx48ZI7rx266hVkQcaKqWUPnpjyXyXYowx48ZIQiHbVU5PH+EySuinNxrLdyXGGDNujCQUsl7m+nQh4VJ8ovT12N3XjDFmwJC/aBaRLrJ/+AtQlJOKxogvXA5AtLsDmJrfYowxZpwYMhRUtWysChlrviIvFHo781yJMcaMHyPZfXRaC3g32kn0duS5EmOMGT8KNhRCJRUAxPusp2CMMQNyGgoicrmIbBWR7SJyW5bxM0XkKRH5s4hsEJErc1lPpqC3+yhpoWCMMWk5CwUR8QN3AVcA84GVIjJ/ULMvAQ+p6lLgeuBfclXPYJFS11NI9dvZR8YYMyCXPYVlwHZV3aGqMeBB4OpBbRQo9x5XAPtzWM9RSsqqAEhaKBhjTFouQ2EGsDfjeZM3LNNXgBu8ezg/Dnwq24xEZJWIrBGRNa2traNS3MDuI+233UfGGDMgl6GQ7RfPg3/zsBK4X1XrgCuBfxORY2pS1XtUtVFVG2trR+mK3cEikvjQWPfozM8YYyaAXIZCE3BGxvM6jt099FHgIQBVfR6IADU5rOkIEXopwhe13UfGGDMgl6HwMjBHRGaJSAh3IPnRQW32ACsARGQeLhRGZ//QMPT7ivElesZqccYYM+7lLBRUNQF8EngS2II7y2iTiNwhIld5zT4HfFxE1gMPADep6phdUynqLyFgoWCMMWlDXuZipFT1cdwB5MxhX854vBm4MJc1DCXhLyYUs1AwxpgBBfuLZoBEsIRwqjffZRhjzLhR0KGQCpZRlOplDPdYGWPMuFbQoaChEkqkjx67+5oxxgAFHgpEyimln86+eL4rMcaYcaGgQ8EfKaOEPjp67ZacxhgDBR8K5fhF6e6yeyoYYwwUeCgES91F8fq6DuW5EmOMGR8KOhRCJS4Uol0H81yJMcaMDwUdCpHySQDEeywUjDEGCjwUisurAUj0HM5zJcYYMz4UdCgEit3uI+2zYwrGGAMFHgpEKgHQfjv7yBhjoOBDwd2n2R+1UDDGGCj0UPAH6JUi/DG7JacxxkChhwLQ5yslFLdQMMYYyHEoiMjlIrJVRLaLyG3HafNBEdksIptE5D9yWU82/YFywkm7JacxxkAOb7IjIn7gLuBS3P2aXxaRR70b6wy0mQN8AbhQVQ+JyORc1XM88WAZRXafZmOMAXLbU1gGbFfVHaoaAx4Erh7U5uPAXap6CEBVW3JYT1aJUDklqR5SKbungjHG5DIUZgB7M543ecMynQOcIyJ/FJEXROTybDMSkVUiskZE1rS2to5qkalQBeXSQ08sMarzNcaY01EuQ0GyDBv8dTwAzAGWAyuBH4lI5TETqd6jqo2q2lhbWzuqRWpRBeX00mH3VDDGmJyGQhNwRsbzOmB/ljaPqGpcVXcCW3EhMWZ8kUrKpI/Onv6xXKwxxoxLuQyFl4E5IjJLRELA9cCjg9r8ErgEQERqcLuTduSwpmP4vSul9nbaRfGMMSZnoaCqCeCTwJPAFuAhVd0kIneIyFVesyeBdhHZDDwF/HdVbc9VTdkESwbuqTCmizXGmHEpZ6ekAqjq48Djg4Z9OeOxArd6f3kRLnNXSo1120XxjDGm4H/RHCnz7qnQbT0FY4wp+FAornS/l9MeCwVjjCn4UAiUuVCQXgsFY4wp+FAgUkkCH4F+CwVjjLFQ8PnoknKCUTvQbIwxFgpAt7+cSNxCwRhjLBSA3kAlJYnD+S7DGGPyzkIB6AtWUZK0W3IaY4yFAhCPVFORslAwxhgLBSAVmUQl3cTjdqVUY0xhs1AApGQSPlE6Do75PX6MMWZcsVAAfGXuHg09B9/IcyXGGJNfFgpAcZW7IVxnW1OeKzHGmPyyUACqps4EoNdCwRhT4CwUgJppZwIQP7wvz5UYY0x+WSgAwaIyuiiGLjumYIwpbDkNBRG5XES2ish2EbltiHbXioiKSGMu6xnKYf8kQn0H8rV4Y4wZF3IWCiLiB+4CrgDmAytFZH6WdmXAp4EXc1XLcPSEaimJtuazBGOMybtc9hSWAdtVdYeqxoAHgauztPt74H8D/Tms5YRixZOpTLbj7hBqjDGFKZehMAPYm/G8yRuWJiJLgTNU9bGhZiQiq0RkjYisaW3Nzbd5LZtOLYc41BPNyfyNMeZ0kMtQkCzD0l/DRcQHfAv43IlmpKr3qGqjqjbW1taOYolHBCunEZIkB5rttFRjTOHKZSg0AWdkPK8D9mc8LwMWAr8XkV3A+cCj+TrYXFQ7G4DO5tfzsXhjjBkXchkKLwNzRGSWiISA64FHB0aqaoeq1qhqvarWAy8AV6nqmhzWdFwV088GoL91Rz4Wb4wx40LOQkFVE8AngSeBLcBDqrpJRO4QkatytdxTVTntLAD00O48V2KMMfkTyOXMVfVx4PFBw758nLbLc1nLifgiZRyigmDnnnyWYYwxeWW/aM7QHpxKWb9d6sIYU7gsFDJ0Fc2gOtac7zKMMSZvLBQyxMpmMkXbSMTstwrGmMJkoZAhWTOXoCRp37Mp36UYY0xeWChkCE4/D4DuPevzXIkxxuSHhUKGmvrziKmfWJOFgjGmMFkoZDiztoIdUoevdXO+SzHGmLywUMjg8wmtxXOY3L0V7GqpxpgCZKEwSPfUt1Clh4nu35jvUowxZsxZKAwSmfcuANrW/jLPlRhjzNizUBhk3jlzeTa5gKqN90G0K9/lGGPMmLJQGGRqRYT7IzcQiR4k+ehnIZXMd0nGGDNmLBSyqF+8nH9O/AX+TT+DB1ZCh10PyRhTGCwUsvi7d89j6zmruD3+YWLbf4/etQx++z9hzwvWczDGTGhyut2ovrGxUdesyf19ePYd7uPCO/+LOmnhq5EHWa4v4ycJFTNh9sUweR7UzIUp86F8es7rMcaYkRCRtap6wjtb5jQURORy4NuAH/iRqt45aPytwMeABNAKfERVh7zLzViFAkBnf5y/+P7zbD3QxVTaucS/jg9Xb2ZW9FXCsUNHGpZNg8ozobQWSqdC2VQorobyGVA8Capngz8I/hAEwmNSuzHGZMp7KIiIH3gNuBR3v+aXgZWqujmjzSXAi6raKyK3AMtV9bqh5juWoQCgqjy7vY37/riL/3q1JT28mk5W1BzkrSXNTOnewnTfQc4IdePvOQD9HVnmJIBCyWQXDKESN7ioCiad5YYnY1A6xbVTdcGCwN4XIRCBukY3PtYDbVtdT6V8ujtLKtYNba9BSS2Ey11QiQ92POVCKVwOW38NZ1/qQqvvkFt2uMw9DhZBbzv0HoSiSrebLFLprYtCxRku2JKxI8srqna1VM6ERL9bp9IprvZ9a9z0HXvh4A4XkJPnuXVKpaBzn6s9EIbDeyDeD9MWQ+sW137KQjdfXwD6D0Os170Gyahb/p7n3TynN8CBjVA7172G8R63/HAZiLjXOBEDn9+tiyr84U6Y/z44861uWeBCvbfN1Z85HQqaAvEfqSVcDv7j3J8qGffa+qC7BeJ97rVr3XJkm0QqvLeEDH6zuW1RXH3keaLfbRtw9Xe94dY1mYC9L0Co1L1uA/NSdY+jXRD03mPxXgiXHltrIgrdB9zrmEpCy2a33RpucuvX3+G+yAwsXxVSCfc+yKxZxK23L+DeP8XVbnj3ASif5tXQB5373Xv9qBpi7r1cXOOm6+907yNfwHu/xSEQcvWlku5x23a3PmVT3evg8x+7/gMO7YZIuXsvZg5XhZ42N+3A6z3Y4HmpHvlRq8/n3jv+MOz5kMMKAAASuElEQVT/k/syuO23bl0+8GNXe9cbbj1Kao5MP/D/J1QKh3e71z4Zc+3CZdCyBV79NVz0WbftUwkIV7jlvf4U1MyBirrs9Z7AeAiFC4CvqOq7vOdfAFDVfzhO+6XA91T1wqHmO9ahkGlPey89sQRX3/VHYokUIb+PWDJ1VJvJZWEuOauMno5W3jk9ydump0i0bqc2FMO353n3BknG3X+4WA+k4tDdCj0t7sPHjJ5whQuRRH/28f6Q+w95zPCw+6DoaXX/KTPnF/UCv7wOEn1um2nKfWDF+0CzHHMKFrsP5jSB0snur7/DhWIgcnSd4jv6/VA+wwUpQNUsOLTz2GUEiyHa6X14x90HIbj32aSzXeglolB1puvB7n4u+/qLD6rqvcD0au0+cGR8IOLmF+068holYxAqg9ig07jDFXD2CveBGesGX9B9GZmywK3DoV3HLn+woioXlnD0MkKlbp7ggrqoyn3QHo8/BNOXupoPZtyLPVzhgqhrP0xe4LaVP+Q+4COV7ovAkRcHUBdivW1DLyvbaztg8PYersaPwHu+dfLTMfxQyOXtOGcAezOeNwFvGaL9R4HfZBshIquAVQAzZ84crfpO2sxJxQC89rUrANeLeGprC519CX74zA7mTyvnj9vb+L/r2gDhsZ0DL+98qktCJJKNFIX8HOh092s4f3Y1f3nBmexp72F6WZApFUUUJw4zeVI1U0v9aLSLgE/cm98fgoOvkzrchK98qguSWLf7hoG6N1n5DBcu4ndv5EDRkf/MgYj7AKqc6T7M/CHoO+y+vdXMcW/weL/7ZhSpdB9UVWe6D4h4n/u2lUy4DwBNQkeTa/fab+Ccy2H/OvftLVTi5nN4j/sGWzoZdv7B/YdNJY98S45UuOX7/G79uva7delpdd/Wu95wvZ5Yt/vX54eDO6F1KzTeDIf3um9joRL3ny8RdePKp0FPuxsejLjXIlTi9T4WQFcz9B6C+gtdz8oXcD2kjiZX7+E9UHuu+8a7b4378CuqgteedN/QAhH3eiei7ptdUZVXn7cdtvzKDQ8WuXAprXWvhz/ogubP/w4zL/B6TEn3IdnTfiR86t/m1qdli5tP5z63DfxB94GlSdfzSMahs8m13/cnOOPNbvuEit32inZ5H0riPnwGvo3WLXLzPLzH9VwyP0T9IRcW4TL3LXz6Ujiw2b1nelpdr2/qeW67dzW7nt6UBdC8wYXvpDmw57mj/9MUVcDWx91rWnUmbH7Ebcv219179exLXbvt/3n0dFMWusCIdR8dCAOhK76jA9sfcq9Len3EvY9624608wXddLGMgA6VuR5j5z73Hox2ufoq6tz7R1PQFXTrD+7/2LRFbviBTd60+93zsqnuW37xJFfL3hcGvRYZ4TbnUtj5jPt/Kn5YegO8/l/ufR8sdtmTSh4JPYDzPwErst7NeFTlsqfwF8C7VPVj3vO/Apap6qeytL0B+CRwsaoOeYebfPYUhutwb4z/89xu6muK6Y8naeuO8ec9h3n+9TZ6YsM/e6k45GdWTQkBvw9UaTrUR3vPkW8ftWVhbrn4LHa19/CH11r52vsWUh4J0tIVpbokxFm1JbR0RdnS3Mnycyazs72HJWe4b499sSSRoA8R4dltbZw1uYRpFW43QSqlHOjqTz83eTZ4N8bpJrP+ZNwF3MCulMHH2AbGZ06bSh5/d122Zam63S0DBnZpZUqljm4zsGxfIPtrHe93wTN4mhNJpaDvoPsykW0X3nD0HTp299cpOG12H4nIO4Hv4gKh5ZgZDXI6hMLxJJIpeqJJNjd30tUf50BXlJ5ogoBPaOmKsn7vYV7ceTDndSybVc1L3nL8PiGZcu+B+knF7GrvParth94yk20HunmtpYt3zZ9KY30VG/d10N4T49L5UygNB/j8wxtYOrOKDzTU0dzRhypcOn8K6/YeZnplhLMnl7GluZO6qiLKIkHauqOEAz5mVBbRE0tSGg6QSimbmzuZN60cv09o747y7PY2yiIB3nHuFACiiSQhvwsyY8zJGQ+hEMAdaF4B7MMdaP5LVd2U0WYp8DPgclXdNpz5ns6hMFy72nqYWhEhEvSzdvdBXn2jiw801BFNpGjt6mf93g4a66vY0NTB468087Y5tby0s51frtuf79JPybxp5Wxp7jypaeZOKaO9J0o44Ofjb5vFCzsOoigHOqPsPdib7lEtn1vL5v2dnDOljIUzKlBVemNJLjx7EiLC9pZufr2hmakVEWbXlPDc6+2cUV1EdUmIR9bt50cfbmThjAr++cmtPLnpAO9ZNI03z6pm7pQyZlYXIwLNHf1Egn4SqRS/29LC1IoIb3T08+b6Ks6eXAbAxn0dzK4t4VBvnFRKWd90mHecO5ntLd1UFoV4dP0+9h7s439cPpdJpWGSKaWrP05lcYjO/jjlkSD7DvdRWRTk1Te6WDijnP54iv54kvbuGHOnluH3HR2WA/+3LUQNjINQ8Iq4EliNOyX1XlX9uojcAaxR1UdF5P8B5wHN3iR7VPWqoeZZCKFwqnqiCfriSXwiVJeEeO71NuZNLSepSk1pGFXld1taeHnXQd67eDoVRUEml4c51BMn4BdqSsO8uKOdxzY0Uxz2c9Nb6wHYdqCbl3Ye5FBvjC3Nnbx7kZv2b3+6nmvfVMfC6eXs7+hnZ1sP/7nZHcNYfEYlew/2crAnRmVxkMO9ccAFQHNHX/r5ROf3CWfXlrL1wMiuo5XZozueG86fyc62Hv64vf2o4WdUF3Hlwmm8sq+DvYd6mVVTytOvtTKlPJw+vnXOlFIuPLuGNzr6SaSU1q4o8WSKWy89hyc2vgHA+xtm0NEbJ5FSvvzIRuZMLqOmLERJKEBdVTHr9h6iuaOfaRURPvPOc0gkU6zdfQi/T9jQ1MHrrd30xpJ8/vJziSaSNB3q40BnPwtnVDC5LMy0iiLueXoHn79iLod64pw9uZSWrn5UoT+e5LebDzCzupglZ1Sybu9hLp0/BZ8IXf1xfD4X8HOnlOETob0nSm1ZmKDPx283v8H8aRWIwLaWLpacUcVzr7cxf1o5k0rDdPTGSamyo62bHa09vH/pDErCAYJ+Hy/vOsismhL+tNsdC7h4bi090SThoI+ycICUgk8gkVKCfrdrKZZIEQr4iCVS9EQT7GrvoSfqvog8va2Ni86uOSrAB9oP1tzRR2VRiKKQn+0tXZxVWzqigB8XoZALFgrjm6qm37i9sQTJlFIWCQ45zcZ9Hexo6+H8WdX0x1NUFAXZtL+Dt55dQ18sSUdfnNJIgHDAR1t3lPbuGHsP9vJW7z/XSzvbqZ9UwpbmLtY3HWbpGZXMmVLKrrZeplVG2NLcxaXzp9AXS+L3Ca8d6OLrv97C3KllPP96O7ddcS6/Wr+f373awopzJ/PuRdOYWV3Mr9bv54lNb7jeyNtnEwn4uOfpHWzzPnz64knau6Pp40Rl4QDXNtYxrSLC2t2HeGHHQTr64syuLaG1M0rS66UMuGD2JJ7f0Z5+/Oe9h+iPuzOOZlQWse9wXy420YTiEzhBVuZcOOAjmnDb7d2LpvHrDc0nmMKZXBampevIIdQ3nVnFpJIQ21u6EYHXW3uOav/2c2r50Y2NWQNkOCwUjDlJvbEExaHROyEvmVLe6OxnRuXRB+xTKcXny/6NL550u4TKIkFiiRR+n+AT6I4mKA0HiCZSJFOKAqXhAHvae3lp10Ge2trC4d4Y1yytozeWoLUrSsOZVcyfVs6z29s4Z0oZ21q68Pt8VBQFSakS8vuYXlnEvkN9/K/Ht3Dtm+pYNqua1w50sfVAF+GAn/NnVdMbS7LnYC/bWroojwSpLQtzzpQyntnWSmN9NbNrSvjt5gOIwDOvtVFdEqK1K8r86eUUh/zc/YfXSak7MeLS+VOoKAqyoekwZeEg0yuLqK8p5hd/3sclcyezcV8HRSE/j3i7Qs+bUcG+w30c7Ilx66Xn8IfXWkkkU6xvcqcGL66r4M311RSHA6zdfZAp5RF2tfXQ1Z9g2axqHl23n65o4qjXePCH8YkC+G1zanh2e9uY3XertixMa1f2821uvOBM7rh64SnN10LBGDMudPTF6eqPU1dVfErTqyop5ZhjJsMRT6YGfllA06E+ZlYXp3fFdfbFiSdTTC6PkEopIu7EpfaeGLVl2a880NrldkulUsrug71MKg3xo2d2MrumhFgyxdvn1FIU9FMU8qenWbPrIJXFIV7a2c7UiiLiyRTvXTydeDJF0O+jozdOUpVXmztZ13SYWy4+i8O9cTbt7+Qts6tp644iCL/Z2My7FkxleuWpnRVooWCMMSZtuKFgV0k1xhiTZqFgjDEmzULBGGNMmoWCMcaYNAsFY4wxaRYKxhhj0iwUjDHGpFkoGGOMSTvtfrwmIq3AkPdxHkINMMTtkiYkW+fCYOtcGEayzmeqau2JGp12oTASIrJmOL/om0hsnQuDrXNhGIt1tt1Hxhhj0iwUjDHGpBVaKNyT7wLywNa5MNg6F4acr3NBHVMwxhgztELrKRhjjBmChYIxxpi0ggkFEblcRLaKyHYRuS3f9YwWETlDRJ4SkS0isklEPuMNrxaR/xSRbd6/Vd5wEZHveK/DBhFpyO8anBoR8YvIn0XkMe/5LBF50Vvf/ysiIW942Hu+3Rtfn8+6R0JEKkXkZyLyqre9L5jI21lE/pv3nt4oIg+ISGQibmcRuVdEWkRkY8awk96uIvJhr/02EfnwqdZTEKEgIn7gLuAKYD6wUkTm57eqUZMAPqeq84DzgU9463Yb8DtVnQP8znsO7jWY4/2tAr4/9iWPis8AWzKe/yPwLW99DwEf9YZ/FDikqmcD3/Lana6+DTyhqucCi3HrPyG3s4jMAD4NNKrqQsAPXM/E3M73A5cPGnZS21VEqoHbgbcAy4DbB4LkpKnqhP8DLgCezHj+BeAL+a4rR+v6CHApsBWY5g2bBmz1Hv8AWJnRPt3udPkD6rz/KO8AHgME9yvPwODtDTwJXOA9DnjtJN/rcArrXA7sHFz7RN3OwAxgL1DtbbfHgHdN1O0M1AMbT3W7AiuBH2QMP6rdyfwVRE+BI2+wAU3esAnF6zIvBV4EpqhqM4D372Sv2UR4LVYD/wNIec8nAYdVNeE9z1yn9Pp64zu89qeb2UArcJ+32+xHIlLCBN3OqroP+AawB2jGbbe1TPztPOBkt+uobe9CCQXJMmxCnYsrIqXAw8BnVbVzqKZZhp02r4WIvAdoUdW1mYOzNNVhjDudBIAG4PuquhTo4cguhWxO6/X2dn1cDcwCpgMluF0ng0207Xwix1vPUVv/QgmFJuCMjOd1wP481TLqRCSIC4SfqOrPvcEHRGSaN34a0OINP91fiwuBq0RkF/AgbhfSaqBSRAJem8x1Sq+vN74CODiWBY+SJqBJVV/0nv8MFxITdTu/E9ipqq2qGgd+DryVib+dB5zsdh217V0oofAyMMc7cyGEO2D1aJ5rGhUiIsCPgS2q+s2MUY8CA2cgfBh3rGFg+I3eWQznAx0D3dTTgap+QVXrVLUetx3/S1U/BDwFXOs1G7y+A6/DtV770+4bpKq+AewVkbneoBXAZibodsbtNjpfRIq99/jA+k7o7ZzhZLfrk8BlIlLl9bIu84advHwfYBnDAzlXAq8BrwN/l+96RnG9LsJ1EzcA67y/K3H7U38HbPP+rfbaC+5MrNeBV3Bnd+R9PU5x3ZcDj3mPZwMvAduBnwJhb3jEe77dGz8733WPYH2XAGu8bf1LoGoib2fgq8CrwEbg34DwRNzOwAO44yZx3Df+j57KdgU+4q3/duDmU63HLnNhjDEmrVB2HxljjBkGCwVjjDFpFgrGGGPSLBSMMcakWSgYY4xJs1AwZhARSYrIuoy/UbuqrojUZ14N05jxJnDiJsYUnD5VXZLvIozJB+spGDNMIrJLRP5RRF7y/s72hp8pIr/zrm//OxGZ6Q2fIiK/EJH13t9bvVn5ReSH3r0CfisiRXlbKWMGsVAw5lhFg3YfXZcxrlNVlwHfw11zCe/xv6rqIuAnwHe84d8B/qCqi3HXKdrkDZ8D3KWqC4DDwAdyvD7GDJv9otmYQUSkW1VLswzfBbxDVXd4FyF8Q1UniUgb7tr3cW94s6rWiEgrUKeq0Yx51AP/qe7mKYjI54Ggqn4t92tmzIlZT8GYk6PHeXy8NtlEMx4nsWN7ZhyxUDDm5FyX8e/z3uPncFdsBfgQ8Kz3+HfALZC+p3T5WBVpzKmybyjGHKtIRNZlPH9CVQdOSw2LyIu4L1QrvWGfBu4Vkf+Ouzvazd7wzwD3iMhHcT2CW3BXwzRm3LJjCsYMk3dMoVFV2/JdizG5YruPjDHGpFlPwRhjTJr1FIwxxqRZKBhjjEmzUDDGGJNmoWCMMSbNQsEYY0za/wfJBZ2tcn64WAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b47f048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(x_test)\n",
    "y_test= [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: yes</th>\n",
       "      <th>Pred: no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True:yes</th>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: no</th>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred: yes  Pred: no\n",
       "True:yes         95        31\n",
       "True: no         14        40"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                   index=['True:yes', 'True: no'],\n",
    "                   columns=['Pred: yes', 'Pred: no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model5New.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
