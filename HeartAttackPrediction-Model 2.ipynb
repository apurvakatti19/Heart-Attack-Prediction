{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected2D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.MinMaxScaler(feature_range=(0,1))\n",
    "#sb.set(rc={'figure.figsize':(10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['id', 'ccf', 'age', 'sex', 'painLocation', 'painExcertion', 'painResting', 'pncaden', 'chestPainType',\n",
    "        'restingBP','hyperTension', 'cholestrol', 'smoker', 'noOfCigarette' , 'smokingYears', 'bloodSugar',\n",
    "        'historyOfDiabetes', 'historyOfHA', 'restingECG', 'ekgmo', 'ekgday', 'ekgyr', 'dig',\n",
    "        'prop', 'nitr', 'pro' ,'diuretic', 'proto', 'stressTestDuration', 'stressTestSTTime', 'stressTestMet',\n",
    "        'stressTestMaxHR', 'stressTestRestingHR', 'stressTestMaxFirstBPS','stressTestMaxSecondBPS', 'dummy',\n",
    "        'stressTestRestingBP', 'exerciseAngina', 'xhypo', 'STDepressionExercise', 'STDepressionSlope',\n",
    "        'rldv5','rldv5e', 'coloredVesselsFluroscopy', 'restckm','exerckm','restef', 'restwm', 'exeref', 'exerwm',\n",
    "        'heartWallDamage', 'thalsev', 'thalpul', 'earlobe', 'cmo', 'cday', 'cyr', 'output', 'lmt',\n",
    " 'ladprox', 'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4',\n",
    " 'lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop=['id', 'ccf', 'painExcertion', 'painResting', 'pncaden','historyOfDiabetes', 'ekgmo', 'ekgday',\n",
    "               'ekgyr', 'dig', 'prop', 'nitr', 'pro' ,'diuretic', 'proto','stressTestMet', 'dummy', 'xhypo',\n",
    "               'rldv5','rldv5e','restckm','exerckm','restef', 'restwm', 'exeref','exerwm', 'thalsev', 'thalpul',\n",
    "               'earlobe', 'cmo', 'cday', 'cyr', 'lmt', 'ladprox', 'laddist', 'diag','cxmain', 'ramus', 'om1', 'om2',\n",
    "               'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4','lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting and Preprocessing the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleveland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedCleveland.txt', 'w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clevelandData=pd.read_csv(\"processedCleveland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "clevelandData=clevelandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hungarian.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedHungarian.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarianData=pd.read_csv(\"processedHungarian.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "hungarianData=hungarianData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('switzerland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedSwitzerland.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "switzerlandData=pd.read_csv(\"processedSwitzerland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "switzerlandData=switzerlandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long-beach-va.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedLongBeach.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "longBeachData=pd.read_csv(\"processedLongBeach.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "longBeachData=longBeachData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[clevelandData,hungarianData,longBeachData,switzerlandData]\n",
    "data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 76 columns):\n",
      "id                          900 non-null object\n",
      "ccf                         900 non-null object\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "painExcertion               900 non-null float64\n",
      "painResting                 900 non-null float64\n",
      "pncaden                     900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfDiabetes           900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "ekgmo                       900 non-null float64\n",
      "ekgday                      900 non-null float64\n",
      "ekgyr                       900 non-null object\n",
      "dig                         900 non-null float64\n",
      "prop                        900 non-null float64\n",
      "nitr                        900 non-null object\n",
      "pro                         900 non-null object\n",
      "diuretic                    900 non-null float64\n",
      "proto                       900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMet               900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "dummy                       900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "xhypo                       900 non-null object\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "rldv5                       900 non-null object\n",
      "rldv5e                      900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "restckm                     900 non-null object\n",
      "exerckm                     900 non-null float64\n",
      "restef                      900 non-null float64\n",
      "restwm                      900 non-null float64\n",
      "exeref                      900 non-null float64\n",
      "exerwm                      900 non-null float64\n",
      "heartWallDamage             900 non-null float64\n",
      "thalsev                     900 non-null float64\n",
      "thalpul                     900 non-null float64\n",
      "earlobe                     900 non-null object\n",
      "cmo                         900 non-null float64\n",
      "cday                        900 non-null float64\n",
      "cyr                         900 non-null float64\n",
      "output                      900 non-null float64\n",
      "lmt                         900 non-null float64\n",
      "ladprox                     900 non-null float64\n",
      "laddist                     900 non-null float64\n",
      "diag                        900 non-null float64\n",
      "cxmain                      900 non-null float64\n",
      "ramus                       900 non-null float64\n",
      "om1                         900 non-null float64\n",
      "om2                         900 non-null float64\n",
      "rcaprox                     900 non-null float64\n",
      "rcadist                     900 non-null float64\n",
      "lvx1                        900 non-null float64\n",
      "lvx2                        900 non-null object\n",
      "lvx3                        900 non-null float64\n",
      "lvx4                        900 non-null object\n",
      "lvf                         900 non-null object\n",
      "cathef                      900 non-null object\n",
      "junk                        900 non-null float64\n",
      "name                        900 non-null object\n",
      "dtypes: float64(56), object(20)\n",
      "memory usage: 541.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>painExcertion</th>\n",
       "      <th>painResting</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>bloodSugar</th>\n",
       "      <th>historyOfDiabetes</th>\n",
       "      <th>historyOfHA</th>\n",
       "      <th>restingECG</th>\n",
       "      <th>ekgmo</th>\n",
       "      <th>ekgday</th>\n",
       "      <th>ekgyr</th>\n",
       "      <th>dig</th>\n",
       "      <th>prop</th>\n",
       "      <th>nitr</th>\n",
       "      <th>pro</th>\n",
       "      <th>diuretic</th>\n",
       "      <th>proto</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMet</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>dummy</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>xhypo</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>rldv5</th>\n",
       "      <th>rldv5e</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>restckm</th>\n",
       "      <th>exerckm</th>\n",
       "      <th>restef</th>\n",
       "      <th>restwm</th>\n",
       "      <th>exeref</th>\n",
       "      <th>exerwm</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>thalsev</th>\n",
       "      <th>thalpul</th>\n",
       "      <th>earlobe</th>\n",
       "      <th>cmo</th>\n",
       "      <th>cday</th>\n",
       "      <th>cyr</th>\n",
       "      <th>output</th>\n",
       "      <th>lmt</th>\n",
       "      <th>ladprox</th>\n",
       "      <th>laddist</th>\n",
       "      <th>diag</th>\n",
       "      <th>cxmain</th>\n",
       "      <th>ramus</th>\n",
       "      <th>om1</th>\n",
       "      <th>om2</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx1</th>\n",
       "      <th>lvx2</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "      <th>cathef</th>\n",
       "      <th>junk</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ccf age  sex  painLocation  painExcertion  painResting  pncaden  \\\n",
       "0  1   0  63  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "1  2   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "2  3   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "3  4   0  37  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "4  6   0  41  0.0          -9.0           -9.0         -9.0     -9.0   \n",
       "\n",
       "  chestPainType restingBP hyperTension  cholestrol smoker  noOfCigarette  \\\n",
       "0             1       145            1       233.0     -9           50.0   \n",
       "1             4       160            1       286.0     -9           40.0   \n",
       "2             4       120            1       229.0     -9           20.0   \n",
       "3             3       130            0       250.0     -9            0.0   \n",
       "4             2       130            1       204.0     -9            0.0   \n",
       "\n",
       "   smokingYears  bloodSugar  historyOfDiabetes  historyOfHA  restingECG  \\\n",
       "0          20.0         1.0               -9.0          1.0         2.0   \n",
       "1          40.0         0.0               -9.0          1.0         2.0   \n",
       "2          35.0         0.0               -9.0          1.0         2.0   \n",
       "3           0.0         0.0               -9.0          1.0         0.0   \n",
       "4           0.0         0.0               -9.0          1.0         2.0   \n",
       "\n",
       "   ekgmo  ekgday ekgyr  dig  prop nitr pro  diuretic  proto  \\\n",
       "0    2.0     3.0    81  0.0   0.0    0   0       0.0    1.0   \n",
       "1    3.0     5.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "2    2.0    19.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "3    2.0    13.0    81  0.0   1.0    0   0       0.0    1.0   \n",
       "4    2.0     7.0    81  0.0   0.0    0   0       0.0    1.0   \n",
       "\n",
       "   stressTestDuration  stressTestSTTime  stressTestMet  stressTestMaxHR  \\\n",
       "0                10.5               6.0           13.0            150.0   \n",
       "1                 9.5               6.0           13.0            108.0   \n",
       "2                 8.5               6.0           10.0            129.0   \n",
       "3                13.0              13.0           17.0            187.0   \n",
       "4                 7.0              -9.0            9.0            172.0   \n",
       "\n",
       "   stressTestRestingHR  stressTestMaxFirstBPS  stressTestMaxSecondBPS  dummy  \\\n",
       "0                 60.0                  190.0                    90.0  145.0   \n",
       "1                 64.0                  160.0                    90.0  160.0   \n",
       "2                 78.0                  140.0                    80.0  120.0   \n",
       "3                 84.0                  195.0                    68.0  130.0   \n",
       "4                 71.0                  160.0                    74.0  130.0   \n",
       "\n",
       "   stressTestRestingBP  exerciseAngina xhypo  STDepressionExercise  \\\n",
       "0                 85.0             0.0     0                   2.3   \n",
       "1                 90.0             1.0     0                   1.5   \n",
       "2                 80.0             1.0     0                   2.6   \n",
       "3                 78.0             0.0     0                   3.5   \n",
       "4                 86.0             0.0     0                   1.4   \n",
       "\n",
       "   STDepressionSlope rldv5  rldv5e coloredVesselsFluroscopy restckm  exerckm  \\\n",
       "0                3.0    -9   172.0                        0      -9     -9.0   \n",
       "1                2.0    -9   185.0                        3      -9     -9.0   \n",
       "2                2.0    -9   150.0                        2      -9     -9.0   \n",
       "3                3.0    -9   167.0                        0      -9     -9.0   \n",
       "4                1.0    -9    40.0                        0      -9     -9.0   \n",
       "\n",
       "   restef  restwm  exeref  exerwm  heartWallDamage  thalsev  thalpul earlobe  \\\n",
       "0    -9.0    -9.0    -9.0    -9.0              6.0     -9.0     -9.0      -9   \n",
       "1    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "2    -9.0    -9.0    -9.0    -9.0              7.0     -9.0     -9.0      -9   \n",
       "3    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "4    -9.0    -9.0    -9.0    -9.0              3.0     -9.0     -9.0      -9   \n",
       "\n",
       "   cmo  cday   cyr  output  lmt  ladprox  laddist  diag  cxmain  ramus  om1  \\\n",
       "0  2.0  16.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "1  2.0   5.0  81.0     2.0  1.0      2.0      2.0  -9.0     2.0   -9.0  1.0   \n",
       "2  2.0  20.0  81.0     1.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "3  2.0   4.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "4  2.0  18.0  81.0     0.0  1.0      1.0      1.0  -9.0     1.0   -9.0  1.0   \n",
       "\n",
       "   om2  rcaprox  rcadist  lvx1 lvx2  lvx3 lvx4 lvf cathef  junk  name  \n",
       "0 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "1 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "2 -9.0      2.0      2.0   1.0    1   1.0    7   3     -9  -9.0  name  \n",
       "3 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  \n",
       "4 -9.0      1.0      1.0   1.0    1   1.0    1   1     -9  -9.0  name  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columnsToDrop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>bloodSugar</th>\n",
       "      <th>historyOfHA</th>\n",
       "      <th>restingECG</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex  painLocation chestPainType restingBP hyperTension  cholestrol  \\\n",
       "0  63  1.0          -9.0             1       145            1       233.0   \n",
       "1  67  1.0          -9.0             4       160            1       286.0   \n",
       "2  67  1.0          -9.0             4       120            1       229.0   \n",
       "3  37  1.0          -9.0             3       130            0       250.0   \n",
       "4  41  0.0          -9.0             2       130            1       204.0   \n",
       "\n",
       "  smoker  noOfCigarette  smokingYears  bloodSugar  historyOfHA  restingECG  \\\n",
       "0     -9           50.0          20.0         1.0          1.0         2.0   \n",
       "1     -9           40.0          40.0         0.0          1.0         2.0   \n",
       "2     -9           20.0          35.0         0.0          1.0         2.0   \n",
       "3     -9            0.0           0.0         0.0          1.0         0.0   \n",
       "4     -9            0.0           0.0         0.0          1.0         2.0   \n",
       "\n",
       "   stressTestDuration  stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0                10.5               6.0            150.0                 60.0   \n",
       "1                 9.5               6.0            108.0                 64.0   \n",
       "2                 8.5               6.0            129.0                 78.0   \n",
       "3                13.0              13.0            187.0                 84.0   \n",
       "4                 7.0              -9.0            172.0                 71.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    90.0                 85.0   \n",
       "1                  160.0                    90.0                 90.0   \n",
       "2                  140.0                    80.0                 80.0   \n",
       "3                  195.0                    68.0                 78.0   \n",
       "4                  160.0                    74.0                 86.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  STDepressionSlope  \\\n",
       "0             0.0                   2.3                3.0   \n",
       "1             1.0                   1.5                2.0   \n",
       "2             1.0                   2.6                2.0   \n",
       "3             0.0                   3.5                3.0   \n",
       "4             0.0                   1.4                1.0   \n",
       "\n",
       "  coloredVesselsFluroscopy  heartWallDamage  output  \n",
       "0                        0              6.0     0.0  \n",
       "1                        3              3.0     2.0  \n",
       "2                        2              7.0     1.0  \n",
       "3                        0              3.0     0.0  \n",
       "4                        0              3.0     0.0  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "heartWallDamage             900 non-null float64\n",
      "output                      900 non-null float64\n",
      "dtypes: float64(20), object(6)\n",
      "memory usage: 189.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPainLocation(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>0):\n",
    "            if(columns[2]==1):\n",
    "                return 0\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceByMean(columns,mean):\n",
    "    if(columns[0]<1):\n",
    "        return int(mean)\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHypertension(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>120):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCholestrol(columns):\n",
    "    if(columns[0]<=200):\n",
    "        return 0\n",
    "    elif(columns[0]<=239):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSmoking(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(int(columns[1])>0):\n",
    "            return 1\n",
    "        elif(int(columns[1])==0):\n",
    "            return 0\n",
    "        if(int(columns[2])>0):\n",
    "            return 1\n",
    "        elif(int(columns[2])==0):\n",
    "            return 0\n",
    "    return int(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDummyCategory(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRestingECG(columns):\n",
    "    if(columns[0]==2):\n",
    "        return 1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processstressTestSTTime(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processExerciseAgnia(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]==1):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSTDepressionSlope(columns):\n",
    "    if(columns[0]<1):\n",
    "        return -1\n",
    "    if(columns[0]==1):\n",
    "        return 1\n",
    "    if(columns[0]==2):\n",
    "        return 0\n",
    "    if(columns[0]==3):\n",
    "        return 2\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processcoloredVesselsFluroscopy(columns):\n",
    "    if(columns[0]==-9 or columns[0]==9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHeartWallDamage(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    if(columns[0]<=3):\n",
    "        return 0\n",
    "    if(columns[0]<=6):\n",
    "        return 2\n",
    "    if(columns[0]==7):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(columns):\n",
    "    if(columns[0]>1):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age']=pd.to_numeric(data['age'])\n",
    "d=data[data.age !=-9]\n",
    "d=d[d.age != 0]\n",
    "mean=d['age'].mean()\n",
    "mean=data['age'].mean()\n",
    "data['age']=data[['age']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex']=pd.to_numeric(data['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['painLocation']=data[['painLocation','output','bloodSugar']].apply(processPainLocation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['chestPainType']=pd.to_numeric(data['chestPainType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['chestPainType'], prefix='chestPainType')\n",
    "data=data.drop('chestPainType',axis=1)\n",
    "data=data.join(dummyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingBP']=pd.to_numeric(data['restingBP'])\n",
    "d=data[data.restingBP !=-9]\n",
    "d=d[d.restingBP != 0]\n",
    "mean=d['restingBP'].mean()\n",
    "data['restingBP']=data[['restingBP']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hyperTension']=pd.to_numeric(data['hyperTension'])\n",
    "data['hyperTension']=data[['hyperTension','restingBP']].apply(processHypertension,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=pd.to_numeric(data['cholestrol'])\n",
    "d=data[data.cholestrol !=-9]\n",
    "d=d[d.cholestrol != 0]\n",
    "mean=d['cholestrol'].mean()\n",
    "data['cholestrol']=data[['cholestrol']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=data[['cholestrol']].apply(processCholestrol,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['cholestrol'], prefix='cholestrol')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('cholestrol',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=pd.to_numeric(data['smoker'])\n",
    "data['smoker']=data[['smoker','smokingYears','noOfCigarette']].apply(processSmoking,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=data[['smoker']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['smoker'], prefix='smoker')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('smoker',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bloodSugar']=pd.to_numeric(data['bloodSugar'])\n",
    "data['bloodSugar']=data[['bloodSugar']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.bloodSugar==40].index[0],'bloodSugar']=int(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['bloodSugar'], prefix='bloodSugar')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('bloodSugar',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['historyOfHA']=pd.to_numeric(data['historyOfHA'])\n",
    "data['historyOfHA']=data[['historyOfHA']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['historyOfHA'], prefix='historyOfHA')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('historyOfHA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingECG']=pd.to_numeric(data['restingECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==0.4].index[0],'restingECG']=int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['restingECG'], prefix='restingECG')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('restingECG',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['restingECG']=data[['restingECG']].apply(processRestingECG,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestDuration']=pd.to_numeric(data['stressTestDuration'])\n",
    "data['stressTestDuration']=data[['stressTestDuration']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestSTTime']=pd.to_numeric(data['stressTestSTTime'])\n",
    "data['stressTestSTTime']=data[['stressTestSTTime']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxHR']=pd.to_numeric(data['stressTestMaxHR'])\n",
    "d=data[data.stressTestMaxHR !=-9]\n",
    "mean=d['stressTestMaxHR'].mean()\n",
    "data['stressTestMaxHR']=data[['stressTestMaxHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxHR==8105].index[0],'stressTestMaxHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingHR']=pd.to_numeric(data['stressTestRestingHR'])\n",
    "d=data[data.stressTestRestingHR !=-9]\n",
    "mean=d['stressTestRestingHR'].mean()\n",
    "data['stressTestRestingHR']=data[['stressTestRestingHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingHR==1.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==37.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==39.0].index[0],'stressTestRestingHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxFirstBPS']=pd.to_numeric(data['stressTestMaxFirstBPS'])\n",
    "d=data[data.stressTestMaxFirstBPS !=-9]\n",
    "mean=d['stressTestMaxFirstBPS'].mean()\n",
    "data['stressTestMaxFirstBPS']=data[['stressTestMaxFirstBPS']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxSecondBPS']=pd.to_numeric(data['stressTestMaxSecondBPS'])\n",
    "d=data[data.stressTestMaxSecondBPS !=-9]\n",
    "mean=d['stressTestMaxSecondBPS'].mean()\n",
    "data['stressTestMaxSecondBPS']=data[['stressTestMaxSecondBPS']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxSecondBPS==1.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==11.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==26.0].index[0],'stressTestMaxSecondBPS']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingBP']=pd.to_numeric(data['stressTestRestingBP'])\n",
    "d=data[data.stressTestRestingBP !=-9]\n",
    "mean=d['stressTestRestingBP'].mean()\n",
    "data['stressTestRestingBP']=data[['stressTestRestingBP']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingBP==1018].index[0],'stressTestRestingBP']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exerciseAngina']=pd.to_numeric(data['exerciseAngina'])\n",
    "data['exerciseAngina']=data[['exerciseAngina','painLocation']].apply(processExerciseAgnia,axis=1)\n",
    "data.at[data[data.exerciseAngina==101881].index[0],'exerciseAngina']=int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionExercise']=pd.to_numeric(data['STDepressionExercise'])\n",
    "d=data[data.STDepressionExercise !=-9]\n",
    "mean=d['STDepressionExercise'].mean()\n",
    "data['STDepressionExercise']=data[['STDepressionExercise']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionSlope']=pd.to_numeric(data['STDepressionSlope'])\n",
    "data['STDepressionSlope']=data[['STDepressionSlope']].apply(processSTDepressionSlope,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['STDepressionSlope'], prefix='STDepressionSlope')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('STDepressionSlope',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coloredVesselsFluroscopy']=pd.to_numeric(data['coloredVesselsFluroscopy'])\n",
    "data['coloredVesselsFluroscopy']=data[['coloredVesselsFluroscopy']].apply(processcoloredVesselsFluroscopy,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['coloredVesselsFluroscopy'], prefix='coloredVesselsFluroscopy')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('coloredVesselsFluroscopy',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heartWallDamage']=pd.to_numeric(data['heartWallDamage'])\n",
    "data['heartWallDamage']=data[['heartWallDamage']].apply(processHeartWallDamage,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['heartWallDamage'], prefix='heartWallDamage')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('heartWallDamage',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output']=pd.to_numeric(data['output'])\n",
    "data['output']=data[['output']].apply(processOutput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOutput=pd.DataFrame(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 1 columns):\n",
      "output    900 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataOutput.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['noOfCigarette' , 'smokingYears'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['output'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   55  1.0           1.0        140             1                 8.0   \n",
       "1   63  1.0           1.0        110             1                 2.0   \n",
       "2   41  1.0           1.0        120             0                20.0   \n",
       "3   54  0.0           1.0        120             1                 6.0   \n",
       "4   76  1.0           1.0        104             1                 8.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0              -1.0            150.0                105.0   \n",
       "1              -1.0            140.0                 94.0   \n",
       "2              -1.0            170.0                 64.0   \n",
       "3              -1.0            140.0                 74.0   \n",
       "4              -1.0            120.0                 70.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  200.0                    95.0                 90.0   \n",
       "1                  130.0                    80.0                 80.0   \n",
       "2                  210.0                    85.0                 80.0   \n",
       "3                  140.0                    80.0                 80.0   \n",
       "4                  160.0                    76.0                 58.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             0.0                   0.0                0                1   \n",
       "1             1.0                   2.0                0                0   \n",
       "2             0.0                   0.0                0                1   \n",
       "3             0.0                   0.0                0                1   \n",
       "4             0.0                   3.5                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                0                0             1             0             0   \n",
       "1                0                1             0             0             1   \n",
       "2                0                0             0             0             1   \n",
       "3                0                0             0             1             0   \n",
       "4                1                0             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          1         0         0                0               1   \n",
       "1          0         0         1                0               1   \n",
       "2          1         0         0                0               1   \n",
       "3          1         0         0                0               0   \n",
       "4          1         0         0                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 1                0                0   \n",
       "1               0                 0                1                0   \n",
       "2               0                 1                0                0   \n",
       "3               1                 1                0                0   \n",
       "4               0                 0                1                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     1   \n",
       "1               0               1               0                     0   \n",
       "2               1               0               0                     1   \n",
       "3               1               0               0                     1   \n",
       "4               0               0               1                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    1   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            1                           0   \n",
       "3                            1                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   0                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   1                  0   \n",
       "3                           0                   1                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  1                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop(['smoker_-1','bloodSugar_-1.0','historyOfHA_-1.0','STDepressionSlope_-1',\n",
    "#               'coloredVesselsFluroscopy_-1','heartWallDamage_-1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   55  1.0           1.0        140             1                 8.0   \n",
       "1   63  1.0           1.0        110             1                 2.0   \n",
       "2   41  1.0           1.0        120             0                20.0   \n",
       "3   54  0.0           1.0        120             1                 6.0   \n",
       "4   76  1.0           1.0        104             1                 8.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0              -1.0            150.0                105.0   \n",
       "1              -1.0            140.0                 94.0   \n",
       "2              -1.0            170.0                 64.0   \n",
       "3              -1.0            140.0                 74.0   \n",
       "4              -1.0            120.0                 70.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  200.0                    95.0                 90.0   \n",
       "1                  130.0                    80.0                 80.0   \n",
       "2                  210.0                    85.0                 80.0   \n",
       "3                  140.0                    80.0                 80.0   \n",
       "4                  160.0                    76.0                 58.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             0.0                   0.0                0                1   \n",
       "1             1.0                   2.0                0                0   \n",
       "2             0.0                   0.0                0                1   \n",
       "3             0.0                   0.0                0                1   \n",
       "4             0.0                   3.5                0                0   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                0                0             1             0             0   \n",
       "1                0                1             0             0             1   \n",
       "2                0                0             0             0             1   \n",
       "3                0                0             0             1             0   \n",
       "4                1                0             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          1         0         0                0               1   \n",
       "1          0         0         1                0               1   \n",
       "2          1         0         0                0               1   \n",
       "3          1         0         0                0               0   \n",
       "4          1         0         0                0               1   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 1                0                0   \n",
       "1               0                 0                1                0   \n",
       "2               0                 1                0                0   \n",
       "3               1                 1                0                0   \n",
       "4               0                 0                1                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     1   \n",
       "1               0               1               0                     0   \n",
       "2               1               0               0                     1   \n",
       "3               1               0               0                     1   \n",
       "4               0               0               1                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    1   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            1                           0   \n",
       "3                            1                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   0                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   1                  0   \n",
       "3                           0                   1                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  1                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  0                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 46 columns):\n",
      "age                            900 non-null int64\n",
      "sex                            900 non-null float64\n",
      "painLocation                   900 non-null float64\n",
      "restingBP                      900 non-null int64\n",
      "hyperTension                   900 non-null int64\n",
      "stressTestDuration             900 non-null float64\n",
      "stressTestSTTime               900 non-null float64\n",
      "stressTestMaxHR                900 non-null float64\n",
      "stressTestRestingHR            900 non-null float64\n",
      "stressTestMaxFirstBPS          900 non-null float64\n",
      "stressTestMaxSecondBPS         900 non-null float64\n",
      "stressTestRestingBP            900 non-null float64\n",
      "exerciseAngina                 900 non-null float64\n",
      "STDepressionExercise           900 non-null float64\n",
      "chestPainType_1                900 non-null uint8\n",
      "chestPainType_2                900 non-null uint8\n",
      "chestPainType_3                900 non-null uint8\n",
      "chestPainType_4                900 non-null uint8\n",
      "cholestrol_0                   900 non-null uint8\n",
      "cholestrol_1                   900 non-null uint8\n",
      "cholestrol_2                   900 non-null uint8\n",
      "smoker_-1                      900 non-null uint8\n",
      "smoker_0                       900 non-null uint8\n",
      "smoker_1                       900 non-null uint8\n",
      "bloodSugar_-1.0                900 non-null uint8\n",
      "bloodSugar_0.0                 900 non-null uint8\n",
      "bloodSugar_1.0                 900 non-null uint8\n",
      "historyOfHA_-1.0               900 non-null uint8\n",
      "historyOfHA_0.0                900 non-null uint8\n",
      "historyOfHA_1.0                900 non-null uint8\n",
      "restingECG_0.0                 900 non-null uint8\n",
      "restingECG_1.0                 900 non-null uint8\n",
      "restingECG_2.0                 900 non-null uint8\n",
      "STDepressionSlope_-1           900 non-null uint8\n",
      "STDepressionSlope_0            900 non-null uint8\n",
      "STDepressionSlope_1            900 non-null uint8\n",
      "STDepressionSlope_2            900 non-null uint8\n",
      "coloredVesselsFluroscopy_-1    900 non-null uint8\n",
      "coloredVesselsFluroscopy_0     900 non-null uint8\n",
      "coloredVesselsFluroscopy_1     900 non-null uint8\n",
      "coloredVesselsFluroscopy_2     900 non-null uint8\n",
      "coloredVesselsFluroscopy_3     900 non-null uint8\n",
      "heartWallDamage_-1             900 non-null uint8\n",
      "heartWallDamage_0              900 non-null uint8\n",
      "heartWallDamage_1              900 non-null uint8\n",
      "heartWallDamage_2              900 non-null uint8\n",
      "dtypes: float64(11), int64(3), uint8(32)\n",
      "memory usage: 126.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_X, testingData_X, trainingData_Y, testingData_Y = train_test_split(data,\n",
    "                                                                                dataOutput,\n",
    "                                                                                test_size = 0.2,\n",
    "                                                                                random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=trainingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=trainingData_Y.values\n",
    "y_test=testingData_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "y_train=y_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "y_test=y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLayer=x_train.shape[1]\n",
    "secondLayer=int(x_train.shape[1]/4)\n",
    "thirdLayer=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46   11   1\n"
     ]
    }
   ],
   "source": [
    "print(firstLayer,\" \",secondLayer,\" \",thirdLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(firstLayer, input_dim=x_train.shape[1], activation='relu',\n",
    "                kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(secondLayer,activation='relu',\n",
    "                kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0),\n",
    "               kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(thirdLayer, activation='sigmoid',kernel_initializer=he_normal(seed=None),\n",
    "                bias_initializer=Constant(value=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.005, momentum=0.0, decay=0.0, nesterov=False),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 11)                517       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 2,691\n",
      "Trainable params: 2,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/1000\n",
      "648/648 [==============================] - 0s 314us/step - loss: 1.0300 - acc: 0.4722 - val_loss: 1.0256 - val_acc: 0.4167\n",
      "Epoch 2/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 1.0128 - acc: 0.5324 - val_loss: 1.0130 - val_acc: 0.5000\n",
      "Epoch 3/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 1.0035 - acc: 0.5309 - val_loss: 1.0011 - val_acc: 0.5417\n",
      "Epoch 4/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.9899 - acc: 0.5540 - val_loss: 0.9895 - val_acc: 0.5556\n",
      "Epoch 5/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.9730 - acc: 0.5802 - val_loss: 0.9783 - val_acc: 0.5556\n",
      "Epoch 6/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.9653 - acc: 0.5741 - val_loss: 0.9671 - val_acc: 0.5417\n",
      "Epoch 7/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.9505 - acc: 0.6049 - val_loss: 0.9560 - val_acc: 0.5694\n",
      "Epoch 8/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.9420 - acc: 0.6142 - val_loss: 0.9452 - val_acc: 0.5556\n",
      "Epoch 9/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.9277 - acc: 0.6157 - val_loss: 0.9346 - val_acc: 0.5556\n",
      "Epoch 10/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.9220 - acc: 0.6111 - val_loss: 0.9242 - val_acc: 0.5694\n",
      "Epoch 11/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.9112 - acc: 0.6173 - val_loss: 0.9139 - val_acc: 0.5694\n",
      "Epoch 12/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.8982 - acc: 0.6204 - val_loss: 0.9036 - val_acc: 0.5833\n",
      "Epoch 13/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.8877 - acc: 0.6327 - val_loss: 0.8935 - val_acc: 0.5833\n",
      "Epoch 14/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.8759 - acc: 0.6265 - val_loss: 0.8836 - val_acc: 0.5833\n",
      "Epoch 15/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.8674 - acc: 0.6512 - val_loss: 0.8738 - val_acc: 0.5833\n",
      "Epoch 16/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.8601 - acc: 0.6358 - val_loss: 0.8642 - val_acc: 0.5833\n",
      "Epoch 17/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.8457 - acc: 0.6451 - val_loss: 0.8548 - val_acc: 0.5833\n",
      "Epoch 18/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.8396 - acc: 0.6435 - val_loss: 0.8454 - val_acc: 0.5833\n",
      "Epoch 19/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.8274 - acc: 0.6512 - val_loss: 0.8361 - val_acc: 0.5833\n",
      "Epoch 20/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.8186 - acc: 0.6481 - val_loss: 0.8267 - val_acc: 0.5833\n",
      "Epoch 21/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.8102 - acc: 0.6451 - val_loss: 0.8176 - val_acc: 0.5833\n",
      "Epoch 22/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.7969 - acc: 0.6528 - val_loss: 0.8086 - val_acc: 0.5833\n",
      "Epoch 23/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.7872 - acc: 0.6636 - val_loss: 0.7995 - val_acc: 0.5833\n",
      "Epoch 24/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.7821 - acc: 0.6543 - val_loss: 0.7905 - val_acc: 0.5833\n",
      "Epoch 25/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.7727 - acc: 0.6451 - val_loss: 0.7816 - val_acc: 0.5833\n",
      "Epoch 26/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.7621 - acc: 0.6497 - val_loss: 0.7728 - val_acc: 0.5833\n",
      "Epoch 27/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.7566 - acc: 0.6481 - val_loss: 0.7641 - val_acc: 0.5833\n",
      "Epoch 28/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.7412 - acc: 0.6574 - val_loss: 0.7555 - val_acc: 0.5833\n",
      "Epoch 29/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.7385 - acc: 0.6481 - val_loss: 0.7470 - val_acc: 0.5833\n",
      "Epoch 30/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.7307 - acc: 0.6420 - val_loss: 0.7386 - val_acc: 0.5833\n",
      "Epoch 31/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.7209 - acc: 0.6466 - val_loss: 0.7304 - val_acc: 0.5833\n",
      "Epoch 32/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.7109 - acc: 0.6512 - val_loss: 0.7223 - val_acc: 0.5833\n",
      "Epoch 33/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.7017 - acc: 0.6574 - val_loss: 0.7142 - val_acc: 0.5833\n",
      "Epoch 34/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.6936 - acc: 0.6497 - val_loss: 0.7063 - val_acc: 0.5833\n",
      "Epoch 35/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6895 - acc: 0.6512 - val_loss: 0.6983 - val_acc: 0.5833\n",
      "Epoch 36/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.6817 - acc: 0.6543 - val_loss: 0.6906 - val_acc: 0.5833\n",
      "Epoch 37/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6705 - acc: 0.6590 - val_loss: 0.6828 - val_acc: 0.5833\n",
      "Epoch 38/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6636 - acc: 0.6559 - val_loss: 0.6752 - val_acc: 0.5833\n",
      "Epoch 39/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6580 - acc: 0.6512 - val_loss: 0.6676 - val_acc: 0.5833\n",
      "Epoch 40/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6501 - acc: 0.6543 - val_loss: 0.6600 - val_acc: 0.5833\n",
      "Epoch 41/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6442 - acc: 0.6559 - val_loss: 0.6525 - val_acc: 0.5833\n",
      "Epoch 42/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6351 - acc: 0.6466 - val_loss: 0.6450 - val_acc: 0.5833\n",
      "Epoch 43/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6274 - acc: 0.6528 - val_loss: 0.6376 - val_acc: 0.5833\n",
      "Epoch 44/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6223 - acc: 0.6512 - val_loss: 0.6302 - val_acc: 0.5833\n",
      "Epoch 45/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.6145 - acc: 0.6466 - val_loss: 0.6228 - val_acc: 0.5833\n",
      "Epoch 46/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.6070 - acc: 0.6451 - val_loss: 0.6157 - val_acc: 0.5833\n",
      "Epoch 47/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.5999 - acc: 0.6512 - val_loss: 0.6087 - val_acc: 0.5833\n",
      "Epoch 48/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.5947 - acc: 0.6528 - val_loss: 0.6016 - val_acc: 0.5833\n",
      "Epoch 49/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.5885 - acc: 0.6528 - val_loss: 0.5948 - val_acc: 0.5833\n",
      "Epoch 50/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.5781 - acc: 0.6590 - val_loss: 0.5881 - val_acc: 0.5833\n",
      "Epoch 51/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5757 - acc: 0.6605 - val_loss: 0.5814 - val_acc: 0.5833\n",
      "Epoch 52/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.5687 - acc: 0.6605 - val_loss: 0.5748 - val_acc: 0.5833\n",
      "Epoch 53/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.5592 - acc: 0.6497 - val_loss: 0.5684 - val_acc: 0.5833\n",
      "Epoch 54/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.5548 - acc: 0.6466 - val_loss: 0.5619 - val_acc: 0.5833\n",
      "Epoch 55/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5468 - acc: 0.6590 - val_loss: 0.5555 - val_acc: 0.5833\n",
      "Epoch 56/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5408 - acc: 0.6605 - val_loss: 0.5490 - val_acc: 0.5833\n",
      "Epoch 57/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5346 - acc: 0.6605 - val_loss: 0.5429 - val_acc: 0.5833\n",
      "Epoch 58/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.5296 - acc: 0.6590 - val_loss: 0.5371 - val_acc: 0.5833\n",
      "Epoch 59/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5257 - acc: 0.6590 - val_loss: 0.5310 - val_acc: 0.5833\n",
      "Epoch 60/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5187 - acc: 0.6528 - val_loss: 0.5251 - val_acc: 0.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5125 - acc: 0.6543 - val_loss: 0.5191 - val_acc: 0.5833\n",
      "Epoch 62/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.5070 - acc: 0.6559 - val_loss: 0.5130 - val_acc: 0.5833\n",
      "Epoch 63/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.5011 - acc: 0.6651 - val_loss: 0.5072 - val_acc: 0.5833\n",
      "Epoch 64/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4962 - acc: 0.6636 - val_loss: 0.5014 - val_acc: 0.5833\n",
      "Epoch 65/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4909 - acc: 0.6605 - val_loss: 0.4958 - val_acc: 0.5833\n",
      "Epoch 66/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.4846 - acc: 0.6512 - val_loss: 0.4903 - val_acc: 0.5833\n",
      "Epoch 67/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.4797 - acc: 0.6559 - val_loss: 0.4848 - val_acc: 0.5833\n",
      "Epoch 68/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4761 - acc: 0.6620 - val_loss: 0.4793 - val_acc: 0.5833\n",
      "Epoch 69/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4694 - acc: 0.6512 - val_loss: 0.4737 - val_acc: 0.5833\n",
      "Epoch 70/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.4647 - acc: 0.6605 - val_loss: 0.4683 - val_acc: 0.5833\n",
      "Epoch 71/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.4565 - acc: 0.6574 - val_loss: 0.4631 - val_acc: 0.5833\n",
      "Epoch 72/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4571 - acc: 0.6481 - val_loss: 0.4576 - val_acc: 0.5972\n",
      "Epoch 73/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4473 - acc: 0.6636 - val_loss: 0.4522 - val_acc: 0.5972\n",
      "Epoch 74/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4429 - acc: 0.6559 - val_loss: 0.4471 - val_acc: 0.5972\n",
      "Epoch 75/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.4365 - acc: 0.6590 - val_loss: 0.4420 - val_acc: 0.5972\n",
      "Epoch 76/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4338 - acc: 0.6713 - val_loss: 0.4372 - val_acc: 0.6111\n",
      "Epoch 77/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.4275 - acc: 0.6512 - val_loss: 0.4324 - val_acc: 0.6111\n",
      "Epoch 78/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4274 - acc: 0.6559 - val_loss: 0.4274 - val_acc: 0.6111\n",
      "Epoch 79/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.4150 - acc: 0.6651 - val_loss: 0.4226 - val_acc: 0.6111\n",
      "Epoch 80/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4153 - acc: 0.6682 - val_loss: 0.4181 - val_acc: 0.5972\n",
      "Epoch 81/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4060 - acc: 0.6636 - val_loss: 0.4134 - val_acc: 0.5972\n",
      "Epoch 82/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.4045 - acc: 0.6821 - val_loss: 0.4089 - val_acc: 0.5972\n",
      "Epoch 83/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.4029 - acc: 0.6759 - val_loss: 0.4042 - val_acc: 0.6111\n",
      "Epoch 84/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.3961 - acc: 0.6728 - val_loss: 0.3998 - val_acc: 0.6111\n",
      "Epoch 85/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.3928 - acc: 0.6821 - val_loss: 0.3954 - val_acc: 0.6111\n",
      "Epoch 86/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.3886 - acc: 0.6852 - val_loss: 0.3909 - val_acc: 0.6111\n",
      "Epoch 87/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.3840 - acc: 0.6790 - val_loss: 0.3866 - val_acc: 0.6111\n",
      "Epoch 88/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.3776 - acc: 0.6836 - val_loss: 0.3826 - val_acc: 0.5972\n",
      "Epoch 89/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.3774 - acc: 0.6574 - val_loss: 0.3785 - val_acc: 0.5972\n",
      "Epoch 90/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.3723 - acc: 0.6713 - val_loss: 0.3745 - val_acc: 0.6111\n",
      "Epoch 91/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.3670 - acc: 0.6605 - val_loss: 0.3704 - val_acc: 0.6111\n",
      "Epoch 92/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.3973 - acc: 0.562 - 0s 65us/step - loss: 0.3628 - acc: 0.6775 - val_loss: 0.3664 - val_acc: 0.6389\n",
      "Epoch 93/1000\n",
      "648/648 [==============================] - 0s 143us/step - loss: 0.3578 - acc: 0.6883 - val_loss: 0.3623 - val_acc: 0.6389\n",
      "Epoch 94/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.3575 - acc: 0.6759 - val_loss: 0.3583 - val_acc: 0.6389\n",
      "Epoch 95/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.3537 - acc: 0.6759 - val_loss: 0.3544 - val_acc: 0.6389\n",
      "Epoch 96/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.3470 - acc: 0.6821 - val_loss: 0.3507 - val_acc: 0.6389\n",
      "Epoch 97/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.3470 - acc: 0.6728 - val_loss: 0.3468 - val_acc: 0.6389\n",
      "Epoch 98/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.3441 - acc: 0.6620 - val_loss: 0.3433 - val_acc: 0.6389\n",
      "Epoch 99/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.3408 - acc: 0.6759 - val_loss: 0.3398 - val_acc: 0.6389\n",
      "Epoch 100/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.3321 - acc: 0.6929 - val_loss: 0.3363 - val_acc: 0.6389\n",
      "Epoch 101/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.3314 - acc: 0.6759 - val_loss: 0.3328 - val_acc: 0.6389\n",
      "Epoch 102/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.3304 - acc: 0.6667 - val_loss: 0.3295 - val_acc: 0.6528\n",
      "Epoch 103/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.3287 - acc: 0.6698 - val_loss: 0.3261 - val_acc: 0.6667\n",
      "Epoch 104/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.3243 - acc: 0.6852 - val_loss: 0.3229 - val_acc: 0.6667\n",
      "Epoch 105/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.3177 - acc: 0.6713 - val_loss: 0.3197 - val_acc: 0.6667\n",
      "Epoch 106/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.3145 - acc: 0.7068 - val_loss: 0.3169 - val_acc: 0.6667\n",
      "Epoch 107/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.3111 - acc: 0.6991 - val_loss: 0.3136 - val_acc: 0.6806\n",
      "Epoch 108/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.3092 - acc: 0.6975 - val_loss: 0.3106 - val_acc: 0.6806\n",
      "Epoch 109/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.3063 - acc: 0.6883 - val_loss: 0.3076 - val_acc: 0.6667\n",
      "Epoch 110/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.3031 - acc: 0.6821 - val_loss: 0.3047 - val_acc: 0.6667\n",
      "Epoch 111/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.3006 - acc: 0.6975 - val_loss: 0.3018 - val_acc: 0.6806\n",
      "Epoch 112/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.3035 - acc: 0.6744 - val_loss: 0.2991 - val_acc: 0.6806\n",
      "Epoch 113/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2942 - acc: 0.6929 - val_loss: 0.2964 - val_acc: 0.6944\n",
      "Epoch 114/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2950 - acc: 0.6867 - val_loss: 0.2942 - val_acc: 0.6806\n",
      "Epoch 115/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2892 - acc: 0.6821 - val_loss: 0.2919 - val_acc: 0.6806\n",
      "Epoch 116/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2918 - acc: 0.6806 - val_loss: 0.2894 - val_acc: 0.7083\n",
      "Epoch 117/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2884 - acc: 0.6929 - val_loss: 0.2873 - val_acc: 0.6806\n",
      "Epoch 118/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.2865 - acc: 0.6775 - val_loss: 0.2851 - val_acc: 0.6944\n",
      "Epoch 119/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2828 - acc: 0.6975 - val_loss: 0.2832 - val_acc: 0.6667\n",
      "Epoch 120/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2837 - acc: 0.6867 - val_loss: 0.2812 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.2797 - acc: 0.6975 - val_loss: 0.2792 - val_acc: 0.6667\n",
      "Epoch 122/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2779 - acc: 0.6867 - val_loss: 0.2773 - val_acc: 0.6806\n",
      "Epoch 123/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2764 - acc: 0.6852 - val_loss: 0.2756 - val_acc: 0.6806\n",
      "Epoch 124/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2719 - acc: 0.6883 - val_loss: 0.2737 - val_acc: 0.6806\n",
      "Epoch 125/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2699 - acc: 0.6944 - val_loss: 0.2717 - val_acc: 0.6806\n",
      "Epoch 126/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2707 - acc: 0.7022 - val_loss: 0.2698 - val_acc: 0.6806\n",
      "Epoch 127/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2675 - acc: 0.6806 - val_loss: 0.2687 - val_acc: 0.6806\n",
      "Epoch 128/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.2657 - acc: 0.6929 - val_loss: 0.2672 - val_acc: 0.6806\n",
      "Epoch 129/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2632 - acc: 0.7006 - val_loss: 0.2657 - val_acc: 0.6806\n",
      "Epoch 130/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2642 - acc: 0.6852 - val_loss: 0.2645 - val_acc: 0.6667\n",
      "Epoch 131/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2603 - acc: 0.6960 - val_loss: 0.2625 - val_acc: 0.6806\n",
      "Epoch 132/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2601 - acc: 0.6836 - val_loss: 0.2614 - val_acc: 0.6806\n",
      "Epoch 133/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2554 - acc: 0.6975 - val_loss: 0.2596 - val_acc: 0.6806\n",
      "Epoch 134/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.2574 - acc: 0.6867 - val_loss: 0.2582 - val_acc: 0.6806\n",
      "Epoch 135/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2564 - acc: 0.6914 - val_loss: 0.2567 - val_acc: 0.6806\n",
      "Epoch 136/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2407 - acc: 0.625 - 0s 82us/step - loss: 0.2539 - acc: 0.6898 - val_loss: 0.2558 - val_acc: 0.6667\n",
      "Epoch 137/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.2496 - acc: 0.7052 - val_loss: 0.2545 - val_acc: 0.6667\n",
      "Epoch 138/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2525 - acc: 0.6790 - val_loss: 0.2531 - val_acc: 0.6667\n",
      "Epoch 139/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2485 - acc: 0.6821 - val_loss: 0.2517 - val_acc: 0.6667\n",
      "Epoch 140/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2519 - acc: 0.6821 - val_loss: 0.2502 - val_acc: 0.6806\n",
      "Epoch 141/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2497 - acc: 0.6790 - val_loss: 0.2489 - val_acc: 0.6944\n",
      "Epoch 142/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2427 - acc: 0.7130 - val_loss: 0.2472 - val_acc: 0.7083\n",
      "Epoch 143/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2439 - acc: 0.6960 - val_loss: 0.2462 - val_acc: 0.6944\n",
      "Epoch 144/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2411 - acc: 0.7022 - val_loss: 0.2453 - val_acc: 0.6944\n",
      "Epoch 145/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2417 - acc: 0.6944 - val_loss: 0.2441 - val_acc: 0.6944\n",
      "Epoch 146/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2452 - acc: 0.6806 - val_loss: 0.2427 - val_acc: 0.7083\n",
      "Epoch 147/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2426 - acc: 0.6821 - val_loss: 0.2418 - val_acc: 0.6944\n",
      "Epoch 148/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2420 - acc: 0.6944 - val_loss: 0.2405 - val_acc: 0.7361\n",
      "Epoch 149/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.2372 - acc: 0.6898 - val_loss: 0.2394 - val_acc: 0.7222\n",
      "Epoch 150/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2354 - acc: 0.7006 - val_loss: 0.2387 - val_acc: 0.7222\n",
      "Epoch 151/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.2352 - acc: 0.7130 - val_loss: 0.2375 - val_acc: 0.7083\n",
      "Epoch 152/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2356 - acc: 0.6929 - val_loss: 0.2364 - val_acc: 0.7361\n",
      "Epoch 153/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2338 - acc: 0.6867 - val_loss: 0.2357 - val_acc: 0.7222\n",
      "Epoch 154/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.2334 - acc: 0.6698 - val_loss: 0.2352 - val_acc: 0.6806\n",
      "Epoch 155/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2333 - acc: 0.6867 - val_loss: 0.2340 - val_acc: 0.7222\n",
      "Epoch 156/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2285 - acc: 0.6991 - val_loss: 0.2331 - val_acc: 0.7222\n",
      "Epoch 157/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2330 - acc: 0.7037 - val_loss: 0.2324 - val_acc: 0.7083\n",
      "Epoch 158/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2309 - acc: 0.6898 - val_loss: 0.2315 - val_acc: 0.7083\n",
      "Epoch 159/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2274 - acc: 0.7006 - val_loss: 0.2305 - val_acc: 0.7222\n",
      "Epoch 160/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2271 - acc: 0.7006 - val_loss: 0.2298 - val_acc: 0.7083\n",
      "Epoch 161/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2206 - acc: 0.7238 - val_loss: 0.2287 - val_acc: 0.7222\n",
      "Epoch 162/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2238 - acc: 0.6960 - val_loss: 0.2278 - val_acc: 0.7222\n",
      "Epoch 163/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2226 - acc: 0.7022 - val_loss: 0.2271 - val_acc: 0.7222\n",
      "Epoch 164/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.2236 - acc: 0.7145 - val_loss: 0.2264 - val_acc: 0.7222\n",
      "Epoch 165/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.2235 - acc: 0.6929 - val_loss: 0.2254 - val_acc: 0.7361\n",
      "Epoch 166/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2289 - acc: 0.7006 - val_loss: 0.2250 - val_acc: 0.7083\n",
      "Epoch 167/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2199 - acc: 0.7037 - val_loss: 0.2243 - val_acc: 0.7083\n",
      "Epoch 168/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2266 - acc: 0.6775 - val_loss: 0.2236 - val_acc: 0.7083\n",
      "Epoch 169/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.2228 - acc: 0.7083 - val_loss: 0.2229 - val_acc: 0.7222\n",
      "Epoch 170/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2209 - acc: 0.7068 - val_loss: 0.2219 - val_acc: 0.7222\n",
      "Epoch 171/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.2168 - acc: 0.7238 - val_loss: 0.2211 - val_acc: 0.7361\n",
      "Epoch 172/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.2228 - acc: 0.6944 - val_loss: 0.2209 - val_acc: 0.7361\n",
      "Epoch 173/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.2235 - acc: 0.6914 - val_loss: 0.2204 - val_acc: 0.7361\n",
      "Epoch 174/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.2210 - acc: 0.6867 - val_loss: 0.2198 - val_acc: 0.7222\n",
      "Epoch 175/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.2239 - acc: 0.6698 - val_loss: 0.2194 - val_acc: 0.7361\n",
      "Epoch 176/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.2174 - acc: 0.6975 - val_loss: 0.2191 - val_acc: 0.7361\n",
      "Epoch 177/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.2182 - acc: 0.7099 - val_loss: 0.2184 - val_acc: 0.7500\n",
      "Epoch 178/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.2152 - acc: 0.7068 - val_loss: 0.2178 - val_acc: 0.7361\n",
      "Epoch 179/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2162 - acc: 0.7006 - val_loss: 0.2172 - val_acc: 0.7222\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 74us/step - loss: 0.2190 - acc: 0.6929 - val_loss: 0.2168 - val_acc: 0.7361\n",
      "Epoch 181/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.2146 - acc: 0.6929 - val_loss: 0.2163 - val_acc: 0.7361\n",
      "Epoch 182/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.2164 - acc: 0.7068 - val_loss: 0.2158 - val_acc: 0.7500\n",
      "Epoch 183/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.2123 - acc: 0.7068 - val_loss: 0.2155 - val_acc: 0.7639\n",
      "Epoch 184/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2170 - acc: 0.6991 - val_loss: 0.2153 - val_acc: 0.7639\n",
      "Epoch 185/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2095 - acc: 0.7160 - val_loss: 0.2151 - val_acc: 0.7361\n",
      "Epoch 186/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2101 - acc: 0.7099 - val_loss: 0.2143 - val_acc: 0.7222\n",
      "Epoch 187/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2115 - acc: 0.7176 - val_loss: 0.2139 - val_acc: 0.7222\n",
      "Epoch 188/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2194 - acc: 0.6898 - val_loss: 0.2141 - val_acc: 0.7222\n",
      "Epoch 189/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2138 - acc: 0.6836 - val_loss: 0.2131 - val_acc: 0.7361\n",
      "Epoch 190/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2139 - acc: 0.6898 - val_loss: 0.2129 - val_acc: 0.7222\n",
      "Epoch 191/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2116 - acc: 0.6914 - val_loss: 0.2128 - val_acc: 0.7361\n",
      "Epoch 192/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2100 - acc: 0.7191 - val_loss: 0.2122 - val_acc: 0.7222\n",
      "Epoch 193/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2093 - acc: 0.7176 - val_loss: 0.2116 - val_acc: 0.7361\n",
      "Epoch 194/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2129 - acc: 0.6944 - val_loss: 0.2113 - val_acc: 0.7500\n",
      "Epoch 195/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2079 - acc: 0.7006 - val_loss: 0.2110 - val_acc: 0.7500\n",
      "Epoch 196/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2091 - acc: 0.7253 - val_loss: 0.2104 - val_acc: 0.7361\n",
      "Epoch 197/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2093 - acc: 0.7006 - val_loss: 0.2104 - val_acc: 0.7500\n",
      "Epoch 198/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.2040 - acc: 0.7006 - val_loss: 0.2103 - val_acc: 0.7222\n",
      "Epoch 199/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.2163 - acc: 0.6898 - val_loss: 0.2102 - val_acc: 0.7222\n",
      "Epoch 200/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.2184 - acc: 0.6713 - val_loss: 0.2099 - val_acc: 0.7639\n",
      "Epoch 201/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.2114 - acc: 0.6806 - val_loss: 0.2100 - val_acc: 0.7222\n",
      "Epoch 202/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2083 - acc: 0.7191 - val_loss: 0.2100 - val_acc: 0.7361\n",
      "Epoch 203/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.2119 - acc: 0.6944 - val_loss: 0.2099 - val_acc: 0.7083\n",
      "Epoch 204/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2088 - acc: 0.7083 - val_loss: 0.2093 - val_acc: 0.7222\n",
      "Epoch 205/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2152 - acc: 0.6806 - val_loss: 0.2092 - val_acc: 0.7083\n",
      "Epoch 206/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2107 - acc: 0.6836 - val_loss: 0.2093 - val_acc: 0.7083\n",
      "Epoch 207/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2071 - acc: 0.7114 - val_loss: 0.2090 - val_acc: 0.7083\n",
      "Epoch 208/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2100 - acc: 0.7176 - val_loss: 0.2087 - val_acc: 0.7361\n",
      "Epoch 209/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2040 - acc: 0.7191 - val_loss: 0.2082 - val_acc: 0.7361\n",
      "Epoch 210/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2084 - acc: 0.7068 - val_loss: 0.2081 - val_acc: 0.7361\n",
      "Epoch 211/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2064 - acc: 0.7114 - val_loss: 0.2076 - val_acc: 0.7361\n",
      "Epoch 212/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2103 - acc: 0.6944 - val_loss: 0.2078 - val_acc: 0.7361\n",
      "Epoch 213/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2086 - acc: 0.7022 - val_loss: 0.2075 - val_acc: 0.7361\n",
      "Epoch 214/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2106 - acc: 0.7006 - val_loss: 0.2073 - val_acc: 0.7222\n",
      "Epoch 215/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2097 - acc: 0.6728 - val_loss: 0.2070 - val_acc: 0.7361\n",
      "Epoch 216/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2107 - acc: 0.6991 - val_loss: 0.2069 - val_acc: 0.7361\n",
      "Epoch 217/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2095 - acc: 0.6914 - val_loss: 0.2069 - val_acc: 0.7083\n",
      "Epoch 218/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2089 - acc: 0.6929 - val_loss: 0.2064 - val_acc: 0.7222\n",
      "Epoch 219/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2044 - acc: 0.7160 - val_loss: 0.2062 - val_acc: 0.7500\n",
      "Epoch 220/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2026 - acc: 0.7099 - val_loss: 0.2062 - val_acc: 0.7361\n",
      "Epoch 221/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2060 - acc: 0.6991 - val_loss: 0.2061 - val_acc: 0.7500\n",
      "Epoch 222/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2030 - acc: 0.7022 - val_loss: 0.2057 - val_acc: 0.7361\n",
      "Epoch 223/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2095 - acc: 0.6759 - val_loss: 0.2059 - val_acc: 0.7361\n",
      "Epoch 224/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2071 - acc: 0.7022 - val_loss: 0.2059 - val_acc: 0.7361\n",
      "Epoch 225/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2030 - acc: 0.7130 - val_loss: 0.2055 - val_acc: 0.7500\n",
      "Epoch 226/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2071 - acc: 0.6960 - val_loss: 0.2055 - val_acc: 0.7361\n",
      "Epoch 227/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2087 - acc: 0.6836 - val_loss: 0.2053 - val_acc: 0.7222\n",
      "Epoch 228/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2069 - acc: 0.7083 - val_loss: 0.2054 - val_acc: 0.7361\n",
      "Epoch 229/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.2090 - acc: 0.7052 - val_loss: 0.2054 - val_acc: 0.7500\n",
      "Epoch 230/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2005 - acc: 0.7130 - val_loss: 0.2052 - val_acc: 0.7361\n",
      "Epoch 231/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2105 - acc: 0.6883 - val_loss: 0.2051 - val_acc: 0.7222\n",
      "Epoch 232/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2013 - acc: 0.7284 - val_loss: 0.2047 - val_acc: 0.7361\n",
      "Epoch 233/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2031 - acc: 0.7207 - val_loss: 0.2045 - val_acc: 0.7222\n",
      "Epoch 234/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2077 - acc: 0.6944 - val_loss: 0.2049 - val_acc: 0.7361\n",
      "Epoch 235/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2075 - acc: 0.6944 - val_loss: 0.2049 - val_acc: 0.7361\n",
      "Epoch 236/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2019 - acc: 0.7145 - val_loss: 0.2046 - val_acc: 0.7361\n",
      "Epoch 237/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2066 - acc: 0.7022 - val_loss: 0.2044 - val_acc: 0.7361\n",
      "Epoch 238/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2057 - acc: 0.6975 - val_loss: 0.2043 - val_acc: 0.7361\n",
      "Epoch 239/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2043 - acc: 0.7068 - val_loss: 0.2042 - val_acc: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2046 - acc: 0.7099 - val_loss: 0.2040 - val_acc: 0.7361\n",
      "Epoch 241/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2010 - acc: 0.7068 - val_loss: 0.2035 - val_acc: 0.7083\n",
      "Epoch 242/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.2074 - acc: 0.7083 - val_loss: 0.2033 - val_acc: 0.7083\n",
      "Epoch 243/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2061 - acc: 0.7099 - val_loss: 0.2032 - val_acc: 0.7083\n",
      "Epoch 244/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2059 - acc: 0.7068 - val_loss: 0.2030 - val_acc: 0.7083\n",
      "Epoch 245/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2061 - acc: 0.6852 - val_loss: 0.2036 - val_acc: 0.7361\n",
      "Epoch 246/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2067 - acc: 0.7068 - val_loss: 0.2032 - val_acc: 0.7222\n",
      "Epoch 247/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2040 - acc: 0.7099 - val_loss: 0.2033 - val_acc: 0.7222\n",
      "Epoch 248/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.2068 - acc: 0.6929 - val_loss: 0.2030 - val_acc: 0.7222\n",
      "Epoch 249/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2015 - acc: 0.7191 - val_loss: 0.2030 - val_acc: 0.7222\n",
      "Epoch 250/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2003 - acc: 0.7160 - val_loss: 0.2024 - val_acc: 0.7083\n",
      "Epoch 251/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2040 - acc: 0.7052 - val_loss: 0.2024 - val_acc: 0.7083\n",
      "Epoch 252/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2041 - acc: 0.7052 - val_loss: 0.2026 - val_acc: 0.7083\n",
      "Epoch 253/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2030 - acc: 0.7068 - val_loss: 0.2022 - val_acc: 0.7083\n",
      "Epoch 254/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.2024 - acc: 0.6929 - val_loss: 0.2021 - val_acc: 0.7083\n",
      "Epoch 255/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.2015 - acc: 0.7253 - val_loss: 0.2023 - val_acc: 0.7083\n",
      "Epoch 256/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1965 - acc: 0.7315 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 257/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.2014 - acc: 0.7207 - val_loss: 0.2015 - val_acc: 0.6806\n",
      "Epoch 258/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2007 - acc: 0.7191 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 259/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.2011 - acc: 0.6929 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 260/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2030 - acc: 0.7022 - val_loss: 0.2009 - val_acc: 0.6944\n",
      "Epoch 261/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2088 - acc: 0.6821 - val_loss: 0.2014 - val_acc: 0.6806\n",
      "Epoch 262/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1981 - acc: 0.7253 - val_loss: 0.2011 - val_acc: 0.6944\n",
      "Epoch 263/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1969 - acc: 0.7346 - val_loss: 0.2007 - val_acc: 0.7083\n",
      "Epoch 264/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2070 - acc: 0.6929 - val_loss: 0.2006 - val_acc: 0.6944\n",
      "Epoch 265/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1992 - acc: 0.7037 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 266/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.2027 - acc: 0.7006 - val_loss: 0.2003 - val_acc: 0.6944\n",
      "Epoch 267/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.2024 - acc: 0.7068 - val_loss: 0.2002 - val_acc: 0.7083\n",
      "Epoch 268/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.2067 - acc: 0.6929 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 269/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2042 - acc: 0.7130 - val_loss: 0.2003 - val_acc: 0.7083\n",
      "Epoch 270/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2011 - acc: 0.7299 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 271/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1986 - acc: 0.7176 - val_loss: 0.2000 - val_acc: 0.6944\n",
      "Epoch 272/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2008 - acc: 0.7006 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 273/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2009 - acc: 0.7176 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 274/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1967 - acc: 0.7269 - val_loss: 0.1999 - val_acc: 0.6806\n",
      "Epoch 275/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.2016 - acc: 0.6929 - val_loss: 0.2002 - val_acc: 0.6944\n",
      "Epoch 276/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2042 - acc: 0.7099 - val_loss: 0.2001 - val_acc: 0.6944\n",
      "Epoch 277/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2049 - acc: 0.7160 - val_loss: 0.1999 - val_acc: 0.7083\n",
      "Epoch 278/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1948 - acc: 0.7222 - val_loss: 0.1998 - val_acc: 0.6944\n",
      "Epoch 279/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2040 - acc: 0.7145 - val_loss: 0.1999 - val_acc: 0.6944\n",
      "Epoch 280/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2034 - acc: 0.6991 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 281/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2018 - acc: 0.7037 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 282/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.2022 - acc: 0.7068 - val_loss: 0.1994 - val_acc: 0.7083\n",
      "Epoch 283/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.2052 - acc: 0.6883 - val_loss: 0.1992 - val_acc: 0.7083\n",
      "Epoch 284/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1943 - acc: 0.7423 - val_loss: 0.1992 - val_acc: 0.7083\n",
      "Epoch 285/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2007 - acc: 0.7037 - val_loss: 0.1991 - val_acc: 0.7083\n",
      "Epoch 286/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2071 - acc: 0.6975 - val_loss: 0.1994 - val_acc: 0.7083\n",
      "Epoch 287/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1974 - acc: 0.7145 - val_loss: 0.1996 - val_acc: 0.6944\n",
      "Epoch 288/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.2035 - acc: 0.6898 - val_loss: 0.1991 - val_acc: 0.7083\n",
      "Epoch 289/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.2008 - acc: 0.6944 - val_loss: 0.1991 - val_acc: 0.7083\n",
      "Epoch 290/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1997 - acc: 0.7083 - val_loss: 0.1991 - val_acc: 0.7083\n",
      "Epoch 291/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1965 - acc: 0.7253 - val_loss: 0.1989 - val_acc: 0.7083\n",
      "Epoch 292/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2020 - acc: 0.7006 - val_loss: 0.1986 - val_acc: 0.7083\n",
      "Epoch 293/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1987 - acc: 0.7099 - val_loss: 0.1987 - val_acc: 0.7083\n",
      "Epoch 294/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2009 - acc: 0.7068 - val_loss: 0.1981 - val_acc: 0.6944\n",
      "Epoch 295/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2019 - acc: 0.7068 - val_loss: 0.1983 - val_acc: 0.6944\n",
      "Epoch 296/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1982 - acc: 0.7238 - val_loss: 0.1983 - val_acc: 0.7083\n",
      "Epoch 297/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1989 - acc: 0.7037 - val_loss: 0.1982 - val_acc: 0.6944\n",
      "Epoch 298/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2013 - acc: 0.7238 - val_loss: 0.1984 - val_acc: 0.7083\n",
      "Epoch 299/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.2027 - acc: 0.7068 - val_loss: 0.1985 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1970 - acc: 0.7253 - val_loss: 0.1979 - val_acc: 0.6944\n",
      "Epoch 301/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.2008 - acc: 0.7114 - val_loss: 0.1979 - val_acc: 0.6944\n",
      "Epoch 302/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1948 - acc: 0.7269 - val_loss: 0.1975 - val_acc: 0.6944\n",
      "Epoch 303/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.2015 - acc: 0.7284 - val_loss: 0.1976 - val_acc: 0.6944\n",
      "Epoch 304/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1996 - acc: 0.7269 - val_loss: 0.1980 - val_acc: 0.6944\n",
      "Epoch 305/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.2054 - acc: 0.7037 - val_loss: 0.1983 - val_acc: 0.7083\n",
      "Epoch 306/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1940 - acc: 0.7269 - val_loss: 0.1982 - val_acc: 0.7083\n",
      "Epoch 307/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1994 - acc: 0.6852 - val_loss: 0.1981 - val_acc: 0.7083\n",
      "Epoch 308/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1972 - acc: 0.7130 - val_loss: 0.1975 - val_acc: 0.6944\n",
      "Epoch 309/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1994 - acc: 0.7238 - val_loss: 0.1977 - val_acc: 0.6944\n",
      "Epoch 310/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1986 - acc: 0.7083 - val_loss: 0.1978 - val_acc: 0.6944\n",
      "Epoch 311/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1923 - acc: 0.7346 - val_loss: 0.1970 - val_acc: 0.6944\n",
      "Epoch 312/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1975 - acc: 0.7284 - val_loss: 0.1972 - val_acc: 0.6944\n",
      "Epoch 313/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1987 - acc: 0.7160 - val_loss: 0.1973 - val_acc: 0.6944\n",
      "Epoch 314/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.2004 - acc: 0.7160 - val_loss: 0.1974 - val_acc: 0.6944\n",
      "Epoch 315/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1983 - acc: 0.7083 - val_loss: 0.1972 - val_acc: 0.6944\n",
      "Epoch 316/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2044 - acc: 0.6898 - val_loss: 0.1977 - val_acc: 0.7083\n",
      "Epoch 317/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1980 - acc: 0.7130 - val_loss: 0.1970 - val_acc: 0.6944\n",
      "Epoch 318/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2006 - acc: 0.7176 - val_loss: 0.1969 - val_acc: 0.6944\n",
      "Epoch 319/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1964 - acc: 0.7130 - val_loss: 0.1970 - val_acc: 0.6944\n",
      "Epoch 320/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1954 - acc: 0.7238 - val_loss: 0.1967 - val_acc: 0.6944\n",
      "Epoch 321/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1962 - acc: 0.7238 - val_loss: 0.1966 - val_acc: 0.6944\n",
      "Epoch 322/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1982 - acc: 0.7022 - val_loss: 0.1969 - val_acc: 0.6944\n",
      "Epoch 323/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1992 - acc: 0.7022 - val_loss: 0.1968 - val_acc: 0.6944\n",
      "Epoch 324/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1986 - acc: 0.6944 - val_loss: 0.1967 - val_acc: 0.6944\n",
      "Epoch 325/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.2010 - acc: 0.7145 - val_loss: 0.1972 - val_acc: 0.6944\n",
      "Epoch 326/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.2006 - acc: 0.6960 - val_loss: 0.1969 - val_acc: 0.6944\n",
      "Epoch 327/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1990 - acc: 0.7037 - val_loss: 0.1969 - val_acc: 0.6944\n",
      "Epoch 328/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1962 - acc: 0.7114 - val_loss: 0.1965 - val_acc: 0.6944\n",
      "Epoch 329/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2154 - acc: 0.625 - 0s 79us/step - loss: 0.1992 - acc: 0.6867 - val_loss: 0.1963 - val_acc: 0.6944\n",
      "Epoch 330/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1935 - acc: 0.7222 - val_loss: 0.1963 - val_acc: 0.6944\n",
      "Epoch 331/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2007 - acc: 0.7114 - val_loss: 0.1965 - val_acc: 0.6944\n",
      "Epoch 332/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1938 - acc: 0.7222 - val_loss: 0.1963 - val_acc: 0.6944\n",
      "Epoch 333/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1927 - acc: 0.7377 - val_loss: 0.1959 - val_acc: 0.6944\n",
      "Epoch 334/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1999 - acc: 0.7176 - val_loss: 0.1959 - val_acc: 0.6944\n",
      "Epoch 335/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.2002 - acc: 0.7083 - val_loss: 0.1958 - val_acc: 0.6944\n",
      "Epoch 336/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1919 - acc: 0.7392 - val_loss: 0.1957 - val_acc: 0.6944\n",
      "Epoch 337/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1942 - acc: 0.7130 - val_loss: 0.1952 - val_acc: 0.6944\n",
      "Epoch 338/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1986 - acc: 0.7176 - val_loss: 0.1956 - val_acc: 0.6944\n",
      "Epoch 339/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1920 - acc: 0.7176 - val_loss: 0.1949 - val_acc: 0.6944\n",
      "Epoch 340/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1957 - acc: 0.7052 - val_loss: 0.1953 - val_acc: 0.6944\n",
      "Epoch 341/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1958 - acc: 0.7269 - val_loss: 0.1951 - val_acc: 0.6944\n",
      "Epoch 342/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1961 - acc: 0.7191 - val_loss: 0.1950 - val_acc: 0.6944\n",
      "Epoch 343/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1947 - acc: 0.7160 - val_loss: 0.1952 - val_acc: 0.6944\n",
      "Epoch 344/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1947 - acc: 0.7176 - val_loss: 0.1949 - val_acc: 0.6944\n",
      "Epoch 345/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.2000 - acc: 0.7083 - val_loss: 0.1952 - val_acc: 0.6944\n",
      "Epoch 346/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1981 - acc: 0.7145 - val_loss: 0.1950 - val_acc: 0.6944\n",
      "Epoch 347/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1920 - acc: 0.7315 - val_loss: 0.1955 - val_acc: 0.6944\n",
      "Epoch 348/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1971 - acc: 0.7222 - val_loss: 0.1954 - val_acc: 0.6944\n",
      "Epoch 349/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2010 - acc: 0.703 - 0s 95us/step - loss: 0.2000 - acc: 0.7037 - val_loss: 0.1950 - val_acc: 0.6944\n",
      "Epoch 350/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1969 - acc: 0.7022 - val_loss: 0.1948 - val_acc: 0.6806\n",
      "Epoch 351/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1941 - acc: 0.7145 - val_loss: 0.1948 - val_acc: 0.6944\n",
      "Epoch 352/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1905 - acc: 0.7284 - val_loss: 0.1949 - val_acc: 0.6944\n",
      "Epoch 353/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1951 - acc: 0.7068 - val_loss: 0.1949 - val_acc: 0.6944\n",
      "Epoch 354/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1984 - acc: 0.7099 - val_loss: 0.1948 - val_acc: 0.6944\n",
      "Epoch 355/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1937 - acc: 0.7238 - val_loss: 0.1947 - val_acc: 0.6944\n",
      "Epoch 356/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1986 - acc: 0.7037 - val_loss: 0.1950 - val_acc: 0.6944\n",
      "Epoch 357/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1952 - acc: 0.7006 - val_loss: 0.1949 - val_acc: 0.6944\n",
      "Epoch 358/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1972 - acc: 0.7207 - val_loss: 0.1943 - val_acc: 0.6944\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 102us/step - loss: 0.1923 - acc: 0.7238 - val_loss: 0.1944 - val_acc: 0.6944\n",
      "Epoch 360/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1962 - acc: 0.7176 - val_loss: 0.1942 - val_acc: 0.6944\n",
      "Epoch 361/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1940 - acc: 0.7114 - val_loss: 0.1941 - val_acc: 0.6944\n",
      "Epoch 362/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1979 - acc: 0.7145 - val_loss: 0.1952 - val_acc: 0.6944\n",
      "Epoch 363/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1979 - acc: 0.7145 - val_loss: 0.1944 - val_acc: 0.6944\n",
      "Epoch 364/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1936 - acc: 0.7191 - val_loss: 0.1940 - val_acc: 0.6806\n",
      "Epoch 365/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1913 - acc: 0.7315 - val_loss: 0.1942 - val_acc: 0.6944\n",
      "Epoch 366/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1983 - acc: 0.7130 - val_loss: 0.1941 - val_acc: 0.6944\n",
      "Epoch 367/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1946 - acc: 0.7299 - val_loss: 0.1939 - val_acc: 0.6667\n",
      "Epoch 368/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1959 - acc: 0.7330 - val_loss: 0.1941 - val_acc: 0.6667\n",
      "Epoch 369/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1954 - acc: 0.7191 - val_loss: 0.1938 - val_acc: 0.6667\n",
      "Epoch 370/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1993 - acc: 0.6975 - val_loss: 0.1942 - val_acc: 0.6667\n",
      "Epoch 371/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1926 - acc: 0.7191 - val_loss: 0.1942 - val_acc: 0.6806\n",
      "Epoch 372/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1913 - acc: 0.7315 - val_loss: 0.1936 - val_acc: 0.6806\n",
      "Epoch 373/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1884 - acc: 0.7269 - val_loss: 0.1934 - val_acc: 0.6667\n",
      "Epoch 374/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1938 - acc: 0.7222 - val_loss: 0.1937 - val_acc: 0.6806\n",
      "Epoch 375/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1968 - acc: 0.7160 - val_loss: 0.1935 - val_acc: 0.6667\n",
      "Epoch 376/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1934 - acc: 0.7253 - val_loss: 0.1936 - val_acc: 0.6944\n",
      "Epoch 377/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1927 - acc: 0.7222 - val_loss: 0.1934 - val_acc: 0.6667\n",
      "Epoch 378/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1952 - acc: 0.7207 - val_loss: 0.1931 - val_acc: 0.6667\n",
      "Epoch 379/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1953 - acc: 0.7130 - val_loss: 0.1930 - val_acc: 0.6667\n",
      "Epoch 380/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1962 - acc: 0.7377 - val_loss: 0.1935 - val_acc: 0.6667\n",
      "Epoch 381/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1967 - acc: 0.7083 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 382/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1956 - acc: 0.7099 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 383/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1916 - acc: 0.7099 - val_loss: 0.1933 - val_acc: 0.6806\n",
      "Epoch 384/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1961 - acc: 0.7238 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 385/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1981 - acc: 0.7083 - val_loss: 0.1931 - val_acc: 0.6667\n",
      "Epoch 386/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1969 - acc: 0.7176 - val_loss: 0.1935 - val_acc: 0.6667\n",
      "Epoch 387/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.2008 - acc: 0.6821 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 388/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1982 - acc: 0.7022 - val_loss: 0.1938 - val_acc: 0.6667\n",
      "Epoch 389/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1936 - acc: 0.7176 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 390/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1900 - acc: 0.7222 - val_loss: 0.1937 - val_acc: 0.6667\n",
      "Epoch 391/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1944 - acc: 0.7253 - val_loss: 0.1935 - val_acc: 0.6806\n",
      "Epoch 392/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1938 - acc: 0.7207 - val_loss: 0.1929 - val_acc: 0.6667\n",
      "Epoch 393/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1947 - acc: 0.7145 - val_loss: 0.1931 - val_acc: 0.6667\n",
      "Epoch 394/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1927 - acc: 0.7207 - val_loss: 0.1929 - val_acc: 0.6667\n",
      "Epoch 395/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1963 - acc: 0.7238 - val_loss: 0.1932 - val_acc: 0.6667\n",
      "Epoch 396/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1899 - acc: 0.7299 - val_loss: 0.1933 - val_acc: 0.6806\n",
      "Epoch 397/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1948 - acc: 0.7238 - val_loss: 0.1936 - val_acc: 0.6944\n",
      "Epoch 398/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1939 - acc: 0.7083 - val_loss: 0.1928 - val_acc: 0.6667\n",
      "Epoch 399/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1943 - acc: 0.7037 - val_loss: 0.1928 - val_acc: 0.6806\n",
      "Epoch 400/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1970 - acc: 0.7160 - val_loss: 0.1932 - val_acc: 0.6806\n",
      "Epoch 401/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1984 - acc: 0.6975 - val_loss: 0.1933 - val_acc: 0.6667\n",
      "Epoch 402/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.2024 - acc: 0.6991 - val_loss: 0.1937 - val_acc: 0.6806\n",
      "Epoch 403/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1949 - acc: 0.6883 - val_loss: 0.1934 - val_acc: 0.6806\n",
      "Epoch 404/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1916 - acc: 0.7253 - val_loss: 0.1929 - val_acc: 0.6667\n",
      "Epoch 405/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1892 - acc: 0.7176 - val_loss: 0.1927 - val_acc: 0.6667\n",
      "Epoch 406/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1941 - acc: 0.7037 - val_loss: 0.1926 - val_acc: 0.6667\n",
      "Epoch 407/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1938 - acc: 0.7130 - val_loss: 0.1926 - val_acc: 0.6806\n",
      "Epoch 408/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1908 - acc: 0.7269 - val_loss: 0.1927 - val_acc: 0.6806\n",
      "Epoch 409/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1961 - acc: 0.6898 - val_loss: 0.1924 - val_acc: 0.6667\n",
      "Epoch 410/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1960 - acc: 0.7006 - val_loss: 0.1926 - val_acc: 0.6667\n",
      "Epoch 411/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1934 - acc: 0.7114 - val_loss: 0.1925 - val_acc: 0.6667\n",
      "Epoch 412/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1942 - acc: 0.7176 - val_loss: 0.1926 - val_acc: 0.6667\n",
      "Epoch 413/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1895 - acc: 0.7160 - val_loss: 0.1924 - val_acc: 0.6667\n",
      "Epoch 414/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1983 - acc: 0.6929 - val_loss: 0.1925 - val_acc: 0.6667\n",
      "Epoch 415/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1900 - acc: 0.7222 - val_loss: 0.1923 - val_acc: 0.6667\n",
      "Epoch 416/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1999 - acc: 0.7052 - val_loss: 0.1923 - val_acc: 0.6667\n",
      "Epoch 417/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1928 - acc: 0.7145 - val_loss: 0.1922 - val_acc: 0.6667\n",
      "Epoch 418/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1918 - acc: 0.7176 - val_loss: 0.1922 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1885 - acc: 0.7346 - val_loss: 0.1920 - val_acc: 0.6667\n",
      "Epoch 420/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1916 - acc: 0.7207 - val_loss: 0.1918 - val_acc: 0.6667\n",
      "Epoch 421/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1969 - acc: 0.7022 - val_loss: 0.1927 - val_acc: 0.6667\n",
      "Epoch 422/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1930 - acc: 0.7284 - val_loss: 0.1921 - val_acc: 0.6667\n",
      "Epoch 423/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1932 - acc: 0.7222 - val_loss: 0.1918 - val_acc: 0.6667\n",
      "Epoch 424/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1947 - acc: 0.7191 - val_loss: 0.1920 - val_acc: 0.6667\n",
      "Epoch 425/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1915 - acc: 0.7222 - val_loss: 0.1915 - val_acc: 0.6667\n",
      "Epoch 426/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.2002 - acc: 0.6975 - val_loss: 0.1915 - val_acc: 0.6944\n",
      "Epoch 427/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1941 - acc: 0.7176 - val_loss: 0.1919 - val_acc: 0.6667\n",
      "Epoch 428/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1955 - acc: 0.7083 - val_loss: 0.1920 - val_acc: 0.6667\n",
      "Epoch 429/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1941 - acc: 0.7114 - val_loss: 0.1921 - val_acc: 0.6667\n",
      "Epoch 430/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1920 - acc: 0.7253 - val_loss: 0.1918 - val_acc: 0.6667\n",
      "Epoch 431/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1904 - acc: 0.7284 - val_loss: 0.1918 - val_acc: 0.6667\n",
      "Epoch 432/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1891 - acc: 0.7238 - val_loss: 0.1913 - val_acc: 0.6667\n",
      "Epoch 433/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1924 - acc: 0.7145 - val_loss: 0.1913 - val_acc: 0.6667\n",
      "Epoch 434/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1935 - acc: 0.7130 - val_loss: 0.1913 - val_acc: 0.6667\n",
      "Epoch 435/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1882 - acc: 0.7238 - val_loss: 0.1909 - val_acc: 0.6667\n",
      "Epoch 436/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1917 - acc: 0.7238 - val_loss: 0.1912 - val_acc: 0.6667\n",
      "Epoch 437/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1922 - acc: 0.7222 - val_loss: 0.1914 - val_acc: 0.6667\n",
      "Epoch 438/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1904 - acc: 0.7377 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 439/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1918 - acc: 0.7160 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 440/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1890 - acc: 0.7176 - val_loss: 0.1909 - val_acc: 0.6667\n",
      "Epoch 441/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1901 - acc: 0.7191 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 442/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.2021 - acc: 0.6914 - val_loss: 0.1915 - val_acc: 0.6667\n",
      "Epoch 443/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1916 - acc: 0.7222 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 444/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1911 - acc: 0.7284 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 445/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1916 - acc: 0.7160 - val_loss: 0.1905 - val_acc: 0.6944\n",
      "Epoch 446/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1964 - acc: 0.7176 - val_loss: 0.1910 - val_acc: 0.6806\n",
      "Epoch 447/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1903 - acc: 0.7330 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 448/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1907 - acc: 0.7176 - val_loss: 0.1910 - val_acc: 0.6806\n",
      "Epoch 449/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1926 - acc: 0.7099 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 450/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1951 - acc: 0.7068 - val_loss: 0.1912 - val_acc: 0.6667\n",
      "Epoch 451/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1920 - acc: 0.7191 - val_loss: 0.1910 - val_acc: 0.6667\n",
      "Epoch 452/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1943 - acc: 0.7006 - val_loss: 0.1914 - val_acc: 0.6667\n",
      "Epoch 453/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1979 - acc: 0.7160 - val_loss: 0.1913 - val_acc: 0.6806\n",
      "Epoch 454/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1938 - acc: 0.7083 - val_loss: 0.1913 - val_acc: 0.6667\n",
      "Epoch 455/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1992 - acc: 0.6898 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 456/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1897 - acc: 0.7253 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 457/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1886 - acc: 0.7500 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 458/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1954 - acc: 0.7145 - val_loss: 0.1914 - val_acc: 0.6667\n",
      "Epoch 459/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1916 - acc: 0.7099 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 460/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1910 - acc: 0.7222 - val_loss: 0.1912 - val_acc: 0.6667\n",
      "Epoch 461/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1863 - acc: 0.7392 - val_loss: 0.1914 - val_acc: 0.6667\n",
      "Epoch 462/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1879 - acc: 0.7207 - val_loss: 0.1908 - val_acc: 0.6806\n",
      "Epoch 463/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1889 - acc: 0.7222 - val_loss: 0.1907 - val_acc: 0.6806\n",
      "Epoch 464/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1948 - acc: 0.7083 - val_loss: 0.1909 - val_acc: 0.6667\n",
      "Epoch 465/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1932 - acc: 0.7299 - val_loss: 0.1902 - val_acc: 0.6806\n",
      "Epoch 466/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1926 - acc: 0.7099 - val_loss: 0.1902 - val_acc: 0.6944\n",
      "Epoch 467/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1970 - acc: 0.7269 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 468/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1903 - acc: 0.7330 - val_loss: 0.1903 - val_acc: 0.6806\n",
      "Epoch 469/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1880 - acc: 0.7392 - val_loss: 0.1902 - val_acc: 0.6806\n",
      "Epoch 470/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1910 - acc: 0.7207 - val_loss: 0.1914 - val_acc: 0.6667\n",
      "Epoch 471/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1936 - acc: 0.7099 - val_loss: 0.1911 - val_acc: 0.6806\n",
      "Epoch 472/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1929 - acc: 0.7083 - val_loss: 0.1906 - val_acc: 0.6667\n",
      "Epoch 473/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1962 - acc: 0.6914 - val_loss: 0.1911 - val_acc: 0.6667\n",
      "Epoch 474/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1880 - acc: 0.7330 - val_loss: 0.1901 - val_acc: 0.6806\n",
      "Epoch 475/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1882 - acc: 0.7176 - val_loss: 0.1902 - val_acc: 0.6806\n",
      "Epoch 476/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1968 - acc: 0.7253 - val_loss: 0.1910 - val_acc: 0.6667\n",
      "Epoch 477/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1920 - acc: 0.7160 - val_loss: 0.1903 - val_acc: 0.6667\n",
      "Epoch 478/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1925 - acc: 0.7222 - val_loss: 0.1904 - val_acc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1939 - acc: 0.7099 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 480/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1879 - acc: 0.7269 - val_loss: 0.1905 - val_acc: 0.6667\n",
      "Epoch 481/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1967 - acc: 0.7022 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 482/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1958 - acc: 0.7083 - val_loss: 0.1907 - val_acc: 0.6806\n",
      "Epoch 483/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1916 - acc: 0.7269 - val_loss: 0.1909 - val_acc: 0.6667\n",
      "Epoch 484/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1932 - acc: 0.7160 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 485/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1888 - acc: 0.7176 - val_loss: 0.1905 - val_acc: 0.6667\n",
      "Epoch 486/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1909 - acc: 0.7284 - val_loss: 0.1903 - val_acc: 0.6806\n",
      "Epoch 487/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1896 - acc: 0.7207 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 488/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1912 - acc: 0.7222 - val_loss: 0.1906 - val_acc: 0.6667\n",
      "Epoch 489/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1870 - acc: 0.7315 - val_loss: 0.1905 - val_acc: 0.6667\n",
      "Epoch 490/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1934 - acc: 0.7222 - val_loss: 0.1900 - val_acc: 0.6806\n",
      "Epoch 491/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1983 - acc: 0.7160 - val_loss: 0.1903 - val_acc: 0.6667\n",
      "Epoch 492/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1879 - acc: 0.7284 - val_loss: 0.1897 - val_acc: 0.6806\n",
      "Epoch 493/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1850 - acc: 0.7238 - val_loss: 0.1894 - val_acc: 0.6806\n",
      "Epoch 494/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1931 - acc: 0.7160 - val_loss: 0.1895 - val_acc: 0.6806\n",
      "Epoch 495/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1868 - acc: 0.7361 - val_loss: 0.1895 - val_acc: 0.6806\n",
      "Epoch 496/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1918 - acc: 0.7145 - val_loss: 0.1894 - val_acc: 0.6806\n",
      "Epoch 497/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1948 - acc: 0.6960 - val_loss: 0.1896 - val_acc: 0.6806\n",
      "Epoch 498/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1839 - acc: 0.7330 - val_loss: 0.1893 - val_acc: 0.6806\n",
      "Epoch 499/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1941 - acc: 0.7052 - val_loss: 0.1896 - val_acc: 0.6806\n",
      "Epoch 500/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1940 - acc: 0.7099 - val_loss: 0.1899 - val_acc: 0.6806\n",
      "Epoch 501/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1934 - acc: 0.7114 - val_loss: 0.1895 - val_acc: 0.6806\n",
      "Epoch 502/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1950 - acc: 0.7022 - val_loss: 0.1896 - val_acc: 0.6806\n",
      "Epoch 503/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1918 - acc: 0.7207 - val_loss: 0.1901 - val_acc: 0.6806\n",
      "Epoch 504/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1928 - acc: 0.7145 - val_loss: 0.1900 - val_acc: 0.6806\n",
      "Epoch 505/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1902 - acc: 0.7160 - val_loss: 0.1899 - val_acc: 0.6806\n",
      "Epoch 506/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1950 - acc: 0.6960 - val_loss: 0.1902 - val_acc: 0.6806\n",
      "Epoch 507/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1856 - acc: 0.7392 - val_loss: 0.1897 - val_acc: 0.6806\n",
      "Epoch 508/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1910 - acc: 0.7052 - val_loss: 0.1897 - val_acc: 0.6806\n",
      "Epoch 509/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.2019 - acc: 0.6975 - val_loss: 0.1903 - val_acc: 0.6806\n",
      "Epoch 510/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1895 - acc: 0.7238 - val_loss: 0.1905 - val_acc: 0.6806\n",
      "Epoch 511/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1903 - acc: 0.7207 - val_loss: 0.1902 - val_acc: 0.6806\n",
      "Epoch 512/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1821 - acc: 0.7454 - val_loss: 0.1896 - val_acc: 0.6806\n",
      "Epoch 513/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1887 - acc: 0.7269 - val_loss: 0.1897 - val_acc: 0.6806\n",
      "Epoch 514/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1908 - acc: 0.7238 - val_loss: 0.1892 - val_acc: 0.6944\n",
      "Epoch 515/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1858 - acc: 0.7361 - val_loss: 0.1888 - val_acc: 0.6944\n",
      "Epoch 516/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1900 - acc: 0.7191 - val_loss: 0.1886 - val_acc: 0.6944\n",
      "Epoch 517/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1827 - acc: 0.7392 - val_loss: 0.1889 - val_acc: 0.6806\n",
      "Epoch 518/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1934 - acc: 0.7269 - val_loss: 0.1887 - val_acc: 0.6944\n",
      "Epoch 519/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1882 - acc: 0.7191 - val_loss: 0.1889 - val_acc: 0.6806\n",
      "Epoch 520/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1949 - acc: 0.6929 - val_loss: 0.1887 - val_acc: 0.6944\n",
      "Epoch 521/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1924 - acc: 0.7222 - val_loss: 0.1893 - val_acc: 0.6806\n",
      "Epoch 522/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1911 - acc: 0.7207 - val_loss: 0.1889 - val_acc: 0.6806\n",
      "Epoch 523/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1902 - acc: 0.7145 - val_loss: 0.1891 - val_acc: 0.6944\n",
      "Epoch 524/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1902 - acc: 0.7269 - val_loss: 0.1890 - val_acc: 0.6806\n",
      "Epoch 525/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1890 - acc: 0.7099 - val_loss: 0.1888 - val_acc: 0.6806\n",
      "Epoch 526/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1931 - acc: 0.7176 - val_loss: 0.1887 - val_acc: 0.6944\n",
      "Epoch 527/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1932 - acc: 0.7238 - val_loss: 0.1887 - val_acc: 0.6944\n",
      "Epoch 528/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1933 - acc: 0.7099 - val_loss: 0.1888 - val_acc: 0.6806\n",
      "Epoch 529/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1945 - acc: 0.6991 - val_loss: 0.1888 - val_acc: 0.6806\n",
      "Epoch 530/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1868 - acc: 0.7222 - val_loss: 0.1889 - val_acc: 0.6806\n",
      "Epoch 531/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1892 - acc: 0.7284 - val_loss: 0.1886 - val_acc: 0.6806\n",
      "Epoch 532/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1836 - acc: 0.7346 - val_loss: 0.1883 - val_acc: 0.6944\n",
      "Epoch 533/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1879 - acc: 0.7207 - val_loss: 0.1884 - val_acc: 0.6806\n",
      "Epoch 534/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1921 - acc: 0.7191 - val_loss: 0.1891 - val_acc: 0.6806\n",
      "Epoch 535/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1859 - acc: 0.7670 - val_loss: 0.1887 - val_acc: 0.6806\n",
      "Epoch 536/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1896 - acc: 0.7238 - val_loss: 0.1886 - val_acc: 0.6806\n",
      "Epoch 537/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1874 - acc: 0.7515 - val_loss: 0.1882 - val_acc: 0.6944\n",
      "Epoch 538/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1891 - acc: 0.7145 - val_loss: 0.1879 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1872 - acc: 0.7392 - val_loss: 0.1876 - val_acc: 0.6944\n",
      "Epoch 540/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1828 - acc: 0.7454 - val_loss: 0.1875 - val_acc: 0.7083\n",
      "Epoch 541/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1869 - acc: 0.7269 - val_loss: 0.1873 - val_acc: 0.7083\n",
      "Epoch 542/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1899 - acc: 0.7176 - val_loss: 0.1872 - val_acc: 0.7083\n",
      "Epoch 543/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1844 - acc: 0.7423 - val_loss: 0.1869 - val_acc: 0.7083\n",
      "Epoch 544/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1896 - acc: 0.7191 - val_loss: 0.1871 - val_acc: 0.7083\n",
      "Epoch 545/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1872 - acc: 0.7253 - val_loss: 0.1872 - val_acc: 0.6944\n",
      "Epoch 546/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1891 - acc: 0.7361 - val_loss: 0.1872 - val_acc: 0.7083\n",
      "Epoch 547/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1881 - acc: 0.7284 - val_loss: 0.1873 - val_acc: 0.7083\n",
      "Epoch 548/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1900 - acc: 0.7160 - val_loss: 0.1871 - val_acc: 0.7083\n",
      "Epoch 549/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1949 - acc: 0.7145 - val_loss: 0.1875 - val_acc: 0.6944\n",
      "Epoch 550/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1873 - acc: 0.7269 - val_loss: 0.1872 - val_acc: 0.7083\n",
      "Epoch 551/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1883 - acc: 0.7330 - val_loss: 0.1875 - val_acc: 0.6944\n",
      "Epoch 552/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1984 - acc: 0.6944 - val_loss: 0.1875 - val_acc: 0.7083\n",
      "Epoch 553/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1916 - acc: 0.7160 - val_loss: 0.1878 - val_acc: 0.6806\n",
      "Epoch 554/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1935 - acc: 0.6960 - val_loss: 0.1882 - val_acc: 0.6806\n",
      "Epoch 555/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1884 - acc: 0.7222 - val_loss: 0.1877 - val_acc: 0.6944\n",
      "Epoch 556/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1856 - acc: 0.7438 - val_loss: 0.1874 - val_acc: 0.6944\n",
      "Epoch 557/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1951 - acc: 0.7160 - val_loss: 0.1882 - val_acc: 0.6806\n",
      "Epoch 558/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1863 - acc: 0.7299 - val_loss: 0.1877 - val_acc: 0.6806\n",
      "Epoch 559/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1875 - acc: 0.7330 - val_loss: 0.1879 - val_acc: 0.6806\n",
      "Epoch 560/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1822 - acc: 0.7361 - val_loss: 0.1876 - val_acc: 0.6944\n",
      "Epoch 561/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1904 - acc: 0.7176 - val_loss: 0.1875 - val_acc: 0.6944\n",
      "Epoch 562/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1900 - acc: 0.7269 - val_loss: 0.1876 - val_acc: 0.6944\n",
      "Epoch 563/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1931 - acc: 0.7160 - val_loss: 0.1881 - val_acc: 0.6806\n",
      "Epoch 564/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1874 - acc: 0.7330 - val_loss: 0.1881 - val_acc: 0.6806\n",
      "Epoch 565/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1880 - acc: 0.7191 - val_loss: 0.1877 - val_acc: 0.6806\n",
      "Epoch 566/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1837 - acc: 0.7392 - val_loss: 0.1872 - val_acc: 0.7083\n",
      "Epoch 567/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1867 - acc: 0.7130 - val_loss: 0.1874 - val_acc: 0.6944\n",
      "Epoch 568/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1890 - acc: 0.7160 - val_loss: 0.1877 - val_acc: 0.6806\n",
      "Epoch 569/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1886 - acc: 0.7377 - val_loss: 0.1871 - val_acc: 0.7083\n",
      "Epoch 570/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1894 - acc: 0.7191 - val_loss: 0.1872 - val_acc: 0.6944\n",
      "Epoch 571/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1893 - acc: 0.7238 - val_loss: 0.1877 - val_acc: 0.6944\n",
      "Epoch 572/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1857 - acc: 0.7207 - val_loss: 0.1878 - val_acc: 0.6806\n",
      "Epoch 573/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1923 - acc: 0.7284 - val_loss: 0.1872 - val_acc: 0.6944\n",
      "Epoch 574/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1872 - acc: 0.7330 - val_loss: 0.1877 - val_acc: 0.6806\n",
      "Epoch 575/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1897 - acc: 0.7299 - val_loss: 0.1875 - val_acc: 0.6806\n",
      "Epoch 576/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1887 - acc: 0.7160 - val_loss: 0.1875 - val_acc: 0.6806\n",
      "Epoch 577/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1860 - acc: 0.7454 - val_loss: 0.1872 - val_acc: 0.6806\n",
      "Epoch 578/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1881 - acc: 0.7377 - val_loss: 0.1867 - val_acc: 0.7083\n",
      "Epoch 579/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1876 - acc: 0.7130 - val_loss: 0.1871 - val_acc: 0.7083\n",
      "Epoch 580/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1830 - acc: 0.7407 - val_loss: 0.1874 - val_acc: 0.6944\n",
      "Epoch 581/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1838 - acc: 0.7207 - val_loss: 0.1864 - val_acc: 0.7083\n",
      "Epoch 582/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1902 - acc: 0.7222 - val_loss: 0.1864 - val_acc: 0.7083\n",
      "Epoch 583/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1894 - acc: 0.7191 - val_loss: 0.1877 - val_acc: 0.6806\n",
      "Epoch 584/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1852 - acc: 0.7191 - val_loss: 0.1865 - val_acc: 0.7083\n",
      "Epoch 585/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1851 - acc: 0.7269 - val_loss: 0.1863 - val_acc: 0.7083\n",
      "Epoch 586/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1872 - acc: 0.7238 - val_loss: 0.1863 - val_acc: 0.7222\n",
      "Epoch 587/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1873 - acc: 0.7315 - val_loss: 0.1869 - val_acc: 0.7083\n",
      "Epoch 588/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1939 - acc: 0.7022 - val_loss: 0.1870 - val_acc: 0.6944\n",
      "Epoch 589/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1900 - acc: 0.7346 - val_loss: 0.1878 - val_acc: 0.6806\n",
      "Epoch 590/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1823 - acc: 0.7377 - val_loss: 0.1866 - val_acc: 0.7083\n",
      "Epoch 591/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1875 - acc: 0.7315 - val_loss: 0.1865 - val_acc: 0.7083\n",
      "Epoch 592/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1853 - acc: 0.7330 - val_loss: 0.1865 - val_acc: 0.7083\n",
      "Epoch 593/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1889 - acc: 0.7207 - val_loss: 0.1866 - val_acc: 0.7083\n",
      "Epoch 594/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1869 - acc: 0.7253 - val_loss: 0.1864 - val_acc: 0.7083\n",
      "Epoch 595/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1874 - acc: 0.7222 - val_loss: 0.1867 - val_acc: 0.6944\n",
      "Epoch 596/1000\n",
      "648/648 [==============================] - 0s 136us/step - loss: 0.1919 - acc: 0.7176 - val_loss: 0.1868 - val_acc: 0.6944\n",
      "Epoch 597/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1851 - acc: 0.7500 - val_loss: 0.1864 - val_acc: 0.7083\n",
      "Epoch 598/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1854 - acc: 0.7392 - val_loss: 0.1866 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1899 - acc: 0.7284 - val_loss: 0.1860 - val_acc: 0.7083\n",
      "Epoch 600/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1942 - acc: 0.7114 - val_loss: 0.1866 - val_acc: 0.6944\n",
      "Epoch 601/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1871 - acc: 0.7346 - val_loss: 0.1862 - val_acc: 0.7083\n",
      "Epoch 602/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1868 - acc: 0.7438 - val_loss: 0.1860 - val_acc: 0.7083\n",
      "Epoch 603/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1911 - acc: 0.7099 - val_loss: 0.1862 - val_acc: 0.7083\n",
      "Epoch 604/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1906 - acc: 0.7083 - val_loss: 0.1874 - val_acc: 0.6806\n",
      "Epoch 605/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1861 - acc: 0.7315 - val_loss: 0.1863 - val_acc: 0.7083\n",
      "Epoch 606/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1849 - acc: 0.7315 - val_loss: 0.1861 - val_acc: 0.7083\n",
      "Epoch 607/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1888 - acc: 0.7284 - val_loss: 0.1861 - val_acc: 0.7083\n",
      "Epoch 608/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1884 - acc: 0.7377 - val_loss: 0.1864 - val_acc: 0.6944\n",
      "Epoch 609/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1833 - acc: 0.7485 - val_loss: 0.1858 - val_acc: 0.7083\n",
      "Epoch 610/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1849 - acc: 0.7330 - val_loss: 0.1862 - val_acc: 0.7083\n",
      "Epoch 611/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1904 - acc: 0.7099 - val_loss: 0.1866 - val_acc: 0.6806\n",
      "Epoch 612/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1849 - acc: 0.7284 - val_loss: 0.1860 - val_acc: 0.7083\n",
      "Epoch 613/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1819 - acc: 0.7577 - val_loss: 0.1857 - val_acc: 0.7083\n",
      "Epoch 614/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1848 - acc: 0.7269 - val_loss: 0.1868 - val_acc: 0.6944\n",
      "Epoch 615/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1894 - acc: 0.7222 - val_loss: 0.1861 - val_acc: 0.6944\n",
      "Epoch 616/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1875 - acc: 0.7145 - val_loss: 0.1863 - val_acc: 0.6944\n",
      "Epoch 617/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1822 - acc: 0.7346 - val_loss: 0.1857 - val_acc: 0.7083\n",
      "Epoch 618/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1855 - acc: 0.7238 - val_loss: 0.1855 - val_acc: 0.7083\n",
      "Epoch 619/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1882 - acc: 0.7238 - val_loss: 0.1858 - val_acc: 0.7083\n",
      "Epoch 620/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1873 - acc: 0.7377 - val_loss: 0.1855 - val_acc: 0.7083\n",
      "Epoch 621/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1892 - acc: 0.7253 - val_loss: 0.1856 - val_acc: 0.7083\n",
      "Epoch 622/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1903 - acc: 0.7284 - val_loss: 0.1862 - val_acc: 0.6944\n",
      "Epoch 623/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1866 - acc: 0.7253 - val_loss: 0.1853 - val_acc: 0.7083\n",
      "Epoch 624/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1884 - acc: 0.7099 - val_loss: 0.1856 - val_acc: 0.7083\n",
      "Epoch 625/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1849 - acc: 0.7238 - val_loss: 0.1855 - val_acc: 0.7083\n",
      "Epoch 626/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1855 - acc: 0.7315 - val_loss: 0.1861 - val_acc: 0.6806\n",
      "Epoch 627/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1932 - acc: 0.7145 - val_loss: 0.1861 - val_acc: 0.6806\n",
      "Epoch 628/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1919 - acc: 0.7253 - val_loss: 0.1867 - val_acc: 0.6806\n",
      "Epoch 629/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1853 - acc: 0.7315 - val_loss: 0.1863 - val_acc: 0.6944\n",
      "Epoch 630/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1906 - acc: 0.7222 - val_loss: 0.1865 - val_acc: 0.6806\n",
      "Epoch 631/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1898 - acc: 0.7284 - val_loss: 0.1861 - val_acc: 0.6944\n",
      "Epoch 632/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1819 - acc: 0.7392 - val_loss: 0.1860 - val_acc: 0.6944\n",
      "Epoch 633/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1822 - acc: 0.7346 - val_loss: 0.1861 - val_acc: 0.6944\n",
      "Epoch 634/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1865 - acc: 0.7315 - val_loss: 0.1858 - val_acc: 0.6944\n",
      "Epoch 635/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1875 - acc: 0.7176 - val_loss: 0.1859 - val_acc: 0.6944\n",
      "Epoch 636/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1858 - acc: 0.7438 - val_loss: 0.1862 - val_acc: 0.6806\n",
      "Epoch 637/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1850 - acc: 0.7269 - val_loss: 0.1860 - val_acc: 0.6944\n",
      "Epoch 638/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1893 - acc: 0.7253 - val_loss: 0.1859 - val_acc: 0.6944\n",
      "Epoch 639/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1877 - acc: 0.7361 - val_loss: 0.1856 - val_acc: 0.6944\n",
      "Epoch 640/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1857 - acc: 0.7423 - val_loss: 0.1857 - val_acc: 0.7083\n",
      "Epoch 641/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1902 - acc: 0.7330 - val_loss: 0.1857 - val_acc: 0.6944\n",
      "Epoch 642/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1899 - acc: 0.7207 - val_loss: 0.1866 - val_acc: 0.6806\n",
      "Epoch 643/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1872 - acc: 0.7145 - val_loss: 0.1858 - val_acc: 0.6944\n",
      "Epoch 644/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1884 - acc: 0.7222 - val_loss: 0.1855 - val_acc: 0.7083\n",
      "Epoch 645/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1838 - acc: 0.7593 - val_loss: 0.1855 - val_acc: 0.7083\n",
      "Epoch 646/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1823 - acc: 0.7407 - val_loss: 0.1851 - val_acc: 0.7083\n",
      "Epoch 647/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1930 - acc: 0.7130 - val_loss: 0.1850 - val_acc: 0.7083\n",
      "Epoch 648/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1874 - acc: 0.7407 - val_loss: 0.1856 - val_acc: 0.6944\n",
      "Epoch 649/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1905 - acc: 0.7330 - val_loss: 0.1857 - val_acc: 0.6944\n",
      "Epoch 650/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1847 - acc: 0.7469 - val_loss: 0.1857 - val_acc: 0.6944\n",
      "Epoch 651/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1856 - acc: 0.7392 - val_loss: 0.1857 - val_acc: 0.6944\n",
      "Epoch 652/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1848 - acc: 0.7299 - val_loss: 0.1858 - val_acc: 0.6944\n",
      "Epoch 653/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1830 - acc: 0.7315 - val_loss: 0.1848 - val_acc: 0.7083\n",
      "Epoch 654/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1845 - acc: 0.7438 - val_loss: 0.1849 - val_acc: 0.7083\n",
      "Epoch 655/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1831 - acc: 0.7330 - val_loss: 0.1851 - val_acc: 0.7083\n",
      "Epoch 656/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1909 - acc: 0.7176 - val_loss: 0.1856 - val_acc: 0.6944\n",
      "Epoch 657/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1906 - acc: 0.7191 - val_loss: 0.1853 - val_acc: 0.6944\n",
      "Epoch 658/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1909 - acc: 0.7099 - val_loss: 0.1856 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 659/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1918 - acc: 0.7176 - val_loss: 0.1853 - val_acc: 0.6944\n",
      "Epoch 660/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1916 - acc: 0.7052 - val_loss: 0.1853 - val_acc: 0.7083\n",
      "Epoch 661/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1875 - acc: 0.7253 - val_loss: 0.1852 - val_acc: 0.6944\n",
      "Epoch 662/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1871 - acc: 0.7269 - val_loss: 0.1861 - val_acc: 0.6806\n",
      "Epoch 663/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1858 - acc: 0.7130 - val_loss: 0.1858 - val_acc: 0.6806\n",
      "Epoch 664/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1871 - acc: 0.7315 - val_loss: 0.1851 - val_acc: 0.7083\n",
      "Epoch 665/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1879 - acc: 0.7299 - val_loss: 0.1849 - val_acc: 0.7083\n",
      "Epoch 666/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1868 - acc: 0.7253 - val_loss: 0.1846 - val_acc: 0.7222\n",
      "Epoch 667/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1848 - acc: 0.7377 - val_loss: 0.1847 - val_acc: 0.7083\n",
      "Epoch 668/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1847 - acc: 0.7284 - val_loss: 0.1847 - val_acc: 0.7083\n",
      "Epoch 669/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1874 - acc: 0.7114 - val_loss: 0.1847 - val_acc: 0.7083\n",
      "Epoch 670/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1813 - acc: 0.7346 - val_loss: 0.1845 - val_acc: 0.7083\n",
      "Epoch 671/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1857 - acc: 0.7423 - val_loss: 0.1847 - val_acc: 0.7083\n",
      "Epoch 672/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1931 - acc: 0.7037 - val_loss: 0.1852 - val_acc: 0.6944\n",
      "Epoch 673/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1836 - acc: 0.7438 - val_loss: 0.1859 - val_acc: 0.6806\n",
      "Epoch 674/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1864 - acc: 0.7330 - val_loss: 0.1849 - val_acc: 0.7083\n",
      "Epoch 675/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1852 - acc: 0.7454 - val_loss: 0.1848 - val_acc: 0.7083\n",
      "Epoch 676/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1858 - acc: 0.7207 - val_loss: 0.1859 - val_acc: 0.6944\n",
      "Epoch 677/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1851 - acc: 0.7438 - val_loss: 0.1860 - val_acc: 0.6944\n",
      "Epoch 678/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1870 - acc: 0.7253 - val_loss: 0.1843 - val_acc: 0.7083\n",
      "Epoch 679/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1869 - acc: 0.7269 - val_loss: 0.1852 - val_acc: 0.7083\n",
      "Epoch 680/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1800 - acc: 0.7438 - val_loss: 0.1846 - val_acc: 0.7083\n",
      "Epoch 681/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1898 - acc: 0.7238 - val_loss: 0.1854 - val_acc: 0.6806\n",
      "Epoch 682/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1931 - acc: 0.7176 - val_loss: 0.1843 - val_acc: 0.7222\n",
      "Epoch 683/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1863 - acc: 0.7037 - val_loss: 0.1851 - val_acc: 0.6944\n",
      "Epoch 684/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1884 - acc: 0.7284 - val_loss: 0.1844 - val_acc: 0.7083\n",
      "Epoch 685/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1851 - acc: 0.7284 - val_loss: 0.1847 - val_acc: 0.7083\n",
      "Epoch 686/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1802 - acc: 0.7392 - val_loss: 0.1842 - val_acc: 0.7222\n",
      "Epoch 687/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1862 - acc: 0.7269 - val_loss: 0.1845 - val_acc: 0.7222\n",
      "Epoch 688/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1842 - acc: 0.7361 - val_loss: 0.1847 - val_acc: 0.6944\n",
      "Epoch 689/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1875 - acc: 0.7253 - val_loss: 0.1845 - val_acc: 0.6944\n",
      "Epoch 690/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1886 - acc: 0.7099 - val_loss: 0.1842 - val_acc: 0.7222\n",
      "Epoch 691/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1872 - acc: 0.7315 - val_loss: 0.1844 - val_acc: 0.7083\n",
      "Epoch 692/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1922 - acc: 0.7191 - val_loss: 0.1839 - val_acc: 0.7222\n",
      "Epoch 693/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1907 - acc: 0.7114 - val_loss: 0.1844 - val_acc: 0.7083\n",
      "Epoch 694/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1842 - acc: 0.7377 - val_loss: 0.1844 - val_acc: 0.6944\n",
      "Epoch 695/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1906 - acc: 0.7160 - val_loss: 0.1847 - val_acc: 0.6944\n",
      "Epoch 696/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1948 - acc: 0.7160 - val_loss: 0.1847 - val_acc: 0.6944\n",
      "Epoch 697/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1817 - acc: 0.7454 - val_loss: 0.1845 - val_acc: 0.6944\n",
      "Epoch 698/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1889 - acc: 0.7222 - val_loss: 0.1843 - val_acc: 0.6944\n",
      "Epoch 699/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1840 - acc: 0.7377 - val_loss: 0.1843 - val_acc: 0.6944\n",
      "Epoch 700/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1837 - acc: 0.7238 - val_loss: 0.1844 - val_acc: 0.6944\n",
      "Epoch 701/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1818 - acc: 0.7377 - val_loss: 0.1839 - val_acc: 0.7083\n",
      "Epoch 702/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1897 - acc: 0.7284 - val_loss: 0.1839 - val_acc: 0.7222\n",
      "Epoch 703/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1877 - acc: 0.7299 - val_loss: 0.1830 - val_acc: 0.7222\n",
      "Epoch 704/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1935 - acc: 0.7083 - val_loss: 0.1838 - val_acc: 0.7222\n",
      "Epoch 705/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1854 - acc: 0.7377 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 706/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1813 - acc: 0.7392 - val_loss: 0.1839 - val_acc: 0.7222\n",
      "Epoch 707/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1865 - acc: 0.7284 - val_loss: 0.1837 - val_acc: 0.7222\n",
      "Epoch 708/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1870 - acc: 0.7207 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 709/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1832 - acc: 0.7423 - val_loss: 0.1834 - val_acc: 0.7222\n",
      "Epoch 710/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1868 - acc: 0.7269 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 711/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1891 - acc: 0.7299 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 712/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1819 - acc: 0.7515 - val_loss: 0.1844 - val_acc: 0.7083\n",
      "Epoch 713/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1869 - acc: 0.7130 - val_loss: 0.1836 - val_acc: 0.7083\n",
      "Epoch 714/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1826 - acc: 0.7438 - val_loss: 0.1840 - val_acc: 0.7083\n",
      "Epoch 715/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1840 - acc: 0.7269 - val_loss: 0.1840 - val_acc: 0.7083\n",
      "Epoch 716/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1863 - acc: 0.7346 - val_loss: 0.1836 - val_acc: 0.7083\n",
      "Epoch 717/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1872 - acc: 0.7284 - val_loss: 0.1842 - val_acc: 0.7083\n",
      "Epoch 718/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1915 - acc: 0.7176 - val_loss: 0.1840 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1817 - acc: 0.7284 - val_loss: 0.1842 - val_acc: 0.7083\n",
      "Epoch 720/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1900 - acc: 0.7160 - val_loss: 0.1837 - val_acc: 0.7222\n",
      "Epoch 721/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1893 - acc: 0.7207 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 722/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1870 - acc: 0.7438 - val_loss: 0.1844 - val_acc: 0.7083\n",
      "Epoch 723/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1841 - acc: 0.7238 - val_loss: 0.1839 - val_acc: 0.7083\n",
      "Epoch 724/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1898 - acc: 0.7284 - val_loss: 0.1838 - val_acc: 0.7222\n",
      "Epoch 725/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1908 - acc: 0.7160 - val_loss: 0.1842 - val_acc: 0.7083\n",
      "Epoch 726/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1886 - acc: 0.7130 - val_loss: 0.1842 - val_acc: 0.7083\n",
      "Epoch 727/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1882 - acc: 0.7284 - val_loss: 0.1838 - val_acc: 0.7222\n",
      "Epoch 728/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1874 - acc: 0.7377 - val_loss: 0.1839 - val_acc: 0.7222\n",
      "Epoch 729/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1865 - acc: 0.7377 - val_loss: 0.1842 - val_acc: 0.7083\n",
      "Epoch 730/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1847 - acc: 0.7407 - val_loss: 0.1842 - val_acc: 0.6944\n",
      "Epoch 731/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1818 - acc: 0.7407 - val_loss: 0.1832 - val_acc: 0.7222\n",
      "Epoch 732/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1818 - acc: 0.7346 - val_loss: 0.1836 - val_acc: 0.7083\n",
      "Epoch 733/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1858 - acc: 0.7377 - val_loss: 0.1838 - val_acc: 0.7222\n",
      "Epoch 734/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1844 - acc: 0.7377 - val_loss: 0.1839 - val_acc: 0.7222\n",
      "Epoch 735/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1852 - acc: 0.7361 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 736/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1856 - acc: 0.7299 - val_loss: 0.1831 - val_acc: 0.7222\n",
      "Epoch 737/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1884 - acc: 0.7454 - val_loss: 0.1835 - val_acc: 0.7222\n",
      "Epoch 738/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1839 - acc: 0.7438 - val_loss: 0.1841 - val_acc: 0.7083\n",
      "Epoch 739/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1851 - acc: 0.7299 - val_loss: 0.1836 - val_acc: 0.7083\n",
      "Epoch 740/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1856 - acc: 0.7515 - val_loss: 0.1834 - val_acc: 0.7222\n",
      "Epoch 741/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1875 - acc: 0.7176 - val_loss: 0.1838 - val_acc: 0.7083\n",
      "Epoch 742/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1915 - acc: 0.7068 - val_loss: 0.1841 - val_acc: 0.7083\n",
      "Epoch 743/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1855 - acc: 0.7500 - val_loss: 0.1840 - val_acc: 0.7083\n",
      "Epoch 744/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1893 - acc: 0.7160 - val_loss: 0.1847 - val_acc: 0.6944\n",
      "Epoch 745/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1828 - acc: 0.7392 - val_loss: 0.1837 - val_acc: 0.7083\n",
      "Epoch 746/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1854 - acc: 0.7361 - val_loss: 0.1840 - val_acc: 0.7083\n",
      "Epoch 747/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1883 - acc: 0.7114 - val_loss: 0.1839 - val_acc: 0.7083\n",
      "Epoch 748/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1790 - acc: 0.7485 - val_loss: 0.1839 - val_acc: 0.7083\n",
      "Epoch 749/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1857 - acc: 0.7068 - val_loss: 0.1836 - val_acc: 0.7083\n",
      "Epoch 750/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1837 - acc: 0.7330 - val_loss: 0.1830 - val_acc: 0.7222\n",
      "Epoch 751/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1865 - acc: 0.7176 - val_loss: 0.1828 - val_acc: 0.7222\n",
      "Epoch 752/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1811 - acc: 0.7639 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 753/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1864 - acc: 0.7454 - val_loss: 0.1835 - val_acc: 0.7083\n",
      "Epoch 754/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1869 - acc: 0.7315 - val_loss: 0.1835 - val_acc: 0.7083\n",
      "Epoch 755/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1859 - acc: 0.7284 - val_loss: 0.1832 - val_acc: 0.7083\n",
      "Epoch 756/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1837 - acc: 0.7454 - val_loss: 0.1834 - val_acc: 0.7083\n",
      "Epoch 757/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1836 - acc: 0.7315 - val_loss: 0.1832 - val_acc: 0.7222\n",
      "Epoch 758/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1878 - acc: 0.7346 - val_loss: 0.1832 - val_acc: 0.7222\n",
      "Epoch 759/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1843 - acc: 0.7330 - val_loss: 0.1830 - val_acc: 0.7222\n",
      "Epoch 760/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1896 - acc: 0.7191 - val_loss: 0.1828 - val_acc: 0.7222\n",
      "Epoch 761/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1883 - acc: 0.7222 - val_loss: 0.1829 - val_acc: 0.7222\n",
      "Epoch 762/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1837 - acc: 0.7423 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 763/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1841 - acc: 0.7284 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 764/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1818 - acc: 0.7485 - val_loss: 0.1830 - val_acc: 0.7222\n",
      "Epoch 765/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1820 - acc: 0.7531 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 766/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1840 - acc: 0.7346 - val_loss: 0.1827 - val_acc: 0.7222\n",
      "Epoch 767/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1896 - acc: 0.7207 - val_loss: 0.1831 - val_acc: 0.7222\n",
      "Epoch 768/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1864 - acc: 0.7315 - val_loss: 0.1838 - val_acc: 0.7222\n",
      "Epoch 769/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1822 - acc: 0.7284 - val_loss: 0.1829 - val_acc: 0.7222\n",
      "Epoch 770/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1805 - acc: 0.7531 - val_loss: 0.1827 - val_acc: 0.7083\n",
      "Epoch 771/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1925 - acc: 0.7145 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 772/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1837 - acc: 0.7423 - val_loss: 0.1827 - val_acc: 0.7222\n",
      "Epoch 773/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1850 - acc: 0.7392 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 774/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1834 - acc: 0.7315 - val_loss: 0.1833 - val_acc: 0.7083\n",
      "Epoch 775/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1795 - acc: 0.7469 - val_loss: 0.1828 - val_acc: 0.7083\n",
      "Epoch 776/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1855 - acc: 0.7469 - val_loss: 0.1820 - val_acc: 0.7222\n",
      "Epoch 777/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1825 - acc: 0.7330 - val_loss: 0.1820 - val_acc: 0.7222\n",
      "Epoch 778/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1852 - acc: 0.7284 - val_loss: 0.1821 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1825 - acc: 0.7438 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 780/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1863 - acc: 0.7176 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 781/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1911 - acc: 0.7299 - val_loss: 0.1835 - val_acc: 0.7083\n",
      "Epoch 782/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1819 - acc: 0.7407 - val_loss: 0.1825 - val_acc: 0.7222\n",
      "Epoch 783/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1838 - acc: 0.7284 - val_loss: 0.1827 - val_acc: 0.7083\n",
      "Epoch 784/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1857 - acc: 0.7330 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 785/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1791 - acc: 0.7577 - val_loss: 0.1825 - val_acc: 0.7222\n",
      "Epoch 786/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1898 - acc: 0.7176 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 787/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1855 - acc: 0.7253 - val_loss: 0.1825 - val_acc: 0.7222\n",
      "Epoch 788/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1864 - acc: 0.7130 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 789/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1805 - acc: 0.7361 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 790/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1882 - acc: 0.7253 - val_loss: 0.1832 - val_acc: 0.7222\n",
      "Epoch 791/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1829 - acc: 0.7222 - val_loss: 0.1831 - val_acc: 0.7222\n",
      "Epoch 792/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1799 - acc: 0.7361 - val_loss: 0.1820 - val_acc: 0.7222\n",
      "Epoch 793/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1877 - acc: 0.7299 - val_loss: 0.1828 - val_acc: 0.7083\n",
      "Epoch 794/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1869 - acc: 0.7315 - val_loss: 0.1829 - val_acc: 0.7222\n",
      "Epoch 795/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1822 - acc: 0.7361 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 796/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1775 - acc: 0.7485 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 797/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1826 - acc: 0.7469 - val_loss: 0.1818 - val_acc: 0.7222\n",
      "Epoch 798/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1852 - acc: 0.7407 - val_loss: 0.1820 - val_acc: 0.7222\n",
      "Epoch 799/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1786 - acc: 0.7515 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 800/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1811 - acc: 0.7577 - val_loss: 0.1821 - val_acc: 0.7222\n",
      "Epoch 801/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1848 - acc: 0.7438 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 802/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1802 - acc: 0.7361 - val_loss: 0.1818 - val_acc: 0.7222\n",
      "Epoch 803/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1836 - acc: 0.7315 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 804/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1864 - acc: 0.7392 - val_loss: 0.1819 - val_acc: 0.7222\n",
      "Epoch 805/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1813 - acc: 0.7361 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 806/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1839 - acc: 0.7485 - val_loss: 0.1821 - val_acc: 0.7222\n",
      "Epoch 807/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1818 - acc: 0.7299 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 808/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1811 - acc: 0.7377 - val_loss: 0.1816 - val_acc: 0.7222\n",
      "Epoch 809/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1873 - acc: 0.7145 - val_loss: 0.1822 - val_acc: 0.7222\n",
      "Epoch 810/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1836 - acc: 0.7346 - val_loss: 0.1822 - val_acc: 0.7361\n",
      "Epoch 811/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1829 - acc: 0.7299 - val_loss: 0.1822 - val_acc: 0.7222\n",
      "Epoch 812/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1832 - acc: 0.7515 - val_loss: 0.1825 - val_acc: 0.7222\n",
      "Epoch 813/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1794 - acc: 0.7469 - val_loss: 0.1822 - val_acc: 0.7222\n",
      "Epoch 814/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1860 - acc: 0.7253 - val_loss: 0.1823 - val_acc: 0.7222\n",
      "Epoch 815/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1842 - acc: 0.7361 - val_loss: 0.1826 - val_acc: 0.7361\n",
      "Epoch 816/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1876 - acc: 0.7269 - val_loss: 0.1827 - val_acc: 0.7222\n",
      "Epoch 817/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1844 - acc: 0.7315 - val_loss: 0.1830 - val_acc: 0.7222\n",
      "Epoch 818/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1832 - acc: 0.7253 - val_loss: 0.1822 - val_acc: 0.7361\n",
      "Epoch 819/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1847 - acc: 0.7269 - val_loss: 0.1833 - val_acc: 0.7222\n",
      "Epoch 820/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1823 - acc: 0.7346 - val_loss: 0.1822 - val_acc: 0.7222\n",
      "Epoch 821/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1854 - acc: 0.7191 - val_loss: 0.1821 - val_acc: 0.7222\n",
      "Epoch 822/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1867 - acc: 0.7315 - val_loss: 0.1833 - val_acc: 0.7083\n",
      "Epoch 823/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1831 - acc: 0.7315 - val_loss: 0.1824 - val_acc: 0.7361\n",
      "Epoch 824/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1880 - acc: 0.7299 - val_loss: 0.1820 - val_acc: 0.7361\n",
      "Epoch 825/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1859 - acc: 0.7284 - val_loss: 0.1825 - val_acc: 0.7361\n",
      "Epoch 826/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1879 - acc: 0.7114 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 827/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1786 - acc: 0.7469 - val_loss: 0.1823 - val_acc: 0.7361\n",
      "Epoch 828/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1860 - acc: 0.7207 - val_loss: 0.1818 - val_acc: 0.7361\n",
      "Epoch 829/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1825 - acc: 0.7407 - val_loss: 0.1818 - val_acc: 0.7361\n",
      "Epoch 830/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1841 - acc: 0.7176 - val_loss: 0.1818 - val_acc: 0.7222\n",
      "Epoch 831/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1841 - acc: 0.7485 - val_loss: 0.1811 - val_acc: 0.7222\n",
      "Epoch 832/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1790 - acc: 0.7593 - val_loss: 0.1826 - val_acc: 0.7222\n",
      "Epoch 833/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1794 - acc: 0.7392 - val_loss: 0.1821 - val_acc: 0.7222\n",
      "Epoch 834/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1871 - acc: 0.7238 - val_loss: 0.1813 - val_acc: 0.7222\n",
      "Epoch 835/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1867 - acc: 0.7423 - val_loss: 0.1814 - val_acc: 0.7222\n",
      "Epoch 836/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1793 - acc: 0.7407 - val_loss: 0.1816 - val_acc: 0.7222\n",
      "Epoch 837/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1850 - acc: 0.7469 - val_loss: 0.1810 - val_acc: 0.7222\n",
      "Epoch 838/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1821 - acc: 0.7207 - val_loss: 0.1819 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1841 - acc: 0.7315 - val_loss: 0.1824 - val_acc: 0.7083\n",
      "Epoch 840/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1811 - acc: 0.7392 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 841/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1811 - acc: 0.7315 - val_loss: 0.1814 - val_acc: 0.7222\n",
      "Epoch 842/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1864 - acc: 0.7207 - val_loss: 0.1812 - val_acc: 0.7222\n",
      "Epoch 843/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1809 - acc: 0.7392 - val_loss: 0.1814 - val_acc: 0.7222\n",
      "Epoch 844/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1837 - acc: 0.7454 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 845/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1813 - acc: 0.7469 - val_loss: 0.1814 - val_acc: 0.7222\n",
      "Epoch 846/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1843 - acc: 0.7269 - val_loss: 0.1816 - val_acc: 0.7222\n",
      "Epoch 847/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1797 - acc: 0.7299 - val_loss: 0.1824 - val_acc: 0.7222\n",
      "Epoch 848/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1839 - acc: 0.7207 - val_loss: 0.1811 - val_acc: 0.7222\n",
      "Epoch 849/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1889 - acc: 0.7191 - val_loss: 0.1815 - val_acc: 0.7222\n",
      "Epoch 850/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1830 - acc: 0.7438 - val_loss: 0.1807 - val_acc: 0.7222\n",
      "Epoch 851/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1777 - acc: 0.7639 - val_loss: 0.1818 - val_acc: 0.7361\n",
      "Epoch 852/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1827 - acc: 0.7377 - val_loss: 0.1815 - val_acc: 0.7222\n",
      "Epoch 853/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1841 - acc: 0.7377 - val_loss: 0.1811 - val_acc: 0.7222\n",
      "Epoch 854/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1795 - acc: 0.7407 - val_loss: 0.1813 - val_acc: 0.7222\n",
      "Epoch 855/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1780 - acc: 0.7423 - val_loss: 0.1814 - val_acc: 0.7361\n",
      "Epoch 856/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1783 - acc: 0.7531 - val_loss: 0.1809 - val_acc: 0.7222\n",
      "Epoch 857/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1834 - acc: 0.7299 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 858/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1897 - acc: 0.7253 - val_loss: 0.1816 - val_acc: 0.7361\n",
      "Epoch 859/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1841 - acc: 0.7315 - val_loss: 0.1811 - val_acc: 0.7222\n",
      "Epoch 860/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1820 - acc: 0.7299 - val_loss: 0.1808 - val_acc: 0.7222\n",
      "Epoch 861/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1835 - acc: 0.7361 - val_loss: 0.1806 - val_acc: 0.7222\n",
      "Epoch 862/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1813 - acc: 0.7531 - val_loss: 0.1806 - val_acc: 0.7222\n",
      "Epoch 863/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1825 - acc: 0.7423 - val_loss: 0.1810 - val_acc: 0.7222\n",
      "Epoch 864/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1862 - acc: 0.7269 - val_loss: 0.1809 - val_acc: 0.7361\n",
      "Epoch 865/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1815 - acc: 0.7377 - val_loss: 0.1813 - val_acc: 0.7361\n",
      "Epoch 866/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1865 - acc: 0.7377 - val_loss: 0.1809 - val_acc: 0.7222\n",
      "Epoch 867/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1804 - acc: 0.7361 - val_loss: 0.1828 - val_acc: 0.7222\n",
      "Epoch 868/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1772 - acc: 0.7531 - val_loss: 0.1804 - val_acc: 0.7222\n",
      "Epoch 869/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1815 - acc: 0.7315 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 870/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1794 - acc: 0.7546 - val_loss: 0.1817 - val_acc: 0.7361\n",
      "Epoch 871/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1843 - acc: 0.7330 - val_loss: 0.1804 - val_acc: 0.7222\n",
      "Epoch 872/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1831 - acc: 0.7346 - val_loss: 0.1807 - val_acc: 0.7222\n",
      "Epoch 873/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1778 - acc: 0.7485 - val_loss: 0.1810 - val_acc: 0.7222\n",
      "Epoch 874/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1822 - acc: 0.7330 - val_loss: 0.1804 - val_acc: 0.7222\n",
      "Epoch 875/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1831 - acc: 0.7562 - val_loss: 0.1809 - val_acc: 0.7222\n",
      "Epoch 876/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1821 - acc: 0.7361 - val_loss: 0.1817 - val_acc: 0.7361\n",
      "Epoch 877/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1824 - acc: 0.7346 - val_loss: 0.1810 - val_acc: 0.7222\n",
      "Epoch 878/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1770 - acc: 0.7577 - val_loss: 0.1804 - val_acc: 0.7222\n",
      "Epoch 879/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1834 - acc: 0.7269 - val_loss: 0.1805 - val_acc: 0.7222\n",
      "Epoch 880/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1835 - acc: 0.7407 - val_loss: 0.1807 - val_acc: 0.7361\n",
      "Epoch 881/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1891 - acc: 0.7176 - val_loss: 0.1805 - val_acc: 0.7361\n",
      "Epoch 882/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1844 - acc: 0.7330 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 883/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1831 - acc: 0.7361 - val_loss: 0.1814 - val_acc: 0.7361\n",
      "Epoch 884/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1841 - acc: 0.7238 - val_loss: 0.1809 - val_acc: 0.7361\n",
      "Epoch 885/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1834 - acc: 0.7299 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 886/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1862 - acc: 0.7145 - val_loss: 0.1806 - val_acc: 0.7361\n",
      "Epoch 887/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1864 - acc: 0.7346 - val_loss: 0.1810 - val_acc: 0.7361\n",
      "Epoch 888/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1802 - acc: 0.7577 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 889/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1819 - acc: 0.7330 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 890/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1815 - acc: 0.7361 - val_loss: 0.1805 - val_acc: 0.7361\n",
      "Epoch 891/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1823 - acc: 0.7346 - val_loss: 0.1807 - val_acc: 0.7361\n",
      "Epoch 892/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1861 - acc: 0.7253 - val_loss: 0.1805 - val_acc: 0.7361\n",
      "Epoch 893/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1877 - acc: 0.7284 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 894/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1856 - acc: 0.7299 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 895/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1878 - acc: 0.7330 - val_loss: 0.1802 - val_acc: 0.7361\n",
      "Epoch 896/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1810 - acc: 0.7407 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 897/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1825 - acc: 0.7392 - val_loss: 0.1804 - val_acc: 0.7361\n",
      "Epoch 898/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2328 - acc: 0.625 - 0s 79us/step - loss: 0.1826 - acc: 0.7423 - val_loss: 0.1798 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1812 - acc: 0.7485 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 900/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1865 - acc: 0.7269 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 901/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1804 - acc: 0.7407 - val_loss: 0.1800 - val_acc: 0.7222\n",
      "Epoch 902/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1796 - acc: 0.7500 - val_loss: 0.1797 - val_acc: 0.7222\n",
      "Epoch 903/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1896 - acc: 0.7191 - val_loss: 0.1803 - val_acc: 0.7222\n",
      "Epoch 904/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1814 - acc: 0.7392 - val_loss: 0.1803 - val_acc: 0.7222\n",
      "Epoch 905/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1775 - acc: 0.7670 - val_loss: 0.1798 - val_acc: 0.7222\n",
      "Epoch 906/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1820 - acc: 0.7423 - val_loss: 0.1792 - val_acc: 0.7361\n",
      "Epoch 907/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1809 - acc: 0.7515 - val_loss: 0.1793 - val_acc: 0.7222\n",
      "Epoch 908/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1778 - acc: 0.7531 - val_loss: 0.1794 - val_acc: 0.7361\n",
      "Epoch 909/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1846 - acc: 0.7284 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 910/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1812 - acc: 0.7531 - val_loss: 0.1796 - val_acc: 0.7222\n",
      "Epoch 911/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1881 - acc: 0.7315 - val_loss: 0.1795 - val_acc: 0.7222\n",
      "Epoch 912/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1767 - acc: 0.7469 - val_loss: 0.1805 - val_acc: 0.7222\n",
      "Epoch 913/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1818 - acc: 0.7315 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 914/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1811 - acc: 0.7423 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 915/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1808 - acc: 0.7407 - val_loss: 0.1810 - val_acc: 0.7361\n",
      "Epoch 916/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1812 - acc: 0.7284 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 917/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1846 - acc: 0.7207 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 918/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1773 - acc: 0.7407 - val_loss: 0.1794 - val_acc: 0.7222\n",
      "Epoch 919/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1858 - acc: 0.7346 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 920/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1817 - acc: 0.7423 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 921/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1853 - acc: 0.7207 - val_loss: 0.1801 - val_acc: 0.7361\n",
      "Epoch 922/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1831 - acc: 0.7299 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 923/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1851 - acc: 0.7315 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 924/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1770 - acc: 0.7407 - val_loss: 0.1795 - val_acc: 0.7222\n",
      "Epoch 925/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1815 - acc: 0.7546 - val_loss: 0.1802 - val_acc: 0.7361\n",
      "Epoch 926/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1798 - acc: 0.7377 - val_loss: 0.1796 - val_acc: 0.7222\n",
      "Epoch 927/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1874 - acc: 0.7222 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 928/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1856 - acc: 0.7145 - val_loss: 0.1807 - val_acc: 0.7361\n",
      "Epoch 929/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1843 - acc: 0.7407 - val_loss: 0.1792 - val_acc: 0.7361\n",
      "Epoch 930/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1870 - acc: 0.7222 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 931/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1764 - acc: 0.7407 - val_loss: 0.1801 - val_acc: 0.7222\n",
      "Epoch 932/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1780 - acc: 0.7562 - val_loss: 0.1800 - val_acc: 0.7222\n",
      "Epoch 933/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1779 - acc: 0.7346 - val_loss: 0.1793 - val_acc: 0.7361\n",
      "Epoch 934/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1811 - acc: 0.7469 - val_loss: 0.1793 - val_acc: 0.7222\n",
      "Epoch 935/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1835 - acc: 0.7315 - val_loss: 0.1801 - val_acc: 0.7361\n",
      "Epoch 936/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1840 - acc: 0.7176 - val_loss: 0.1807 - val_acc: 0.7361\n",
      "Epoch 937/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1826 - acc: 0.7361 - val_loss: 0.1801 - val_acc: 0.7361\n",
      "Epoch 938/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1848 - acc: 0.7377 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 939/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1842 - acc: 0.7469 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 940/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1832 - acc: 0.7377 - val_loss: 0.1805 - val_acc: 0.7361\n",
      "Epoch 941/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1796 - acc: 0.7423 - val_loss: 0.1809 - val_acc: 0.7361\n",
      "Epoch 942/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1795 - acc: 0.7423 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 943/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1839 - acc: 0.7284 - val_loss: 0.1800 - val_acc: 0.7361\n",
      "Epoch 944/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1909 - acc: 0.7099 - val_loss: 0.1800 - val_acc: 0.7361\n",
      "Epoch 945/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1836 - acc: 0.7392 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 946/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1854 - acc: 0.7299 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 947/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1809 - acc: 0.7222 - val_loss: 0.1809 - val_acc: 0.7361\n",
      "Epoch 948/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1854 - acc: 0.7253 - val_loss: 0.1802 - val_acc: 0.7361\n",
      "Epoch 949/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1784 - acc: 0.7423 - val_loss: 0.1806 - val_acc: 0.7361\n",
      "Epoch 950/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1788 - acc: 0.7346 - val_loss: 0.1807 - val_acc: 0.7361\n",
      "Epoch 951/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1766 - acc: 0.7284 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 952/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1836 - acc: 0.7315 - val_loss: 0.1806 - val_acc: 0.7361\n",
      "Epoch 953/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1766 - acc: 0.7562 - val_loss: 0.1811 - val_acc: 0.7361\n",
      "Epoch 954/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1847 - acc: 0.7392 - val_loss: 0.1809 - val_acc: 0.7361\n",
      "Epoch 955/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1822 - acc: 0.7392 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 956/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1845 - acc: 0.7176 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 957/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1818 - acc: 0.7361 - val_loss: 0.1802 - val_acc: 0.7361\n",
      "Epoch 958/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1816 - acc: 0.7207 - val_loss: 0.1796 - val_acc: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1839 - acc: 0.7546 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 960/1000\n",
      "648/648 [==============================] - 0s 57us/step - loss: 0.1780 - acc: 0.7469 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 961/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1823 - acc: 0.7454 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 962/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1744 - acc: 0.7515 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 963/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1810 - acc: 0.7407 - val_loss: 0.1788 - val_acc: 0.7361\n",
      "Epoch 964/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1860 - acc: 0.7238 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 965/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1844 - acc: 0.7346 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 966/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1789 - acc: 0.7577 - val_loss: 0.1810 - val_acc: 0.7361\n",
      "Epoch 967/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1798 - acc: 0.7423 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 968/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1821 - acc: 0.7222 - val_loss: 0.1805 - val_acc: 0.7361\n",
      "Epoch 969/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1848 - acc: 0.7284 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 970/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1805 - acc: 0.7485 - val_loss: 0.1802 - val_acc: 0.7361\n",
      "Epoch 971/1000\n",
      "648/648 [==============================] - 0s 59us/step - loss: 0.1849 - acc: 0.7207 - val_loss: 0.1803 - val_acc: 0.7361\n",
      "Epoch 972/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1822 - acc: 0.7238 - val_loss: 0.1800 - val_acc: 0.7361\n",
      "Epoch 973/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1852 - acc: 0.7114 - val_loss: 0.1817 - val_acc: 0.7222\n",
      "Epoch 974/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1803 - acc: 0.7407 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 975/1000\n",
      "648/648 [==============================] - 0s 58us/step - loss: 0.1819 - acc: 0.7330 - val_loss: 0.1793 - val_acc: 0.7361\n",
      "Epoch 976/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1805 - acc: 0.7361 - val_loss: 0.1800 - val_acc: 0.7361\n",
      "Epoch 977/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1788 - acc: 0.7562 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 978/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1771 - acc: 0.7392 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 979/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1789 - acc: 0.7407 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 980/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1828 - acc: 0.7346 - val_loss: 0.1808 - val_acc: 0.7361\n",
      "Epoch 981/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1776 - acc: 0.7438 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 982/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1888 - acc: 0.7114 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 983/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1843 - acc: 0.7253 - val_loss: 0.1804 - val_acc: 0.7361\n",
      "Epoch 984/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1762 - acc: 0.7330 - val_loss: 0.1791 - val_acc: 0.7361\n",
      "Epoch 985/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1816 - acc: 0.7361 - val_loss: 0.1788 - val_acc: 0.7361\n",
      "Epoch 986/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1773 - acc: 0.7562 - val_loss: 0.1795 - val_acc: 0.7361\n",
      "Epoch 987/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1800 - acc: 0.7454 - val_loss: 0.1790 - val_acc: 0.7361\n",
      "Epoch 988/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1846 - acc: 0.7377 - val_loss: 0.1793 - val_acc: 0.7361\n",
      "Epoch 989/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1799 - acc: 0.7546 - val_loss: 0.1790 - val_acc: 0.7361\n",
      "Epoch 990/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1826 - acc: 0.7253 - val_loss: 0.1798 - val_acc: 0.7361\n",
      "Epoch 991/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1756 - acc: 0.7546 - val_loss: 0.1791 - val_acc: 0.7361\n",
      "Epoch 992/1000\n",
      "648/648 [==============================] - 0s 60us/step - loss: 0.1775 - acc: 0.7407 - val_loss: 0.1787 - val_acc: 0.7361\n",
      "Epoch 993/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1812 - acc: 0.7361 - val_loss: 0.1791 - val_acc: 0.7361\n",
      "Epoch 994/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1840 - acc: 0.7130 - val_loss: 0.1786 - val_acc: 0.7361\n",
      "Epoch 995/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1850 - acc: 0.7284 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 996/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1834 - acc: 0.7284 - val_loss: 0.1787 - val_acc: 0.7361\n",
      "Epoch 997/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1830 - acc: 0.7361 - val_loss: 0.1799 - val_acc: 0.7361\n",
      "Epoch 998/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1804 - acc: 0.7269 - val_loss: 0.1785 - val_acc: 0.7361\n",
      "Epoch 999/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1752 - acc: 0.7593 - val_loss: 0.1797 - val_acc: 0.7361\n",
      "Epoch 1000/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1797 - acc: 0.7423 - val_loss: 0.1794 - val_acc: 0.7361\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, validation_split=0.1, epochs=1000,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 30us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 73.33% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a249d4080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a249f3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(x_test)\n",
    "y_test= [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: yes</th>\n",
       "      <th>Pred: no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True:yes</th>\n",
       "      <td>105</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: no</th>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred: yes  Pred: no\n",
       "True:yes        105        25\n",
       "True: no         23        27"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                   index=['True:yes', 'True: no'],\n",
    "                   columns=['Pred: yes', 'Pred: no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2New.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
