{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LocallyConnected2D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.MinMaxScaler(feature_range=(0,1))\n",
    "#sb.set(rc={'figure.figsize':(10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['id', 'ccf', 'age', 'sex', 'painLocation', 'painExcertion', 'painResting', 'pncaden', 'chestPainType',\n",
    "        'restingBP','hyperTension', 'cholestrol', 'smoker', 'noOfCigarette' , 'smokingYears', 'bloodSugar',\n",
    "        'historyOfDiabetes', 'historyOfHA', 'restingECG', 'ekgmo', 'ekgday', 'ekgyr', 'dig',\n",
    "        'prop', 'nitr', 'pro' ,'diuretic', 'proto', 'stressTestDuration', 'stressTestSTTime', 'stressTestMet',\n",
    "        'stressTestMaxHR', 'stressTestRestingHR', 'stressTestMaxFirstBPS','stressTestMaxSecondBPS', 'dummy',\n",
    "        'stressTestRestingBP', 'exerciseAngina', 'xhypo', 'STDepressionExercise', 'STDepressionSlope',\n",
    "        'rldv5','rldv5e', 'coloredVesselsFluroscopy', 'restckm','exerckm','restef', 'restwm', 'exeref', 'exerwm',\n",
    "        'heartWallDamage', 'thalsev', 'thalpul', 'earlobe', 'cmo', 'cday', 'cyr', 'output', 'lmt',\n",
    " 'ladprox', 'laddist', 'diag', 'cxmain', 'ramus', 'om1', 'om2', 'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4',\n",
    " 'lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop=['id', 'ccf', 'painExcertion', 'painResting', 'pncaden','historyOfDiabetes', 'ekgmo', 'ekgday',\n",
    "               'ekgyr', 'dig', 'prop', 'nitr', 'pro' ,'diuretic', 'proto','stressTestMet', 'dummy', 'xhypo',\n",
    "               'rldv5','rldv5e','restckm','exerckm','restef', 'restwm', 'exeref','exerwm', 'thalsev', 'thalpul',\n",
    "               'earlobe', 'cmo', 'cday', 'cyr', 'lmt', 'ladprox', 'laddist', 'diag','cxmain', 'ramus', 'om1', 'om2',\n",
    "               'rcaprox', 'rcadist', 'lvx1', 'lvx2', 'lvx3', 'lvx4','lvf', 'cathef', 'junk', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting and Preprocessing the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleveland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedCleveland.txt', 'w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clevelandData=pd.read_csv(\"processedCleveland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "clevelandData=clevelandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hungarian.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedHungarian.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungarianData=pd.read_csv(\"processedHungarian.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "hungarianData=hungarianData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('switzerland.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedSwitzerland.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "switzerlandData=pd.read_csv(\"processedSwitzerland.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "switzerlandData=switzerlandData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long-beach-va.data.txt', 'r', errors='replace', encoding='utf-8') as fp:\n",
    "    line=fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processedLongBeach.txt','w', encoding='utf-8')as fp:\n",
    "    s=\"\"\n",
    "    for l in line:\n",
    "        s=s+l.strip()+\" \"\n",
    "        if(l.split()[-1]==\"name\"):\n",
    "            fp.write(s.strip()+\"\\n\")\n",
    "            s=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "longBeachData=pd.read_csv(\"processedLongBeach.txt\", delimiter=\" \", error_bad_lines=False, names=header)\n",
    "longBeachData=longBeachData.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[clevelandData,hungarianData,longBeachData,switzerlandData]\n",
    "data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 76 columns):\n",
      "id                          900 non-null object\n",
      "ccf                         900 non-null object\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "painExcertion               900 non-null float64\n",
      "painResting                 900 non-null float64\n",
      "pncaden                     900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfDiabetes           900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "ekgmo                       900 non-null float64\n",
      "ekgday                      900 non-null float64\n",
      "ekgyr                       900 non-null object\n",
      "dig                         900 non-null float64\n",
      "prop                        900 non-null float64\n",
      "nitr                        900 non-null object\n",
      "pro                         900 non-null object\n",
      "diuretic                    900 non-null float64\n",
      "proto                       900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMet               900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "dummy                       900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "xhypo                       900 non-null object\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "rldv5                       900 non-null object\n",
      "rldv5e                      900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "restckm                     900 non-null object\n",
      "exerckm                     900 non-null float64\n",
      "restef                      900 non-null float64\n",
      "restwm                      900 non-null float64\n",
      "exeref                      900 non-null float64\n",
      "exerwm                      900 non-null float64\n",
      "heartWallDamage             900 non-null float64\n",
      "thalsev                     900 non-null float64\n",
      "thalpul                     900 non-null float64\n",
      "earlobe                     900 non-null object\n",
      "cmo                         900 non-null float64\n",
      "cday                        900 non-null float64\n",
      "cyr                         900 non-null float64\n",
      "output                      900 non-null float64\n",
      "lmt                         900 non-null float64\n",
      "ladprox                     900 non-null float64\n",
      "laddist                     900 non-null float64\n",
      "diag                        900 non-null float64\n",
      "cxmain                      900 non-null float64\n",
      "ramus                       900 non-null float64\n",
      "om1                         900 non-null float64\n",
      "om2                         900 non-null float64\n",
      "rcaprox                     900 non-null float64\n",
      "rcadist                     900 non-null float64\n",
      "lvx1                        900 non-null float64\n",
      "lvx2                        900 non-null object\n",
      "lvx3                        900 non-null float64\n",
      "lvx4                        900 non-null object\n",
      "lvf                         900 non-null object\n",
      "cathef                      900 non-null object\n",
      "junk                        900 non-null float64\n",
      "name                        900 non-null object\n",
      "dtypes: float64(56), object(20)\n",
      "memory usage: 541.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ccf</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>painExcertion</th>\n",
       "      <th>painResting</th>\n",
       "      <th>pncaden</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>...</th>\n",
       "      <th>rcaprox</th>\n",
       "      <th>rcadist</th>\n",
       "      <th>lvx1</th>\n",
       "      <th>lvx2</th>\n",
       "      <th>lvx3</th>\n",
       "      <th>lvx4</th>\n",
       "      <th>lvf</th>\n",
       "      <th>cathef</th>\n",
       "      <th>junk</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ccf age  sex  painLocation  painExcertion  painResting  pncaden  \\\n",
       "0  1   0  63  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "1  2   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "2  3   0  67  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "3  4   0  37  1.0          -9.0           -9.0         -9.0     -9.0   \n",
       "4  6   0  41  0.0          -9.0           -9.0         -9.0     -9.0   \n",
       "\n",
       "  chestPainType restingBP  ...  rcaprox  rcadist lvx1  lvx2  lvx3  lvx4  lvf  \\\n",
       "0             1       145  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "1             4       160  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "2             4       120  ...      2.0      2.0  1.0     1   1.0     7    3   \n",
       "3             3       130  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "4             2       130  ...      1.0      1.0  1.0     1   1.0     1    1   \n",
       "\n",
       "   cathef  junk  name  \n",
       "0      -9  -9.0  name  \n",
       "1      -9  -9.0  name  \n",
       "2      -9  -9.0  name  \n",
       "3      -9  -9.0  name  \n",
       "4      -9  -9.0  name  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columnsToDrop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>chestPainType</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>smoker</th>\n",
       "      <th>noOfCigarette</th>\n",
       "      <th>smokingYears</th>\n",
       "      <th>...</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>STDepressionSlope</th>\n",
       "      <th>coloredVesselsFluroscopy</th>\n",
       "      <th>heartWallDamage</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex  painLocation chestPainType restingBP hyperTension  cholestrol  \\\n",
       "0  63  1.0          -9.0             1       145            1       233.0   \n",
       "1  67  1.0          -9.0             4       160            1       286.0   \n",
       "2  67  1.0          -9.0             4       120            1       229.0   \n",
       "3  37  1.0          -9.0             3       130            0       250.0   \n",
       "4  41  0.0          -9.0             2       130            1       204.0   \n",
       "\n",
       "  smoker  noOfCigarette  smokingYears   ...    stressTestRestingHR  \\\n",
       "0     -9           50.0          20.0   ...                   60.0   \n",
       "1     -9           40.0          40.0   ...                   64.0   \n",
       "2     -9           20.0          35.0   ...                   78.0   \n",
       "3     -9            0.0           0.0   ...                   84.0   \n",
       "4     -9            0.0           0.0   ...                   71.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  190.0                    90.0                 85.0   \n",
       "1                  160.0                    90.0                 90.0   \n",
       "2                  140.0                    80.0                 80.0   \n",
       "3                  195.0                    68.0                 78.0   \n",
       "4                  160.0                    74.0                 86.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  STDepressionSlope  \\\n",
       "0             0.0                   2.3                3.0   \n",
       "1             1.0                   1.5                2.0   \n",
       "2             1.0                   2.6                2.0   \n",
       "3             0.0                   3.5                3.0   \n",
       "4             0.0                   1.4                1.0   \n",
       "\n",
       "   coloredVesselsFluroscopy  heartWallDamage  output  \n",
       "0                         0              6.0     0.0  \n",
       "1                         3              3.0     2.0  \n",
       "2                         2              7.0     1.0  \n",
       "3                         0              3.0     0.0  \n",
       "4                         0              3.0     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 122\n",
      "Data columns (total 26 columns):\n",
      "age                         900 non-null object\n",
      "sex                         900 non-null float64\n",
      "painLocation                900 non-null float64\n",
      "chestPainType               900 non-null object\n",
      "restingBP                   900 non-null object\n",
      "hyperTension                900 non-null object\n",
      "cholestrol                  900 non-null float64\n",
      "smoker                      900 non-null object\n",
      "noOfCigarette               900 non-null float64\n",
      "smokingYears                900 non-null float64\n",
      "bloodSugar                  900 non-null float64\n",
      "historyOfHA                 900 non-null float64\n",
      "restingECG                  900 non-null float64\n",
      "stressTestDuration          900 non-null float64\n",
      "stressTestSTTime            900 non-null float64\n",
      "stressTestMaxHR             900 non-null float64\n",
      "stressTestRestingHR         900 non-null float64\n",
      "stressTestMaxFirstBPS       900 non-null float64\n",
      "stressTestMaxSecondBPS      900 non-null float64\n",
      "stressTestRestingBP         900 non-null float64\n",
      "exerciseAngina              900 non-null float64\n",
      "STDepressionExercise        900 non-null float64\n",
      "STDepressionSlope           900 non-null float64\n",
      "coloredVesselsFluroscopy    900 non-null object\n",
      "heartWallDamage             900 non-null float64\n",
      "output                      900 non-null float64\n",
      "dtypes: float64(20), object(6)\n",
      "memory usage: 189.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPainLocation(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>0):\n",
    "            if(columns[2]==1):\n",
    "                return 0\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceByMean(columns,mean):\n",
    "    if(columns[0]<1):\n",
    "        return int(mean)\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHypertension(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]>120):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCholestrol(columns):\n",
    "    if(columns[0]<=200):\n",
    "        return 0\n",
    "    elif(columns[0]<=239):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSmoking(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(int(columns[1])>0):\n",
    "            return 1\n",
    "        elif(int(columns[1])==0):\n",
    "            return 0\n",
    "        if(int(columns[2])>0):\n",
    "            return 1\n",
    "        elif(int(columns[2])==0):\n",
    "            return 0\n",
    "    return int(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDummyCategory(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRestingECG(columns):\n",
    "    if(columns[0]==2):\n",
    "        return 1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processstressTestSTTime(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processExerciseAgnia(columns):\n",
    "    if(columns[0]==-9):\n",
    "        if(columns[1]==1):\n",
    "            return 1\n",
    "        return 0\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSTDepressionSlope(columns):\n",
    "    if(columns[0]<1):\n",
    "        return -1\n",
    "    if(columns[0]==1):\n",
    "        return 1\n",
    "    if(columns[0]==2):\n",
    "        return 0\n",
    "    if(columns[0]==3):\n",
    "        return 2\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processcoloredVesselsFluroscopy(columns):\n",
    "    if(columns[0]==-9 or columns[0]==9):\n",
    "        return -1\n",
    "    return columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processHeartWallDamage(columns):\n",
    "    if(columns[0]==-9):\n",
    "        return -1\n",
    "    if(columns[0]<=3):\n",
    "        return 0\n",
    "    if(columns[0]<=6):\n",
    "        return 2\n",
    "    if(columns[0]==7):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(columns):\n",
    "    if(columns[0]>1):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age']=pd.to_numeric(data['age'])\n",
    "d=data[data.age !=-9]\n",
    "d=d[d.age != 0]\n",
    "mean=d['age'].mean()\n",
    "mean=data['age'].mean()\n",
    "data['age']=data[['age']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex']=pd.to_numeric(data['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['painLocation']=data[['painLocation','output','bloodSugar']].apply(processPainLocation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['chestPainType']=pd.to_numeric(data['chestPainType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['chestPainType'], prefix='chestPainType')\n",
    "data=data.drop('chestPainType',axis=1)\n",
    "data=data.join(dummyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingBP']=pd.to_numeric(data['restingBP'])\n",
    "d=data[data.restingBP !=-9]\n",
    "d=d[d.restingBP != 0]\n",
    "mean=d['restingBP'].mean()\n",
    "data['restingBP']=data[['restingBP']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hyperTension']=pd.to_numeric(data['hyperTension'])\n",
    "data['hyperTension']=data[['hyperTension','restingBP']].apply(processHypertension,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=pd.to_numeric(data['cholestrol'])\n",
    "d=data[data.cholestrol !=-9]\n",
    "d=d[d.cholestrol != 0]\n",
    "mean=d['cholestrol'].mean()\n",
    "data['cholestrol']=data[['cholestrol']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cholestrol']=data[['cholestrol']].apply(processCholestrol,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['cholestrol'], prefix='cholestrol')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('cholestrol',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=pd.to_numeric(data['smoker'])\n",
    "data['smoker']=data[['smoker','smokingYears','noOfCigarette']].apply(processSmoking,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smoker']=data[['smoker']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['smoker'], prefix='smoker')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('smoker',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bloodSugar']=pd.to_numeric(data['bloodSugar'])\n",
    "data['bloodSugar']=data[['bloodSugar']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.bloodSugar==40].index[0],'bloodSugar']=int(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['bloodSugar'], prefix='bloodSugar')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('bloodSugar',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['historyOfHA']=pd.to_numeric(data['historyOfHA'])\n",
    "data['historyOfHA']=data[['historyOfHA']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['historyOfHA'], prefix='historyOfHA')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('historyOfHA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['restingECG']=pd.to_numeric(data['restingECG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==-9].index[0],'restingECG']=int(0)\n",
    "data.at[data[data.restingECG==0.4].index[0],'restingECG']=int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['restingECG'], prefix='restingECG')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('restingECG',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['restingECG']=data[['restingECG']].apply(processRestingECG,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestDuration']=pd.to_numeric(data['stressTestDuration'])\n",
    "data['stressTestDuration']=data[['stressTestDuration']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestSTTime']=pd.to_numeric(data['stressTestSTTime'])\n",
    "data['stressTestSTTime']=data[['stressTestSTTime']].apply(addDummyCategory,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxHR']=pd.to_numeric(data['stressTestMaxHR'])\n",
    "d=data[data.stressTestMaxHR !=-9]\n",
    "mean=d['stressTestMaxHR'].mean()\n",
    "data['stressTestMaxHR']=data[['stressTestMaxHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxHR==8105].index[0],'stressTestMaxHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingHR']=pd.to_numeric(data['stressTestRestingHR'])\n",
    "d=data[data.stressTestRestingHR !=-9]\n",
    "mean=d['stressTestRestingHR'].mean()\n",
    "data['stressTestRestingHR']=data[['stressTestRestingHR']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingHR==1.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==37.0].index[0],'stressTestRestingHR']=int(mean)\n",
    "data.at[data[data.stressTestRestingHR==39.0].index[0],'stressTestRestingHR']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxFirstBPS']=pd.to_numeric(data['stressTestMaxFirstBPS'])\n",
    "d=data[data.stressTestMaxFirstBPS !=-9]\n",
    "mean=d['stressTestMaxFirstBPS'].mean()\n",
    "data['stressTestMaxFirstBPS']=data[['stressTestMaxFirstBPS']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestMaxSecondBPS']=pd.to_numeric(data['stressTestMaxSecondBPS'])\n",
    "d=data[data.stressTestMaxSecondBPS !=-9]\n",
    "mean=d['stressTestMaxSecondBPS'].mean()\n",
    "data['stressTestMaxSecondBPS']=data[['stressTestMaxSecondBPS']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestMaxSecondBPS==1.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==11.0].index[0],'stressTestMaxSecondBPS']=int(mean)\n",
    "data.at[data[data.stressTestMaxSecondBPS==26.0].index[0],'stressTestMaxSecondBPS']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stressTestRestingBP']=pd.to_numeric(data['stressTestRestingBP'])\n",
    "d=data[data.stressTestRestingBP !=-9]\n",
    "mean=d['stressTestRestingBP'].mean()\n",
    "data['stressTestRestingBP']=data[['stressTestRestingBP']].apply(replaceByMean,args=(mean,),axis=1)\n",
    "data.at[data[data.stressTestRestingBP==1018].index[0],'stressTestRestingBP']=int(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exerciseAngina']=pd.to_numeric(data['exerciseAngina'])\n",
    "data['exerciseAngina']=data[['exerciseAngina','painLocation']].apply(processExerciseAgnia,axis=1)\n",
    "data.at[data[data.exerciseAngina==101881].index[0],'exerciseAngina']=int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionExercise']=pd.to_numeric(data['STDepressionExercise'])\n",
    "d=data[data.STDepressionExercise !=-9]\n",
    "mean=d['STDepressionExercise'].mean()\n",
    "data['STDepressionExercise']=data[['STDepressionExercise']].apply(replaceByMean,args=(mean,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['STDepressionSlope']=pd.to_numeric(data['STDepressionSlope'])\n",
    "data['STDepressionSlope']=data[['STDepressionSlope']].apply(processSTDepressionSlope,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['STDepressionSlope'], prefix='STDepressionSlope')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('STDepressionSlope',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coloredVesselsFluroscopy']=pd.to_numeric(data['coloredVesselsFluroscopy'])\n",
    "data['coloredVesselsFluroscopy']=data[['coloredVesselsFluroscopy']].apply(processcoloredVesselsFluroscopy,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['coloredVesselsFluroscopy'], prefix='coloredVesselsFluroscopy')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('coloredVesselsFluroscopy',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heartWallDamage']=pd.to_numeric(data['heartWallDamage'])\n",
    "data['heartWallDamage']=data[['heartWallDamage']].apply(processHeartWallDamage,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyList = pd.get_dummies(data['heartWallDamage'], prefix='heartWallDamage')\n",
    "data=data.join(dummyList)\n",
    "data=data.drop('heartWallDamage',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output']=pd.to_numeric(data['output'])\n",
    "data['output']=data[['output']].apply(processOutput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOutput=pd.DataFrame(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 1 columns):\n",
      "output    900 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataOutput.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['noOfCigarette' , 'smokingYears'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['output'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>143.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   49  0.0           1.0        160             1                10.0   \n",
       "1   61  1.0           1.0        110             0                 9.0   \n",
       "2   32  1.0           1.0        118             0                18.0   \n",
       "3   70  1.0           1.0        160             1                 5.3   \n",
       "4   55  1.0           1.0        160             1                 7.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0               9.0            156.0                100.0   \n",
       "1               9.4            113.0                 47.0   \n",
       "2              -1.0            130.0                 74.0   \n",
       "3               3.0            112.0                 60.0   \n",
       "4               5.5            143.0                 96.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  220.0                   106.0                 90.0   \n",
       "1                  170.0                   100.0                 85.0   \n",
       "2                  180.0                    70.0                 70.0   \n",
       "3                  180.0                    75.0                 90.0   \n",
       "4                  200.0                   120.0                110.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             0.0                   1.0                0                0   \n",
       "1             0.0                   1.4                0                0   \n",
       "2             0.0                   0.0                0                0   \n",
       "3             1.0                   2.9                0                0   \n",
       "4             1.0                   2.0                0                1   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             1             0             0   \n",
       "1                0                1             0             0             1   \n",
       "2                0                1             0             0             1   \n",
       "3                1                0             0             0             1   \n",
       "4                0                0             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          1         0         0                0               1   \n",
       "1          1         0         0                1               0   \n",
       "2          1         0         0                0               1   \n",
       "3          0         1         0                0               1   \n",
       "4          1         0         0                0               0   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 1                0                0   \n",
       "1               0                 1                0                0   \n",
       "2               0                 1                0                0   \n",
       "3               0                 0                1                0   \n",
       "4               1                 1                0                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               1               0               0                     0   \n",
       "2               1               0               0                     1   \n",
       "3               1               0               0                     0   \n",
       "4               1               0               0                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    1                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            1                           0   \n",
       "3                            0                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           1                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   1                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   1                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  1                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop(['smoker_-1','bloodSugar_-1.0','historyOfHA_-1.0','STDepressionSlope_-1',\n",
    "#               'coloredVesselsFluroscopy_-1','heartWallDamage_-1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>painLocation</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>hyperTension</th>\n",
       "      <th>stressTestDuration</th>\n",
       "      <th>stressTestSTTime</th>\n",
       "      <th>stressTestMaxHR</th>\n",
       "      <th>stressTestRestingHR</th>\n",
       "      <th>stressTestMaxFirstBPS</th>\n",
       "      <th>stressTestMaxSecondBPS</th>\n",
       "      <th>stressTestRestingBP</th>\n",
       "      <th>exerciseAngina</th>\n",
       "      <th>STDepressionExercise</th>\n",
       "      <th>chestPainType_1</th>\n",
       "      <th>chestPainType_2</th>\n",
       "      <th>chestPainType_3</th>\n",
       "      <th>chestPainType_4</th>\n",
       "      <th>cholestrol_0</th>\n",
       "      <th>cholestrol_1</th>\n",
       "      <th>cholestrol_2</th>\n",
       "      <th>smoker_-1</th>\n",
       "      <th>smoker_0</th>\n",
       "      <th>smoker_1</th>\n",
       "      <th>bloodSugar_-1.0</th>\n",
       "      <th>bloodSugar_0.0</th>\n",
       "      <th>bloodSugar_1.0</th>\n",
       "      <th>historyOfHA_-1.0</th>\n",
       "      <th>historyOfHA_0.0</th>\n",
       "      <th>historyOfHA_1.0</th>\n",
       "      <th>restingECG_0.0</th>\n",
       "      <th>restingECG_1.0</th>\n",
       "      <th>restingECG_2.0</th>\n",
       "      <th>STDepressionSlope_-1</th>\n",
       "      <th>STDepressionSlope_0</th>\n",
       "      <th>STDepressionSlope_1</th>\n",
       "      <th>STDepressionSlope_2</th>\n",
       "      <th>coloredVesselsFluroscopy_-1</th>\n",
       "      <th>coloredVesselsFluroscopy_0</th>\n",
       "      <th>coloredVesselsFluroscopy_1</th>\n",
       "      <th>coloredVesselsFluroscopy_2</th>\n",
       "      <th>coloredVesselsFluroscopy_3</th>\n",
       "      <th>heartWallDamage_-1</th>\n",
       "      <th>heartWallDamage_0</th>\n",
       "      <th>heartWallDamage_1</th>\n",
       "      <th>heartWallDamage_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>143.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  painLocation  restingBP  hyperTension  stressTestDuration  \\\n",
       "0   49  0.0           1.0        160             1                10.0   \n",
       "1   61  1.0           1.0        110             0                 9.0   \n",
       "2   32  1.0           1.0        118             0                18.0   \n",
       "3   70  1.0           1.0        160             1                 5.3   \n",
       "4   55  1.0           1.0        160             1                 7.0   \n",
       "\n",
       "   stressTestSTTime  stressTestMaxHR  stressTestRestingHR  \\\n",
       "0               9.0            156.0                100.0   \n",
       "1               9.4            113.0                 47.0   \n",
       "2              -1.0            130.0                 74.0   \n",
       "3               3.0            112.0                 60.0   \n",
       "4               5.5            143.0                 96.0   \n",
       "\n",
       "   stressTestMaxFirstBPS  stressTestMaxSecondBPS  stressTestRestingBP  \\\n",
       "0                  220.0                   106.0                 90.0   \n",
       "1                  170.0                   100.0                 85.0   \n",
       "2                  180.0                    70.0                 70.0   \n",
       "3                  180.0                    75.0                 90.0   \n",
       "4                  200.0                   120.0                110.0   \n",
       "\n",
       "   exerciseAngina  STDepressionExercise  chestPainType_1  chestPainType_2  \\\n",
       "0             0.0                   1.0                0                0   \n",
       "1             0.0                   1.4                0                0   \n",
       "2             0.0                   0.0                0                0   \n",
       "3             1.0                   2.9                0                0   \n",
       "4             1.0                   2.0                0                1   \n",
       "\n",
       "   chestPainType_3  chestPainType_4  cholestrol_0  cholestrol_1  cholestrol_2  \\\n",
       "0                1                0             1             0             0   \n",
       "1                0                1             0             0             1   \n",
       "2                0                1             0             0             1   \n",
       "3                1                0             0             0             1   \n",
       "4                0                0             0             0             1   \n",
       "\n",
       "   smoker_-1  smoker_0  smoker_1  bloodSugar_-1.0  bloodSugar_0.0  \\\n",
       "0          1         0         0                0               1   \n",
       "1          1         0         0                1               0   \n",
       "2          1         0         0                0               1   \n",
       "3          0         1         0                0               1   \n",
       "4          1         0         0                0               0   \n",
       "\n",
       "   bloodSugar_1.0  historyOfHA_-1.0  historyOfHA_0.0  historyOfHA_1.0  \\\n",
       "0               0                 1                0                0   \n",
       "1               0                 1                0                0   \n",
       "2               0                 1                0                0   \n",
       "3               0                 0                1                0   \n",
       "4               1                 1                0                0   \n",
       "\n",
       "   restingECG_0.0  restingECG_1.0  restingECG_2.0  STDepressionSlope_-1  \\\n",
       "0               1               0               0                     0   \n",
       "1               1               0               0                     0   \n",
       "2               1               0               0                     1   \n",
       "3               1               0               0                     0   \n",
       "4               1               0               0                     0   \n",
       "\n",
       "   STDepressionSlope_0  STDepressionSlope_1  STDepressionSlope_2  \\\n",
       "0                    1                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    1                    0                    0   \n",
       "\n",
       "   coloredVesselsFluroscopy_-1  coloredVesselsFluroscopy_0  \\\n",
       "0                            1                           0   \n",
       "1                            1                           0   \n",
       "2                            1                           0   \n",
       "3                            0                           0   \n",
       "4                            1                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_1  coloredVesselsFluroscopy_2  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           1                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   coloredVesselsFluroscopy_3  heartWallDamage_-1  heartWallDamage_0  \\\n",
       "0                           0                   1                  0   \n",
       "1                           0                   1                  0   \n",
       "2                           0                   1                  0   \n",
       "3                           0                   0                  0   \n",
       "4                           0                   1                  0   \n",
       "\n",
       "   heartWallDamage_1  heartWallDamage_2  \n",
       "0                  0                  0  \n",
       "1                  0                  0  \n",
       "2                  0                  0  \n",
       "3                  1                  0  \n",
       "4                  0                  0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 46 columns):\n",
      "age                            900 non-null int64\n",
      "sex                            900 non-null float64\n",
      "painLocation                   900 non-null float64\n",
      "restingBP                      900 non-null int64\n",
      "hyperTension                   900 non-null int64\n",
      "stressTestDuration             900 non-null float64\n",
      "stressTestSTTime               900 non-null float64\n",
      "stressTestMaxHR                900 non-null float64\n",
      "stressTestRestingHR            900 non-null float64\n",
      "stressTestMaxFirstBPS          900 non-null float64\n",
      "stressTestMaxSecondBPS         900 non-null float64\n",
      "stressTestRestingBP            900 non-null float64\n",
      "exerciseAngina                 900 non-null float64\n",
      "STDepressionExercise           900 non-null float64\n",
      "chestPainType_1                900 non-null uint8\n",
      "chestPainType_2                900 non-null uint8\n",
      "chestPainType_3                900 non-null uint8\n",
      "chestPainType_4                900 non-null uint8\n",
      "cholestrol_0                   900 non-null uint8\n",
      "cholestrol_1                   900 non-null uint8\n",
      "cholestrol_2                   900 non-null uint8\n",
      "smoker_-1                      900 non-null uint8\n",
      "smoker_0                       900 non-null uint8\n",
      "smoker_1                       900 non-null uint8\n",
      "bloodSugar_-1.0                900 non-null uint8\n",
      "bloodSugar_0.0                 900 non-null uint8\n",
      "bloodSugar_1.0                 900 non-null uint8\n",
      "historyOfHA_-1.0               900 non-null uint8\n",
      "historyOfHA_0.0                900 non-null uint8\n",
      "historyOfHA_1.0                900 non-null uint8\n",
      "restingECG_0.0                 900 non-null uint8\n",
      "restingECG_1.0                 900 non-null uint8\n",
      "restingECG_2.0                 900 non-null uint8\n",
      "STDepressionSlope_-1           900 non-null uint8\n",
      "STDepressionSlope_0            900 non-null uint8\n",
      "STDepressionSlope_1            900 non-null uint8\n",
      "STDepressionSlope_2            900 non-null uint8\n",
      "coloredVesselsFluroscopy_-1    900 non-null uint8\n",
      "coloredVesselsFluroscopy_0     900 non-null uint8\n",
      "coloredVesselsFluroscopy_1     900 non-null uint8\n",
      "coloredVesselsFluroscopy_2     900 non-null uint8\n",
      "coloredVesselsFluroscopy_3     900 non-null uint8\n",
      "heartWallDamage_-1             900 non-null uint8\n",
      "heartWallDamage_0              900 non-null uint8\n",
      "heartWallDamage_1              900 non-null uint8\n",
      "heartWallDamage_2              900 non-null uint8\n",
      "dtypes: float64(11), int64(3), uint8(32)\n",
      "memory usage: 126.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_X, testingData_X, trainingData_Y, testingData_Y = train_test_split(data,\n",
    "                                                                                dataOutput,\n",
    "                                                                                test_size = 0.2,\n",
    "                                                                                random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=trainingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testingData_X.values\n",
    "\n",
    "sacler=scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=trainingData_Y.values\n",
    "y_test=testingData_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "y_train=y_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "y_test=y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstLayer=x_train.shape[1]\n",
    "secondLayer=int(x_train.shape[1]/2)\n",
    "thirdLayer=int(secondLayer/2)\n",
    "fourthLayer=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46   23   11   1\n"
     ]
    }
   ],
   "source": [
    "print(firstLayer,\" \",secondLayer,\" \",thirdLayer,\" \",fourthLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(firstLayer, input_dim=x_train.shape[1], activation='relu',\n",
    "                kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(secondLayer,activation='tanh',\n",
    "                kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0),\n",
    "               kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(fourthLayer, activation='sigmoid',kernel_initializer=glorot_uniform(seed=None),\n",
    "                bias_initializer=Constant(value=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 23)                1081      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 3,267\n",
      "Trainable params: 3,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/1000\n",
      "648/648 [==============================] - 0s 281us/step - loss: 1.7898 - acc: 0.5833 - val_loss: 1.7594 - val_acc: 0.6250\n",
      "Epoch 2/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 1.7565 - acc: 0.6173 - val_loss: 1.7176 - val_acc: 0.6250\n",
      "Epoch 3/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 1.7061 - acc: 0.6327 - val_loss: 1.6770 - val_acc: 0.6528\n",
      "Epoch 4/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 1.6645 - acc: 0.6543 - val_loss: 1.6378 - val_acc: 0.6528\n",
      "Epoch 5/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 1.6237 - acc: 0.6559 - val_loss: 1.5998 - val_acc: 0.6528\n",
      "Epoch 6/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 1.5909 - acc: 0.6651 - val_loss: 1.5622 - val_acc: 0.6528\n",
      "Epoch 7/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 1.5557 - acc: 0.6590 - val_loss: 1.5251 - val_acc: 0.6667\n",
      "Epoch 8/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 1.5198 - acc: 0.6620 - val_loss: 1.4887 - val_acc: 0.6667\n",
      "Epoch 9/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 1.4846 - acc: 0.6651 - val_loss: 1.4529 - val_acc: 0.6667\n",
      "Epoch 10/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 1.4456 - acc: 0.6744 - val_loss: 1.4176 - val_acc: 0.6667\n",
      "Epoch 11/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 1.4082 - acc: 0.6559 - val_loss: 1.3832 - val_acc: 0.6667\n",
      "Epoch 12/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 1.3771 - acc: 0.6682 - val_loss: 1.3492 - val_acc: 0.6667\n",
      "Epoch 13/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 1.3415 - acc: 0.6821 - val_loss: 1.3157 - val_acc: 0.6667\n",
      "Epoch 14/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 1.3103 - acc: 0.6651 - val_loss: 1.2825 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 1.2729 - acc: 0.6682 - val_loss: 1.2500 - val_acc: 0.6667\n",
      "Epoch 16/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 1.2441 - acc: 0.6728 - val_loss: 1.2177 - val_acc: 0.6667\n",
      "Epoch 17/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 1.2099 - acc: 0.6821 - val_loss: 1.1859 - val_acc: 0.6667\n",
      "Epoch 18/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 1.1845 - acc: 0.6775 - val_loss: 1.1547 - val_acc: 0.6667\n",
      "Epoch 19/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 1.1517 - acc: 0.6759 - val_loss: 1.1241 - val_acc: 0.6667\n",
      "Epoch 20/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 1.1220 - acc: 0.6759 - val_loss: 1.0942 - val_acc: 0.6667\n",
      "Epoch 21/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 1.0880 - acc: 0.6944 - val_loss: 1.0647 - val_acc: 0.6667\n",
      "Epoch 22/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 1.0588 - acc: 0.6883 - val_loss: 1.0357 - val_acc: 0.6806\n",
      "Epoch 23/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 1.0326 - acc: 0.6960 - val_loss: 1.0075 - val_acc: 0.6806\n",
      "Epoch 24/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 1.0094 - acc: 0.6852 - val_loss: 0.9795 - val_acc: 0.6667\n",
      "Epoch 25/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.9737 - acc: 0.6944 - val_loss: 0.9524 - val_acc: 0.6667\n",
      "Epoch 26/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.9474 - acc: 0.7022 - val_loss: 0.9254 - val_acc: 0.6667\n",
      "Epoch 27/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.9206 - acc: 0.7083 - val_loss: 0.8991 - val_acc: 0.6667\n",
      "Epoch 28/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.8953 - acc: 0.7114 - val_loss: 0.8732 - val_acc: 0.6667\n",
      "Epoch 29/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.8711 - acc: 0.7068 - val_loss: 0.8476 - val_acc: 0.6667\n",
      "Epoch 30/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.8466 - acc: 0.7006 - val_loss: 0.8229 - val_acc: 0.6667\n",
      "Epoch 31/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.8208 - acc: 0.7037 - val_loss: 0.7985 - val_acc: 0.6806\n",
      "Epoch 32/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.7959 - acc: 0.7037 - val_loss: 0.7751 - val_acc: 0.6806\n",
      "Epoch 33/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.7726 - acc: 0.7068 - val_loss: 0.7522 - val_acc: 0.6806\n",
      "Epoch 34/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.7536 - acc: 0.7037 - val_loss: 0.7298 - val_acc: 0.6806\n",
      "Epoch 35/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.7307 - acc: 0.6867 - val_loss: 0.7081 - val_acc: 0.6944\n",
      "Epoch 36/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.7084 - acc: 0.7176 - val_loss: 0.6869 - val_acc: 0.6944\n",
      "Epoch 37/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.6833 - acc: 0.7145 - val_loss: 0.6661 - val_acc: 0.6944\n",
      "Epoch 38/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.6675 - acc: 0.7160 - val_loss: 0.6457 - val_acc: 0.6944\n",
      "Epoch 39/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.6467 - acc: 0.7222 - val_loss: 0.6261 - val_acc: 0.6944\n",
      "Epoch 40/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.6298 - acc: 0.7176 - val_loss: 0.6068 - val_acc: 0.6944\n",
      "Epoch 41/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.6085 - acc: 0.7253 - val_loss: 0.5876 - val_acc: 0.6944\n",
      "Epoch 42/1000\n",
      "648/648 [==============================] - 0s 129us/step - loss: 0.5927 - acc: 0.7068 - val_loss: 0.5693 - val_acc: 0.6944\n",
      "Epoch 43/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.5711 - acc: 0.7330 - val_loss: 0.5513 - val_acc: 0.6944\n",
      "Epoch 44/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.5522 - acc: 0.7423 - val_loss: 0.5343 - val_acc: 0.6944\n",
      "Epoch 45/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.5361 - acc: 0.7130 - val_loss: 0.5177 - val_acc: 0.6944\n",
      "Epoch 46/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.5199 - acc: 0.7130 - val_loss: 0.5014 - val_acc: 0.6944\n",
      "Epoch 47/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.5028 - acc: 0.7222 - val_loss: 0.4859 - val_acc: 0.6944\n",
      "Epoch 48/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.4877 - acc: 0.7392 - val_loss: 0.4707 - val_acc: 0.6944\n",
      "Epoch 49/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.4781 - acc: 0.7083 - val_loss: 0.4559 - val_acc: 0.6944\n",
      "Epoch 50/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.4601 - acc: 0.7191 - val_loss: 0.4417 - val_acc: 0.6944\n",
      "Epoch 51/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.4439 - acc: 0.7145 - val_loss: 0.4282 - val_acc: 0.6944\n",
      "Epoch 52/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.4318 - acc: 0.7238 - val_loss: 0.4151 - val_acc: 0.6944\n",
      "Epoch 53/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.4206 - acc: 0.7269 - val_loss: 0.4025 - val_acc: 0.6944\n",
      "Epoch 54/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.4066 - acc: 0.7330 - val_loss: 0.3903 - val_acc: 0.6944\n",
      "Epoch 55/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.3914 - acc: 0.7377 - val_loss: 0.3785 - val_acc: 0.6944\n",
      "Epoch 56/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.3825 - acc: 0.7392 - val_loss: 0.3670 - val_acc: 0.6944\n",
      "Epoch 57/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.3717 - acc: 0.7500 - val_loss: 0.3560 - val_acc: 0.6944\n",
      "Epoch 58/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.3606 - acc: 0.7253 - val_loss: 0.3456 - val_acc: 0.6944\n",
      "Epoch 59/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.3469 - acc: 0.7346 - val_loss: 0.3357 - val_acc: 0.7083\n",
      "Epoch 60/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.3415 - acc: 0.7454 - val_loss: 0.3261 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.3314 - acc: 0.7330 - val_loss: 0.3171 - val_acc: 0.6944\n",
      "Epoch 62/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.3203 - acc: 0.7253 - val_loss: 0.3080 - val_acc: 0.7083\n",
      "Epoch 63/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.3152 - acc: 0.7238 - val_loss: 0.2994 - val_acc: 0.7083\n",
      "Epoch 64/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.3025 - acc: 0.7562 - val_loss: 0.2915 - val_acc: 0.7083\n",
      "Epoch 65/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.2986 - acc: 0.7407 - val_loss: 0.2840 - val_acc: 0.7083\n",
      "Epoch 66/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2913 - acc: 0.7392 - val_loss: 0.2768 - val_acc: 0.6944\n",
      "Epoch 67/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2814 - acc: 0.7392 - val_loss: 0.2697 - val_acc: 0.6944\n",
      "Epoch 68/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.2771 - acc: 0.7315 - val_loss: 0.2633 - val_acc: 0.6944\n",
      "Epoch 69/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.2724 - acc: 0.7407 - val_loss: 0.2576 - val_acc: 0.6944\n",
      "Epoch 70/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2649 - acc: 0.7330 - val_loss: 0.2524 - val_acc: 0.6944\n",
      "Epoch 71/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2608 - acc: 0.7299 - val_loss: 0.2478 - val_acc: 0.6944\n",
      "Epoch 72/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2572 - acc: 0.7176 - val_loss: 0.2437 - val_acc: 0.6944\n",
      "Epoch 73/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2533 - acc: 0.7407 - val_loss: 0.2400 - val_acc: 0.6944\n",
      "Epoch 74/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2482 - acc: 0.7407 - val_loss: 0.2365 - val_acc: 0.7083\n",
      "Epoch 75/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2486 - acc: 0.7269 - val_loss: 0.2336 - val_acc: 0.6944\n",
      "Epoch 76/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2426 - acc: 0.7299 - val_loss: 0.2309 - val_acc: 0.6944\n",
      "Epoch 77/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.2387 - acc: 0.7377 - val_loss: 0.2285 - val_acc: 0.6944\n",
      "Epoch 78/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.2372 - acc: 0.7361 - val_loss: 0.2261 - val_acc: 0.6944\n",
      "Epoch 79/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.2370 - acc: 0.7377 - val_loss: 0.2239 - val_acc: 0.6944\n",
      "Epoch 80/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.2329 - acc: 0.7222 - val_loss: 0.2218 - val_acc: 0.6944\n",
      "Epoch 81/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.2309 - acc: 0.7577 - val_loss: 0.2198 - val_acc: 0.6944\n",
      "Epoch 82/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.2279 - acc: 0.7346 - val_loss: 0.2180 - val_acc: 0.6944\n",
      "Epoch 83/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.2267 - acc: 0.7423 - val_loss: 0.2163 - val_acc: 0.6944\n",
      "Epoch 84/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2265 - acc: 0.7284 - val_loss: 0.2146 - val_acc: 0.6944\n",
      "Epoch 85/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2206 - acc: 0.7515 - val_loss: 0.2132 - val_acc: 0.6944\n",
      "Epoch 86/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2253 - acc: 0.7377 - val_loss: 0.2117 - val_acc: 0.6944\n",
      "Epoch 87/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2218 - acc: 0.7330 - val_loss: 0.2103 - val_acc: 0.6944\n",
      "Epoch 88/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2234 - acc: 0.7176 - val_loss: 0.2092 - val_acc: 0.6944\n",
      "Epoch 89/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2168 - acc: 0.7423 - val_loss: 0.2079 - val_acc: 0.6944\n",
      "Epoch 90/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2178 - acc: 0.7330 - val_loss: 0.2067 - val_acc: 0.6944\n",
      "Epoch 91/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2143 - acc: 0.7284 - val_loss: 0.2057 - val_acc: 0.6944\n",
      "Epoch 92/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2152 - acc: 0.7500 - val_loss: 0.2045 - val_acc: 0.6944\n",
      "Epoch 93/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2166 - acc: 0.7423 - val_loss: 0.2037 - val_acc: 0.6944\n",
      "Epoch 94/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2149 - acc: 0.7207 - val_loss: 0.2028 - val_acc: 0.7083\n",
      "Epoch 95/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2152 - acc: 0.7330 - val_loss: 0.2021 - val_acc: 0.6944\n",
      "Epoch 96/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.2111 - acc: 0.7284 - val_loss: 0.2012 - val_acc: 0.6944\n",
      "Epoch 97/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2106 - acc: 0.7377 - val_loss: 0.2004 - val_acc: 0.6944\n",
      "Epoch 98/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.2103 - acc: 0.7438 - val_loss: 0.1997 - val_acc: 0.6944\n",
      "Epoch 99/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.2089 - acc: 0.7346 - val_loss: 0.1992 - val_acc: 0.6944\n",
      "Epoch 100/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.2085 - acc: 0.7377 - val_loss: 0.1985 - val_acc: 0.6944\n",
      "Epoch 101/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2087 - acc: 0.7531 - val_loss: 0.1978 - val_acc: 0.6944\n",
      "Epoch 102/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2071 - acc: 0.7361 - val_loss: 0.1969 - val_acc: 0.6944\n",
      "Epoch 103/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2058 - acc: 0.7469 - val_loss: 0.1964 - val_acc: 0.6944\n",
      "Epoch 104/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2045 - acc: 0.7423 - val_loss: 0.1958 - val_acc: 0.6944\n",
      "Epoch 105/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2057 - acc: 0.7330 - val_loss: 0.1952 - val_acc: 0.6944\n",
      "Epoch 106/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2061 - acc: 0.7377 - val_loss: 0.1948 - val_acc: 0.6806\n",
      "Epoch 107/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2052 - acc: 0.7407 - val_loss: 0.1941 - val_acc: 0.6944\n",
      "Epoch 108/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2066 - acc: 0.7269 - val_loss: 0.1935 - val_acc: 0.7222\n",
      "Epoch 109/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2039 - acc: 0.7315 - val_loss: 0.1930 - val_acc: 0.7222\n",
      "Epoch 110/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2045 - acc: 0.7315 - val_loss: 0.1925 - val_acc: 0.7222\n",
      "Epoch 111/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2050 - acc: 0.7222 - val_loss: 0.1924 - val_acc: 0.6806\n",
      "Epoch 112/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.2046 - acc: 0.7361 - val_loss: 0.1920 - val_acc: 0.6806\n",
      "Epoch 113/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2081 - acc: 0.7130 - val_loss: 0.1916 - val_acc: 0.6806\n",
      "Epoch 114/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.2031 - acc: 0.7284 - val_loss: 0.1912 - val_acc: 0.6806\n",
      "Epoch 115/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.2003 - acc: 0.7454 - val_loss: 0.1907 - val_acc: 0.6944\n",
      "Epoch 116/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2047 - acc: 0.7315 - val_loss: 0.1902 - val_acc: 0.7222\n",
      "Epoch 117/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.2023 - acc: 0.7052 - val_loss: 0.1901 - val_acc: 0.6806\n",
      "Epoch 118/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1992 - acc: 0.7438 - val_loss: 0.1895 - val_acc: 0.6944\n",
      "Epoch 119/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.2018 - acc: 0.7269 - val_loss: 0.1891 - val_acc: 0.6944\n",
      "Epoch 120/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.2004 - acc: 0.7392 - val_loss: 0.1887 - val_acc: 0.6944\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 70us/step - loss: 0.1961 - acc: 0.7392 - val_loss: 0.1883 - val_acc: 0.7083\n",
      "Epoch 122/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.2005 - acc: 0.7392 - val_loss: 0.1878 - val_acc: 0.7361\n",
      "Epoch 123/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1981 - acc: 0.7377 - val_loss: 0.1872 - val_acc: 0.7500\n",
      "Epoch 124/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1993 - acc: 0.7392 - val_loss: 0.1869 - val_acc: 0.7500\n",
      "Epoch 125/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1955 - acc: 0.7377 - val_loss: 0.1865 - val_acc: 0.7500\n",
      "Epoch 126/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1947 - acc: 0.7469 - val_loss: 0.1860 - val_acc: 0.7500\n",
      "Epoch 127/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1967 - acc: 0.7469 - val_loss: 0.1858 - val_acc: 0.7500\n",
      "Epoch 128/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1976 - acc: 0.7438 - val_loss: 0.1851 - val_acc: 0.7639\n",
      "Epoch 129/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1942 - acc: 0.7407 - val_loss: 0.1846 - val_acc: 0.7639\n",
      "Epoch 130/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1968 - acc: 0.7176 - val_loss: 0.1844 - val_acc: 0.7639\n",
      "Epoch 131/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1981 - acc: 0.7315 - val_loss: 0.1842 - val_acc: 0.7639\n",
      "Epoch 132/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1985 - acc: 0.7407 - val_loss: 0.1838 - val_acc: 0.7639\n",
      "Epoch 133/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1990 - acc: 0.7330 - val_loss: 0.1837 - val_acc: 0.7639\n",
      "Epoch 134/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1979 - acc: 0.7438 - val_loss: 0.1835 - val_acc: 0.7639\n",
      "Epoch 135/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1965 - acc: 0.7423 - val_loss: 0.1831 - val_acc: 0.7639\n",
      "Epoch 136/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1929 - acc: 0.7423 - val_loss: 0.1826 - val_acc: 0.7639\n",
      "Epoch 137/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1969 - acc: 0.7284 - val_loss: 0.1825 - val_acc: 0.7639\n",
      "Epoch 138/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1938 - acc: 0.7454 - val_loss: 0.1822 - val_acc: 0.7639\n",
      "Epoch 139/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1915 - acc: 0.7562 - val_loss: 0.1818 - val_acc: 0.7639\n",
      "Epoch 140/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1945 - acc: 0.7423 - val_loss: 0.1815 - val_acc: 0.7778\n",
      "Epoch 141/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1956 - acc: 0.7546 - val_loss: 0.1811 - val_acc: 0.7778\n",
      "Epoch 142/1000\n",
      "648/648 [==============================] - 0s 164us/step - loss: 0.1937 - acc: 0.7269 - val_loss: 0.1809 - val_acc: 0.7778\n",
      "Epoch 143/1000\n",
      "648/648 [==============================] - 0s 184us/step - loss: 0.1953 - acc: 0.7299 - val_loss: 0.1806 - val_acc: 0.7778\n",
      "Epoch 144/1000\n",
      "648/648 [==============================] - 0s 158us/step - loss: 0.1894 - acc: 0.7485 - val_loss: 0.1803 - val_acc: 0.7778\n",
      "Epoch 145/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1889 - acc: 0.7639 - val_loss: 0.1798 - val_acc: 0.7778\n",
      "Epoch 146/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1938 - acc: 0.7454 - val_loss: 0.1799 - val_acc: 0.7778\n",
      "Epoch 147/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1936 - acc: 0.7485 - val_loss: 0.1796 - val_acc: 0.7778\n",
      "Epoch 148/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1925 - acc: 0.7315 - val_loss: 0.1794 - val_acc: 0.7778\n",
      "Epoch 149/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1896 - acc: 0.7361 - val_loss: 0.1793 - val_acc: 0.7778\n",
      "Epoch 150/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1945 - acc: 0.7315 - val_loss: 0.1789 - val_acc: 0.7778\n",
      "Epoch 151/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1902 - acc: 0.7577 - val_loss: 0.1788 - val_acc: 0.7778\n",
      "Epoch 152/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1882 - acc: 0.7454 - val_loss: 0.1785 - val_acc: 0.7778\n",
      "Epoch 153/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1914 - acc: 0.7423 - val_loss: 0.1781 - val_acc: 0.7778\n",
      "Epoch 154/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1944 - acc: 0.7284 - val_loss: 0.1780 - val_acc: 0.7778\n",
      "Epoch 155/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1887 - acc: 0.7515 - val_loss: 0.1778 - val_acc: 0.7778\n",
      "Epoch 156/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1915 - acc: 0.7577 - val_loss: 0.1775 - val_acc: 0.7778\n",
      "Epoch 157/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1928 - acc: 0.7593 - val_loss: 0.1774 - val_acc: 0.7778\n",
      "Epoch 158/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1878 - acc: 0.7500 - val_loss: 0.1772 - val_acc: 0.7778\n",
      "Epoch 159/1000\n",
      "648/648 [==============================] - 0s 130us/step - loss: 0.1928 - acc: 0.7207 - val_loss: 0.1771 - val_acc: 0.7778\n",
      "Epoch 160/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1929 - acc: 0.7377 - val_loss: 0.1770 - val_acc: 0.7778\n",
      "Epoch 161/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1895 - acc: 0.7377 - val_loss: 0.1767 - val_acc: 0.7778\n",
      "Epoch 162/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1904 - acc: 0.7515 - val_loss: 0.1763 - val_acc: 0.7778\n",
      "Epoch 163/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1889 - acc: 0.7531 - val_loss: 0.1761 - val_acc: 0.7778\n",
      "Epoch 164/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1929 - acc: 0.7346 - val_loss: 0.1760 - val_acc: 0.7778\n",
      "Epoch 165/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1891 - acc: 0.7562 - val_loss: 0.1757 - val_acc: 0.7778\n",
      "Epoch 166/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1890 - acc: 0.7454 - val_loss: 0.1752 - val_acc: 0.7639\n",
      "Epoch 167/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1911 - acc: 0.7346 - val_loss: 0.1752 - val_acc: 0.7639\n",
      "Epoch 168/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1914 - acc: 0.7469 - val_loss: 0.1753 - val_acc: 0.7778\n",
      "Epoch 169/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1880 - acc: 0.7377 - val_loss: 0.1748 - val_acc: 0.7778\n",
      "Epoch 170/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1884 - acc: 0.7377 - val_loss: 0.1743 - val_acc: 0.7639\n",
      "Epoch 171/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1894 - acc: 0.7577 - val_loss: 0.1742 - val_acc: 0.7639\n",
      "Epoch 172/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1880 - acc: 0.7407 - val_loss: 0.1740 - val_acc: 0.7639\n",
      "Epoch 173/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1870 - acc: 0.7485 - val_loss: 0.1738 - val_acc: 0.7639\n",
      "Epoch 174/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1863 - acc: 0.7423 - val_loss: 0.1737 - val_acc: 0.7639\n",
      "Epoch 175/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1913 - acc: 0.7485 - val_loss: 0.1738 - val_acc: 0.7639\n",
      "Epoch 176/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1852 - acc: 0.7469 - val_loss: 0.1736 - val_acc: 0.7639\n",
      "Epoch 177/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1896 - acc: 0.7207 - val_loss: 0.1733 - val_acc: 0.7639\n",
      "Epoch 178/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1880 - acc: 0.7407 - val_loss: 0.1731 - val_acc: 0.7639\n",
      "Epoch 179/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1880 - acc: 0.7500 - val_loss: 0.1729 - val_acc: 0.7639\n",
      "Epoch 180/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1856 - acc: 0.7531 - val_loss: 0.1728 - val_acc: 0.7639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1846 - acc: 0.7670 - val_loss: 0.1725 - val_acc: 0.7639\n",
      "Epoch 182/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1863 - acc: 0.7423 - val_loss: 0.1724 - val_acc: 0.7639\n",
      "Epoch 183/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1858 - acc: 0.7593 - val_loss: 0.1724 - val_acc: 0.7639\n",
      "Epoch 184/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1850 - acc: 0.7515 - val_loss: 0.1723 - val_acc: 0.7639\n",
      "Epoch 185/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1831 - acc: 0.7639 - val_loss: 0.1719 - val_acc: 0.7639\n",
      "Epoch 186/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1872 - acc: 0.7392 - val_loss: 0.1717 - val_acc: 0.7639\n",
      "Epoch 187/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1852 - acc: 0.7623 - val_loss: 0.1716 - val_acc: 0.7639\n",
      "Epoch 188/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1865 - acc: 0.7469 - val_loss: 0.1715 - val_acc: 0.7639\n",
      "Epoch 189/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1842 - acc: 0.7546 - val_loss: 0.1716 - val_acc: 0.7639\n",
      "Epoch 190/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1855 - acc: 0.7485 - val_loss: 0.1713 - val_acc: 0.7639\n",
      "Epoch 191/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1845 - acc: 0.7577 - val_loss: 0.1710 - val_acc: 0.7639\n",
      "Epoch 192/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1847 - acc: 0.7577 - val_loss: 0.1708 - val_acc: 0.7639\n",
      "Epoch 193/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1846 - acc: 0.7438 - val_loss: 0.1706 - val_acc: 0.7639\n",
      "Epoch 194/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1851 - acc: 0.7407 - val_loss: 0.1707 - val_acc: 0.7639\n",
      "Epoch 195/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1855 - acc: 0.7469 - val_loss: 0.1704 - val_acc: 0.7639\n",
      "Epoch 196/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1827 - acc: 0.7392 - val_loss: 0.1704 - val_acc: 0.7639\n",
      "Epoch 197/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1833 - acc: 0.7515 - val_loss: 0.1705 - val_acc: 0.7639\n",
      "Epoch 198/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1812 - acc: 0.7670 - val_loss: 0.1699 - val_acc: 0.7639\n",
      "Epoch 199/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1845 - acc: 0.7577 - val_loss: 0.1699 - val_acc: 0.7639\n",
      "Epoch 200/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1850 - acc: 0.7577 - val_loss: 0.1696 - val_acc: 0.7639\n",
      "Epoch 201/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1830 - acc: 0.7577 - val_loss: 0.1693 - val_acc: 0.7778\n",
      "Epoch 202/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1839 - acc: 0.7485 - val_loss: 0.1693 - val_acc: 0.7639\n",
      "Epoch 203/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1870 - acc: 0.7377 - val_loss: 0.1694 - val_acc: 0.7639\n",
      "Epoch 204/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1825 - acc: 0.7485 - val_loss: 0.1695 - val_acc: 0.7639\n",
      "Epoch 205/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1839 - acc: 0.7562 - val_loss: 0.1693 - val_acc: 0.7639\n",
      "Epoch 206/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1833 - acc: 0.7546 - val_loss: 0.1693 - val_acc: 0.7639\n",
      "Epoch 207/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1832 - acc: 0.7546 - val_loss: 0.1690 - val_acc: 0.7639\n",
      "Epoch 208/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1843 - acc: 0.7515 - val_loss: 0.1684 - val_acc: 0.7778\n",
      "Epoch 209/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1836 - acc: 0.7454 - val_loss: 0.1688 - val_acc: 0.7639\n",
      "Epoch 210/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1865 - acc: 0.7438 - val_loss: 0.1684 - val_acc: 0.7639\n",
      "Epoch 211/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1897 - acc: 0.7083 - val_loss: 0.1686 - val_acc: 0.7639\n",
      "Epoch 212/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1852 - acc: 0.7485 - val_loss: 0.1681 - val_acc: 0.7778\n",
      "Epoch 213/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1839 - acc: 0.7562 - val_loss: 0.1688 - val_acc: 0.7639\n",
      "Epoch 214/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1866 - acc: 0.7392 - val_loss: 0.1688 - val_acc: 0.7639\n",
      "Epoch 215/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1843 - acc: 0.7469 - val_loss: 0.1685 - val_acc: 0.7639\n",
      "Epoch 216/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1838 - acc: 0.7469 - val_loss: 0.1684 - val_acc: 0.7639\n",
      "Epoch 217/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1830 - acc: 0.7531 - val_loss: 0.1684 - val_acc: 0.7639\n",
      "Epoch 218/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1811 - acc: 0.7515 - val_loss: 0.1679 - val_acc: 0.7639\n",
      "Epoch 219/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1795 - acc: 0.7639 - val_loss: 0.1681 - val_acc: 0.7639\n",
      "Epoch 220/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1828 - acc: 0.7500 - val_loss: 0.1681 - val_acc: 0.7639\n",
      "Epoch 221/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1837 - acc: 0.7454 - val_loss: 0.1675 - val_acc: 0.7639\n",
      "Epoch 222/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1806 - acc: 0.7747 - val_loss: 0.1674 - val_acc: 0.7639\n",
      "Epoch 223/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1796 - acc: 0.7747 - val_loss: 0.1674 - val_acc: 0.7639\n",
      "Epoch 224/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1788 - acc: 0.7608 - val_loss: 0.1668 - val_acc: 0.7639\n",
      "Epoch 225/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1820 - acc: 0.7577 - val_loss: 0.1669 - val_acc: 0.7639\n",
      "Epoch 226/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1807 - acc: 0.7809 - val_loss: 0.1670 - val_acc: 0.7639\n",
      "Epoch 227/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1843 - acc: 0.7423 - val_loss: 0.1670 - val_acc: 0.7639\n",
      "Epoch 228/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1840 - acc: 0.7454 - val_loss: 0.1666 - val_acc: 0.7639\n",
      "Epoch 229/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1802 - acc: 0.7577 - val_loss: 0.1664 - val_acc: 0.7639\n",
      "Epoch 230/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1802 - acc: 0.7608 - val_loss: 0.1660 - val_acc: 0.7917\n",
      "Epoch 231/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1813 - acc: 0.7546 - val_loss: 0.1660 - val_acc: 0.7917\n",
      "Epoch 232/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1793 - acc: 0.7577 - val_loss: 0.1659 - val_acc: 0.7778\n",
      "Epoch 233/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1816 - acc: 0.7454 - val_loss: 0.1662 - val_acc: 0.7639\n",
      "Epoch 234/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1812 - acc: 0.7531 - val_loss: 0.1658 - val_acc: 0.7778\n",
      "Epoch 235/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1859 - acc: 0.7454 - val_loss: 0.1656 - val_acc: 0.7917\n",
      "Epoch 236/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1833 - acc: 0.7531 - val_loss: 0.1658 - val_acc: 0.7778\n",
      "Epoch 237/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1807 - acc: 0.7608 - val_loss: 0.1659 - val_acc: 0.7639\n",
      "Epoch 238/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1815 - acc: 0.7546 - val_loss: 0.1657 - val_acc: 0.7639\n",
      "Epoch 239/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1808 - acc: 0.7500 - val_loss: 0.1657 - val_acc: 0.7639\n",
      "Epoch 240/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1773 - acc: 0.7685 - val_loss: 0.1653 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1821 - acc: 0.7423 - val_loss: 0.1650 - val_acc: 0.7917\n",
      "Epoch 242/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1799 - acc: 0.7608 - val_loss: 0.1653 - val_acc: 0.7639\n",
      "Epoch 243/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1847 - acc: 0.7423 - val_loss: 0.1655 - val_acc: 0.7639\n",
      "Epoch 244/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1804 - acc: 0.7608 - val_loss: 0.1654 - val_acc: 0.7639\n",
      "Epoch 245/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1770 - acc: 0.7654 - val_loss: 0.1650 - val_acc: 0.7778\n",
      "Epoch 246/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1847 - acc: 0.7454 - val_loss: 0.1652 - val_acc: 0.7639\n",
      "Epoch 247/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1763 - acc: 0.7546 - val_loss: 0.1651 - val_acc: 0.7778\n",
      "Epoch 248/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1766 - acc: 0.7670 - val_loss: 0.1648 - val_acc: 0.7778\n",
      "Epoch 249/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1818 - acc: 0.7438 - val_loss: 0.1645 - val_acc: 0.7917\n",
      "Epoch 250/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1813 - acc: 0.7500 - val_loss: 0.1644 - val_acc: 0.7917\n",
      "Epoch 251/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1821 - acc: 0.7454 - val_loss: 0.1645 - val_acc: 0.7917\n",
      "Epoch 252/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1780 - acc: 0.7577 - val_loss: 0.1643 - val_acc: 0.7917\n",
      "Epoch 253/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1765 - acc: 0.7562 - val_loss: 0.1641 - val_acc: 0.7917\n",
      "Epoch 254/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1747 - acc: 0.7731 - val_loss: 0.1641 - val_acc: 0.7917\n",
      "Epoch 255/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1794 - acc: 0.7500 - val_loss: 0.1642 - val_acc: 0.7917\n",
      "Epoch 256/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1800 - acc: 0.7500 - val_loss: 0.1644 - val_acc: 0.7778\n",
      "Epoch 257/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1810 - acc: 0.7407 - val_loss: 0.1645 - val_acc: 0.7778\n",
      "Epoch 258/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1781 - acc: 0.7639 - val_loss: 0.1640 - val_acc: 0.7917\n",
      "Epoch 259/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1732 - acc: 0.7824 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 260/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1788 - acc: 0.7670 - val_loss: 0.1639 - val_acc: 0.7917\n",
      "Epoch 261/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1769 - acc: 0.7593 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 262/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1822 - acc: 0.7469 - val_loss: 0.1642 - val_acc: 0.7778\n",
      "Epoch 263/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1786 - acc: 0.7377 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 264/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1791 - acc: 0.7454 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 265/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1766 - acc: 0.7716 - val_loss: 0.1640 - val_acc: 0.7778\n",
      "Epoch 266/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1785 - acc: 0.7469 - val_loss: 0.1643 - val_acc: 0.7639\n",
      "Epoch 267/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1780 - acc: 0.7639 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 268/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1776 - acc: 0.7407 - val_loss: 0.1639 - val_acc: 0.7778\n",
      "Epoch 269/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1789 - acc: 0.7500 - val_loss: 0.1637 - val_acc: 0.7778\n",
      "Epoch 270/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1804 - acc: 0.7299 - val_loss: 0.1640 - val_acc: 0.7639\n",
      "Epoch 271/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1809 - acc: 0.7407 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 272/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1756 - acc: 0.7685 - val_loss: 0.1638 - val_acc: 0.7778\n",
      "Epoch 273/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1747 - acc: 0.7870 - val_loss: 0.1635 - val_acc: 0.7778\n",
      "Epoch 274/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1743 - acc: 0.7685 - val_loss: 0.1629 - val_acc: 0.7917\n",
      "Epoch 275/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1768 - acc: 0.7423 - val_loss: 0.1629 - val_acc: 0.7917\n",
      "Epoch 276/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1767 - acc: 0.7577 - val_loss: 0.1629 - val_acc: 0.7778\n",
      "Epoch 277/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1756 - acc: 0.7701 - val_loss: 0.1630 - val_acc: 0.7778\n",
      "Epoch 278/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1753 - acc: 0.7593 - val_loss: 0.1632 - val_acc: 0.7778\n",
      "Epoch 279/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1803 - acc: 0.7438 - val_loss: 0.1626 - val_acc: 0.7778\n",
      "Epoch 280/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1799 - acc: 0.7423 - val_loss: 0.1630 - val_acc: 0.7778\n",
      "Epoch 281/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1765 - acc: 0.7747 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 282/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1772 - acc: 0.7562 - val_loss: 0.1632 - val_acc: 0.7778\n",
      "Epoch 283/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1787 - acc: 0.7438 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 284/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1756 - acc: 0.7577 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 285/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1792 - acc: 0.7469 - val_loss: 0.1624 - val_acc: 0.7778\n",
      "Epoch 286/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1763 - acc: 0.7531 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 287/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1799 - acc: 0.7531 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 288/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1757 - acc: 0.7716 - val_loss: 0.1620 - val_acc: 0.7917\n",
      "Epoch 289/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1781 - acc: 0.7577 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 290/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1767 - acc: 0.7531 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 291/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1811 - acc: 0.7346 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 292/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1750 - acc: 0.7639 - val_loss: 0.1620 - val_acc: 0.7778\n",
      "Epoch 293/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1790 - acc: 0.7500 - val_loss: 0.1625 - val_acc: 0.7778\n",
      "Epoch 294/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1806 - acc: 0.7562 - val_loss: 0.1622 - val_acc: 0.7778\n",
      "Epoch 295/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1780 - acc: 0.7469 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 296/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1763 - acc: 0.7593 - val_loss: 0.1618 - val_acc: 0.7778\n",
      "Epoch 297/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1799 - acc: 0.7469 - val_loss: 0.1617 - val_acc: 0.7778\n",
      "Epoch 298/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1743 - acc: 0.7701 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 299/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1758 - acc: 0.7593 - val_loss: 0.1615 - val_acc: 0.7778\n",
      "Epoch 300/1000\n",
      "648/648 [==============================] - 0s 110us/step - loss: 0.1785 - acc: 0.7608 - val_loss: 0.1617 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1766 - acc: 0.7438 - val_loss: 0.1614 - val_acc: 0.7778\n",
      "Epoch 302/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1764 - acc: 0.7593 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 303/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1756 - acc: 0.7623 - val_loss: 0.1618 - val_acc: 0.7778\n",
      "Epoch 304/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1731 - acc: 0.7747 - val_loss: 0.1616 - val_acc: 0.7778\n",
      "Epoch 305/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1767 - acc: 0.7531 - val_loss: 0.1612 - val_acc: 0.7778\n",
      "Epoch 306/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1779 - acc: 0.7546 - val_loss: 0.1619 - val_acc: 0.7778\n",
      "Epoch 307/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1769 - acc: 0.7639 - val_loss: 0.1615 - val_acc: 0.7778\n",
      "Epoch 308/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1752 - acc: 0.7623 - val_loss: 0.1611 - val_acc: 0.7778\n",
      "Epoch 309/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1732 - acc: 0.7716 - val_loss: 0.1611 - val_acc: 0.7778\n",
      "Epoch 310/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1747 - acc: 0.7762 - val_loss: 0.1608 - val_acc: 0.8056\n",
      "Epoch 311/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1722 - acc: 0.7608 - val_loss: 0.1602 - val_acc: 0.8056\n",
      "Epoch 312/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1755 - acc: 0.7608 - val_loss: 0.1607 - val_acc: 0.8056\n",
      "Epoch 313/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1744 - acc: 0.7639 - val_loss: 0.1606 - val_acc: 0.8056\n",
      "Epoch 314/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1738 - acc: 0.7562 - val_loss: 0.1609 - val_acc: 0.7917\n",
      "Epoch 315/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1766 - acc: 0.7531 - val_loss: 0.1609 - val_acc: 0.7778\n",
      "Epoch 316/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1746 - acc: 0.7639 - val_loss: 0.1614 - val_acc: 0.7778\n",
      "Epoch 317/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1737 - acc: 0.7670 - val_loss: 0.1606 - val_acc: 0.7917\n",
      "Epoch 318/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1743 - acc: 0.7670 - val_loss: 0.1603 - val_acc: 0.8056\n",
      "Epoch 319/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1744 - acc: 0.7623 - val_loss: 0.1607 - val_acc: 0.7917\n",
      "Epoch 320/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1730 - acc: 0.7670 - val_loss: 0.1609 - val_acc: 0.7778\n",
      "Epoch 321/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1750 - acc: 0.7701 - val_loss: 0.1606 - val_acc: 0.7917\n",
      "Epoch 322/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1732 - acc: 0.7577 - val_loss: 0.1605 - val_acc: 0.7917\n",
      "Epoch 323/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1726 - acc: 0.7577 - val_loss: 0.1603 - val_acc: 0.7917\n",
      "Epoch 324/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1736 - acc: 0.7531 - val_loss: 0.1607 - val_acc: 0.7917\n",
      "Epoch 325/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1738 - acc: 0.7639 - val_loss: 0.1602 - val_acc: 0.7917\n",
      "Epoch 326/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1724 - acc: 0.7731 - val_loss: 0.1599 - val_acc: 0.8056\n",
      "Epoch 327/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1725 - acc: 0.7531 - val_loss: 0.1599 - val_acc: 0.7917\n",
      "Epoch 328/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1721 - acc: 0.7577 - val_loss: 0.1596 - val_acc: 0.8056\n",
      "Epoch 329/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1755 - acc: 0.7747 - val_loss: 0.1601 - val_acc: 0.7917\n",
      "Epoch 330/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1767 - acc: 0.7593 - val_loss: 0.1602 - val_acc: 0.7917\n",
      "Epoch 331/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1746 - acc: 0.7577 - val_loss: 0.1605 - val_acc: 0.7778\n",
      "Epoch 332/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1743 - acc: 0.7531 - val_loss: 0.1605 - val_acc: 0.7917\n",
      "Epoch 333/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1711 - acc: 0.7701 - val_loss: 0.1602 - val_acc: 0.7917\n",
      "Epoch 334/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1725 - acc: 0.7654 - val_loss: 0.1599 - val_acc: 0.7917\n",
      "Epoch 335/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1765 - acc: 0.7562 - val_loss: 0.1603 - val_acc: 0.7917\n",
      "Epoch 336/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1730 - acc: 0.7639 - val_loss: 0.1598 - val_acc: 0.7917\n",
      "Epoch 337/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1747 - acc: 0.7562 - val_loss: 0.1599 - val_acc: 0.7917\n",
      "Epoch 338/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1731 - acc: 0.7654 - val_loss: 0.1593 - val_acc: 0.8056\n",
      "Epoch 339/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1746 - acc: 0.7546 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 340/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1746 - acc: 0.7654 - val_loss: 0.1598 - val_acc: 0.7917\n",
      "Epoch 341/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1735 - acc: 0.7639 - val_loss: 0.1598 - val_acc: 0.7917\n",
      "Epoch 342/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1722 - acc: 0.7593 - val_loss: 0.1597 - val_acc: 0.7917\n",
      "Epoch 343/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1738 - acc: 0.7670 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 344/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1723 - acc: 0.7593 - val_loss: 0.1602 - val_acc: 0.7917\n",
      "Epoch 345/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1730 - acc: 0.7701 - val_loss: 0.1601 - val_acc: 0.7917\n",
      "Epoch 346/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1706 - acc: 0.7531 - val_loss: 0.1599 - val_acc: 0.7917\n",
      "Epoch 347/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1738 - acc: 0.7562 - val_loss: 0.1599 - val_acc: 0.7917\n",
      "Epoch 348/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1737 - acc: 0.7716 - val_loss: 0.1596 - val_acc: 0.7917\n",
      "Epoch 349/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1747 - acc: 0.7623 - val_loss: 0.1593 - val_acc: 0.7917\n",
      "Epoch 350/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1718 - acc: 0.7608 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 351/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1747 - acc: 0.7747 - val_loss: 0.1593 - val_acc: 0.7917\n",
      "Epoch 352/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1717 - acc: 0.7701 - val_loss: 0.1589 - val_acc: 0.7917\n",
      "Epoch 353/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1756 - acc: 0.7623 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 354/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1724 - acc: 0.7654 - val_loss: 0.1595 - val_acc: 0.7917\n",
      "Epoch 355/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1720 - acc: 0.7685 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 356/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1705 - acc: 0.7623 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 357/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1720 - acc: 0.7701 - val_loss: 0.1594 - val_acc: 0.7917\n",
      "Epoch 358/1000\n",
      "648/648 [==============================] - 0s 133us/step - loss: 0.1703 - acc: 0.7670 - val_loss: 0.1586 - val_acc: 0.8056\n",
      "Epoch 359/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1721 - acc: 0.7608 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 360/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1745 - acc: 0.7639 - val_loss: 0.1596 - val_acc: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1730 - acc: 0.7701 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 362/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1737 - acc: 0.7701 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 363/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1723 - acc: 0.7670 - val_loss: 0.1591 - val_acc: 0.7917\n",
      "Epoch 364/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1726 - acc: 0.7438 - val_loss: 0.1593 - val_acc: 0.7917\n",
      "Epoch 365/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1771 - acc: 0.7500 - val_loss: 0.1595 - val_acc: 0.7917\n",
      "Epoch 366/1000\n",
      "648/648 [==============================] - 0s 61us/step - loss: 0.1729 - acc: 0.7577 - val_loss: 0.1589 - val_acc: 0.7917\n",
      "Epoch 367/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1704 - acc: 0.7623 - val_loss: 0.1589 - val_acc: 0.7917\n",
      "Epoch 368/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1713 - acc: 0.7685 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 369/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1712 - acc: 0.7639 - val_loss: 0.1591 - val_acc: 0.7917\n",
      "Epoch 370/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1711 - acc: 0.7762 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 371/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1720 - acc: 0.7531 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 372/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1694 - acc: 0.7731 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 373/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1743 - acc: 0.7593 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 374/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1609 - acc: 0.687 - 0s 82us/step - loss: 0.1731 - acc: 0.7701 - val_loss: 0.1589 - val_acc: 0.7917\n",
      "Epoch 375/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1729 - acc: 0.7593 - val_loss: 0.1587 - val_acc: 0.7917\n",
      "Epoch 376/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1718 - acc: 0.7716 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 377/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1694 - acc: 0.7731 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 378/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1717 - acc: 0.7639 - val_loss: 0.1588 - val_acc: 0.7917\n",
      "Epoch 379/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1721 - acc: 0.7623 - val_loss: 0.1591 - val_acc: 0.7917\n",
      "Epoch 380/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1743 - acc: 0.7531 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 381/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1687 - acc: 0.7608 - val_loss: 0.1593 - val_acc: 0.7917\n",
      "Epoch 382/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1722 - acc: 0.7546 - val_loss: 0.1588 - val_acc: 0.7917\n",
      "Epoch 383/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1691 - acc: 0.7639 - val_loss: 0.1587 - val_acc: 0.7917\n",
      "Epoch 384/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1684 - acc: 0.7701 - val_loss: 0.1586 - val_acc: 0.7917\n",
      "Epoch 385/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1722 - acc: 0.7531 - val_loss: 0.1586 - val_acc: 0.7917\n",
      "Epoch 386/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1730 - acc: 0.7731 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 387/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1713 - acc: 0.7701 - val_loss: 0.1581 - val_acc: 0.7917\n",
      "Epoch 388/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1691 - acc: 0.7639 - val_loss: 0.1583 - val_acc: 0.7917\n",
      "Epoch 389/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1745 - acc: 0.7438 - val_loss: 0.1587 - val_acc: 0.7917\n",
      "Epoch 390/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1739 - acc: 0.7593 - val_loss: 0.1587 - val_acc: 0.7917\n",
      "Epoch 391/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1707 - acc: 0.7546 - val_loss: 0.1587 - val_acc: 0.7917\n",
      "Epoch 392/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1701 - acc: 0.7608 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 393/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1683 - acc: 0.7546 - val_loss: 0.1581 - val_acc: 0.7917\n",
      "Epoch 394/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1766 - acc: 0.7438 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 395/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1666 - acc: 0.7824 - val_loss: 0.1585 - val_acc: 0.7917\n",
      "Epoch 396/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1722 - acc: 0.7546 - val_loss: 0.1586 - val_acc: 0.7917\n",
      "Epoch 397/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1740 - acc: 0.7639 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 398/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1702 - acc: 0.7840 - val_loss: 0.1579 - val_acc: 0.7917\n",
      "Epoch 399/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1733 - acc: 0.7562 - val_loss: 0.1580 - val_acc: 0.7917\n",
      "Epoch 400/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1689 - acc: 0.7778 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 401/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1719 - acc: 0.7608 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 402/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1709 - acc: 0.7685 - val_loss: 0.1585 - val_acc: 0.7917\n",
      "Epoch 403/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1720 - acc: 0.7515 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 404/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1679 - acc: 0.7716 - val_loss: 0.1577 - val_acc: 0.7917\n",
      "Epoch 405/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1697 - acc: 0.7670 - val_loss: 0.1581 - val_acc: 0.7917\n",
      "Epoch 406/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1707 - acc: 0.7577 - val_loss: 0.1578 - val_acc: 0.7917\n",
      "Epoch 407/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1720 - acc: 0.7685 - val_loss: 0.1580 - val_acc: 0.7917\n",
      "Epoch 408/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1683 - acc: 0.7701 - val_loss: 0.1579 - val_acc: 0.7917\n",
      "Epoch 409/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1696 - acc: 0.7500 - val_loss: 0.1579 - val_acc: 0.7917\n",
      "Epoch 410/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1739 - acc: 0.7577 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 411/1000\n",
      "648/648 [==============================] - 0s 133us/step - loss: 0.1736 - acc: 0.7593 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 412/1000\n",
      "648/648 [==============================] - 0s 150us/step - loss: 0.1692 - acc: 0.7809 - val_loss: 0.1584 - val_acc: 0.7917\n",
      "Epoch 413/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1704 - acc: 0.7608 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 414/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1701 - acc: 0.7762 - val_loss: 0.1580 - val_acc: 0.7917\n",
      "Epoch 415/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1680 - acc: 0.7731 - val_loss: 0.1580 - val_acc: 0.7917\n",
      "Epoch 416/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1714 - acc: 0.7670 - val_loss: 0.1574 - val_acc: 0.7917\n",
      "Epoch 417/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1671 - acc: 0.7593 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 418/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1745 - acc: 0.7654 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 419/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1698 - acc: 0.7716 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 107us/step - loss: 0.1655 - acc: 0.7824 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 421/1000\n",
      "648/648 [==============================] - 0s 201us/step - loss: 0.1676 - acc: 0.7716 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 422/1000\n",
      "648/648 [==============================] - 0s 131us/step - loss: 0.1690 - acc: 0.7546 - val_loss: 0.1571 - val_acc: 0.7917\n",
      "Epoch 423/1000\n",
      "648/648 [==============================] - 0s 132us/step - loss: 0.1682 - acc: 0.7654 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 424/1000\n",
      "648/648 [==============================] - 0s 123us/step - loss: 0.1675 - acc: 0.7762 - val_loss: 0.1572 - val_acc: 0.7917\n",
      "Epoch 425/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1718 - acc: 0.7562 - val_loss: 0.1571 - val_acc: 0.7917\n",
      "Epoch 426/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1679 - acc: 0.7515 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 427/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1717 - acc: 0.7654 - val_loss: 0.1572 - val_acc: 0.7917\n",
      "Epoch 428/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1695 - acc: 0.7515 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 429/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1658 - acc: 0.7762 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 430/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1669 - acc: 0.7762 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 431/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1713 - acc: 0.7654 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 432/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1697 - acc: 0.7701 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 433/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1639 - acc: 0.7731 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 434/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1701 - acc: 0.7654 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 435/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1685 - acc: 0.7731 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 436/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1685 - acc: 0.7685 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 437/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1711 - acc: 0.7562 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 438/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1707 - acc: 0.7824 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 439/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1697 - acc: 0.7716 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 440/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1683 - acc: 0.7623 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 441/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1645 - acc: 0.7778 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 442/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1698 - acc: 0.7593 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 443/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1688 - acc: 0.7716 - val_loss: 0.1577 - val_acc: 0.7917\n",
      "Epoch 444/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1701 - acc: 0.7654 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 445/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1668 - acc: 0.7762 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 446/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1712 - acc: 0.7577 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 447/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1638 - acc: 0.7623 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 448/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1741 - acc: 0.7577 - val_loss: 0.1574 - val_acc: 0.7917\n",
      "Epoch 449/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1673 - acc: 0.7685 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 450/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1698 - acc: 0.7685 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 451/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1640 - acc: 0.7778 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 452/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1671 - acc: 0.7639 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 453/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1686 - acc: 0.7778 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 454/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1717 - acc: 0.7654 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 455/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1665 - acc: 0.7731 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 456/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1684 - acc: 0.7701 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 457/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1664 - acc: 0.7824 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 458/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1673 - acc: 0.7793 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 459/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1663 - acc: 0.7747 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 460/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1685 - acc: 0.7670 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 461/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1660 - acc: 0.7546 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 462/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1715 - acc: 0.7639 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 463/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1672 - acc: 0.7701 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 464/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1693 - acc: 0.7623 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 465/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1669 - acc: 0.7701 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 466/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1685 - acc: 0.7701 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 467/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1677 - acc: 0.7639 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 468/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1704 - acc: 0.7593 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 469/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1704 - acc: 0.7454 - val_loss: 0.1581 - val_acc: 0.7917\n",
      "Epoch 470/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1658 - acc: 0.7670 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 471/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1689 - acc: 0.7623 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 472/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1653 - acc: 0.7824 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 473/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1664 - acc: 0.7716 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 474/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1684 - acc: 0.7731 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 475/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1671 - acc: 0.7762 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 476/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1693 - acc: 0.7639 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 477/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1656 - acc: 0.7793 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 478/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1652 - acc: 0.7623 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 479/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1691 - acc: 0.7685 - val_loss: 0.1568 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "648/648 [==============================] - 0s 121us/step - loss: 0.1637 - acc: 0.7809 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 481/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1640 - acc: 0.7747 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 482/1000\n",
      "648/648 [==============================] - 0s 128us/step - loss: 0.1653 - acc: 0.7778 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 483/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1673 - acc: 0.7731 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 484/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1641 - acc: 0.7793 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 485/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1683 - acc: 0.7870 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 486/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1676 - acc: 0.7685 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 487/1000\n",
      "648/648 [==============================] - 0s 124us/step - loss: 0.1661 - acc: 0.7762 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 488/1000\n",
      "648/648 [==============================] - 0s 129us/step - loss: 0.1654 - acc: 0.7639 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 489/1000\n",
      "648/648 [==============================] - 0s 118us/step - loss: 0.1708 - acc: 0.7670 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 490/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1677 - acc: 0.7623 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 491/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1647 - acc: 0.7701 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 492/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1639 - acc: 0.7886 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 493/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1665 - acc: 0.7747 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 494/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1663 - acc: 0.7716 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 495/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1646 - acc: 0.7824 - val_loss: 0.1556 - val_acc: 0.7639\n",
      "Epoch 496/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1662 - acc: 0.7870 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 497/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1679 - acc: 0.7778 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 498/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1619 - acc: 0.7793 - val_loss: 0.1553 - val_acc: 0.7639\n",
      "Epoch 499/1000\n",
      "648/648 [==============================] - 0s 134us/step - loss: 0.1678 - acc: 0.7670 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 500/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1624 - acc: 0.7747 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 501/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1669 - acc: 0.7608 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 502/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1665 - acc: 0.7608 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 503/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1644 - acc: 0.7670 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 504/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1654 - acc: 0.7716 - val_loss: 0.1553 - val_acc: 0.7639\n",
      "Epoch 505/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1640 - acc: 0.7731 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 506/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1648 - acc: 0.7593 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 507/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1635 - acc: 0.7716 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 508/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1641 - acc: 0.7809 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 509/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1658 - acc: 0.7701 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 510/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1648 - acc: 0.7701 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 511/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1704 - acc: 0.7654 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 512/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1719 - acc: 0.7608 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 513/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1667 - acc: 0.7809 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 514/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1666 - acc: 0.7886 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 515/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1665 - acc: 0.7639 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 516/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1628 - acc: 0.7747 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 517/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1614 - acc: 0.7747 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 518/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1639 - acc: 0.7762 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 519/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1623 - acc: 0.7809 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 520/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1660 - acc: 0.7716 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 521/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1670 - acc: 0.7762 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 522/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1703 - acc: 0.7747 - val_loss: 0.1577 - val_acc: 0.7778\n",
      "Epoch 523/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1624 - acc: 0.7731 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 524/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1636 - acc: 0.7793 - val_loss: 0.1557 - val_acc: 0.7639\n",
      "Epoch 525/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1625 - acc: 0.7886 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 526/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1673 - acc: 0.7685 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 527/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1681 - acc: 0.7731 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 528/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1692 - acc: 0.7809 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 529/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1672 - acc: 0.7778 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 530/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1621 - acc: 0.7685 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 531/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1635 - acc: 0.7701 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 532/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1669 - acc: 0.7716 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 533/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1608 - acc: 0.7901 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 534/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1662 - acc: 0.7778 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 535/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1658 - acc: 0.7809 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 536/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1642 - acc: 0.7701 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 537/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1665 - acc: 0.7562 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 538/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1684 - acc: 0.7670 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 539/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 65us/step - loss: 0.1628 - acc: 0.7639 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 540/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1645 - acc: 0.7886 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 541/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1673 - acc: 0.7716 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 542/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1641 - acc: 0.7793 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 543/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1611 - acc: 0.7762 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 544/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1650 - acc: 0.7701 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 545/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1640 - acc: 0.7855 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 546/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1616 - acc: 0.7747 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 547/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1626 - acc: 0.7870 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 548/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1617 - acc: 0.7917 - val_loss: 0.1550 - val_acc: 0.7639\n",
      "Epoch 549/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1650 - acc: 0.7731 - val_loss: 0.1551 - val_acc: 0.7639\n",
      "Epoch 550/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1641 - acc: 0.7855 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 551/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1649 - acc: 0.7840 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 552/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1641 - acc: 0.7809 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 553/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1679 - acc: 0.7731 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 554/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1644 - acc: 0.7654 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 555/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1664 - acc: 0.7855 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 556/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1641 - acc: 0.7608 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 557/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1620 - acc: 0.7793 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 558/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1662 - acc: 0.7778 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 559/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1633 - acc: 0.7747 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 560/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1649 - acc: 0.7685 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 561/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1649 - acc: 0.7762 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 562/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1628 - acc: 0.7762 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 563/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1633 - acc: 0.7701 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 564/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1630 - acc: 0.7824 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 565/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1649 - acc: 0.7809 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 566/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1648 - acc: 0.7870 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 567/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1630 - acc: 0.7701 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 568/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1652 - acc: 0.7778 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 569/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1630 - acc: 0.7886 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 570/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1638 - acc: 0.7778 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 571/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1617 - acc: 0.7747 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 572/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1613 - acc: 0.7824 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 573/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1623 - acc: 0.7809 - val_loss: 0.1551 - val_acc: 0.7639\n",
      "Epoch 574/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1686 - acc: 0.7824 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 575/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1646 - acc: 0.7809 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 576/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1669 - acc: 0.7701 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 577/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1619 - acc: 0.7762 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 578/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1641 - acc: 0.7809 - val_loss: 0.1563 - val_acc: 0.7778\n",
      "Epoch 579/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1629 - acc: 0.7824 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 580/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1660 - acc: 0.7716 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 581/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1620 - acc: 0.7886 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 582/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1609 - acc: 0.7932 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 583/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1631 - acc: 0.7747 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 584/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1623 - acc: 0.7747 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 585/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1626 - acc: 0.7824 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 586/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1622 - acc: 0.7762 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 587/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1616 - acc: 0.7809 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 588/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1641 - acc: 0.7701 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 589/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1673 - acc: 0.7623 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 590/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1600 - acc: 0.7901 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 591/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1615 - acc: 0.7948 - val_loss: 0.1555 - val_acc: 0.7639\n",
      "Epoch 592/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1601 - acc: 0.7963 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 593/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1587 - acc: 0.7963 - val_loss: 0.1543 - val_acc: 0.7778\n",
      "Epoch 594/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1616 - acc: 0.7840 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 595/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1642 - acc: 0.7809 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 596/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1628 - acc: 0.7886 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 597/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1635 - acc: 0.7809 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 598/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1619 - acc: 0.7747 - val_loss: 0.1553 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1631 - acc: 0.7886 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 600/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1620 - acc: 0.7855 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 601/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1625 - acc: 0.7901 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 602/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1617 - acc: 0.7886 - val_loss: 0.1543 - val_acc: 0.7778\n",
      "Epoch 603/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1623 - acc: 0.7778 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 604/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1588 - acc: 0.7870 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 605/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1617 - acc: 0.7809 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 606/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1609 - acc: 0.7824 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 607/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1602 - acc: 0.7731 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 608/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1620 - acc: 0.7639 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 609/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1634 - acc: 0.7840 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 610/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1620 - acc: 0.7886 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 611/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1626 - acc: 0.7778 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 612/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1628 - acc: 0.7778 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 613/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1631 - acc: 0.7824 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 614/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1644 - acc: 0.7793 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 615/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1618 - acc: 0.7824 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 616/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1590 - acc: 0.7809 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 617/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1603 - acc: 0.7870 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 618/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1627 - acc: 0.7639 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 619/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1618 - acc: 0.7855 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 620/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1631 - acc: 0.7716 - val_loss: 0.1540 - val_acc: 0.7778\n",
      "Epoch 621/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1663 - acc: 0.7701 - val_loss: 0.1542 - val_acc: 0.7917\n",
      "Epoch 622/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1616 - acc: 0.7747 - val_loss: 0.1540 - val_acc: 0.7778\n",
      "Epoch 623/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1597 - acc: 0.7901 - val_loss: 0.1540 - val_acc: 0.7778\n",
      "Epoch 624/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1628 - acc: 0.7809 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 625/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1640 - acc: 0.7886 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 626/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1622 - acc: 0.7716 - val_loss: 0.1542 - val_acc: 0.7917\n",
      "Epoch 627/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1604 - acc: 0.7901 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 628/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1601 - acc: 0.7994 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 629/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1577 - acc: 0.8025 - val_loss: 0.1542 - val_acc: 0.7917\n",
      "Epoch 630/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1630 - acc: 0.7840 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 631/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1625 - acc: 0.7778 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 632/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1623 - acc: 0.7623 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 633/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1642 - acc: 0.7840 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 634/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1616 - acc: 0.7824 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 635/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1597 - acc: 0.7809 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 636/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1576 - acc: 0.7855 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 637/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1609 - acc: 0.7731 - val_loss: 0.1539 - val_acc: 0.7917\n",
      "Epoch 638/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1600 - acc: 0.7793 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 639/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1581 - acc: 0.7793 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 640/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1587 - acc: 0.7886 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 641/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1616 - acc: 0.7917 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 642/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1596 - acc: 0.7747 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 643/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1621 - acc: 0.7762 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 644/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1652 - acc: 0.7793 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 645/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1620 - acc: 0.7855 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 646/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1619 - acc: 0.7731 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 647/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1623 - acc: 0.7762 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 648/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1642 - acc: 0.7778 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 649/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1599 - acc: 0.7840 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 650/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1617 - acc: 0.8040 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 651/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1618 - acc: 0.7809 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 652/1000\n",
      "648/648 [==============================] - 0s 158us/step - loss: 0.1587 - acc: 0.7886 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 653/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1622 - acc: 0.7855 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 654/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1590 - acc: 0.7855 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 655/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1589 - acc: 0.7824 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 656/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1601 - acc: 0.7901 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 657/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1601 - acc: 0.7716 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 658/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1609 - acc: 0.7793 - val_loss: 0.1545 - val_acc: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 659/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1621 - acc: 0.7747 - val_loss: 0.1539 - val_acc: 0.7917\n",
      "Epoch 660/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1606 - acc: 0.7762 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 661/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1628 - acc: 0.7932 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 662/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1594 - acc: 0.7963 - val_loss: 0.1540 - val_acc: 0.7917\n",
      "Epoch 663/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1610 - acc: 0.7855 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 664/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1622 - acc: 0.7731 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 665/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1594 - acc: 0.7809 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 666/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1586 - acc: 0.7932 - val_loss: 0.1539 - val_acc: 0.7917\n",
      "Epoch 667/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1625 - acc: 0.7701 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 668/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1599 - acc: 0.7824 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 669/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1579 - acc: 0.7932 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 670/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1624 - acc: 0.7840 - val_loss: 0.1540 - val_acc: 0.7917\n",
      "Epoch 671/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1558 - acc: 0.7994 - val_loss: 0.1534 - val_acc: 0.7778\n",
      "Epoch 672/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1637 - acc: 0.7701 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 673/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1587 - acc: 0.7948 - val_loss: 0.1535 - val_acc: 0.7778\n",
      "Epoch 674/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1642 - acc: 0.7731 - val_loss: 0.1537 - val_acc: 0.7917\n",
      "Epoch 675/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1579 - acc: 0.7855 - val_loss: 0.1537 - val_acc: 0.7917\n",
      "Epoch 676/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1565 - acc: 0.7994 - val_loss: 0.1538 - val_acc: 0.7917\n",
      "Epoch 677/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1588 - acc: 0.7840 - val_loss: 0.1536 - val_acc: 0.7917\n",
      "Epoch 678/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1623 - acc: 0.7901 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 679/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1606 - acc: 0.7855 - val_loss: 0.1542 - val_acc: 0.7917\n",
      "Epoch 680/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1599 - acc: 0.7824 - val_loss: 0.1539 - val_acc: 0.7917\n",
      "Epoch 681/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1582 - acc: 0.7901 - val_loss: 0.1535 - val_acc: 0.7917\n",
      "Epoch 682/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1619 - acc: 0.7793 - val_loss: 0.1535 - val_acc: 0.7917\n",
      "Epoch 683/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1640 - acc: 0.7762 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 684/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1588 - acc: 0.8009 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 685/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1618 - acc: 0.7685 - val_loss: 0.1539 - val_acc: 0.7917\n",
      "Epoch 686/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1604 - acc: 0.7824 - val_loss: 0.1543 - val_acc: 0.7917\n",
      "Epoch 687/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1589 - acc: 0.7886 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 688/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1603 - acc: 0.7932 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 689/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1555 - acc: 0.7870 - val_loss: 0.1541 - val_acc: 0.7917\n",
      "Epoch 690/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1601 - acc: 0.7793 - val_loss: 0.1542 - val_acc: 0.7917\n",
      "Epoch 691/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1607 - acc: 0.7793 - val_loss: 0.1540 - val_acc: 0.7917\n",
      "Epoch 692/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1572 - acc: 0.7948 - val_loss: 0.1540 - val_acc: 0.7917\n",
      "Epoch 693/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1586 - acc: 0.7670 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 694/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1606 - acc: 0.7716 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 695/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1577 - acc: 0.7932 - val_loss: 0.1544 - val_acc: 0.7917\n",
      "Epoch 696/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1552 - acc: 0.8025 - val_loss: 0.1547 - val_acc: 0.7917\n",
      "Epoch 697/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1579 - acc: 0.7855 - val_loss: 0.1545 - val_acc: 0.7917\n",
      "Epoch 698/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1584 - acc: 0.7824 - val_loss: 0.1541 - val_acc: 0.7778\n",
      "Epoch 699/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1572 - acc: 0.7886 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 700/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1587 - acc: 0.7793 - val_loss: 0.1549 - val_acc: 0.7917\n",
      "Epoch 701/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1610 - acc: 0.7762 - val_loss: 0.1550 - val_acc: 0.7917\n",
      "Epoch 702/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1555 - acc: 0.7963 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 703/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1576 - acc: 0.7901 - val_loss: 0.1551 - val_acc: 0.7917\n",
      "Epoch 704/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1602 - acc: 0.7809 - val_loss: 0.1543 - val_acc: 0.7778\n",
      "Epoch 705/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1584 - acc: 0.7870 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 706/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1617 - acc: 0.7870 - val_loss: 0.1551 - val_acc: 0.7917\n",
      "Epoch 707/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1569 - acc: 0.7901 - val_loss: 0.1550 - val_acc: 0.7917\n",
      "Epoch 708/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1611 - acc: 0.7778 - val_loss: 0.1550 - val_acc: 0.7917\n",
      "Epoch 709/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1584 - acc: 0.7840 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 710/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1593 - acc: 0.7855 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 711/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1567 - acc: 0.7978 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 712/1000\n",
      "648/648 [==============================] - 0s 109us/step - loss: 0.1589 - acc: 0.7809 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 713/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1587 - acc: 0.7963 - val_loss: 0.1547 - val_acc: 0.7778\n",
      "Epoch 714/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1567 - acc: 0.7917 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 715/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1569 - acc: 0.7948 - val_loss: 0.1544 - val_acc: 0.7778\n",
      "Epoch 716/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1589 - acc: 0.7901 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 717/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1614 - acc: 0.7747 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 718/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1565 - acc: 0.7948 - val_loss: 0.1547 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1570 - acc: 0.7901 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 720/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1623 - acc: 0.7855 - val_loss: 0.1541 - val_acc: 0.7778\n",
      "Epoch 721/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1579 - acc: 0.7840 - val_loss: 0.1548 - val_acc: 0.7917\n",
      "Epoch 722/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1563 - acc: 0.7901 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 723/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1628 - acc: 0.7901 - val_loss: 0.1552 - val_acc: 0.7917\n",
      "Epoch 724/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1616 - acc: 0.7747 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 725/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1574 - acc: 0.7948 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 726/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1627 - acc: 0.7855 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 727/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1560 - acc: 0.7917 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 728/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1584 - acc: 0.7994 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 729/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1564 - acc: 0.7901 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 730/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1591 - acc: 0.7809 - val_loss: 0.1544 - val_acc: 0.7778\n",
      "Epoch 731/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1574 - acc: 0.8025 - val_loss: 0.1546 - val_acc: 0.7917\n",
      "Epoch 732/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1601 - acc: 0.7917 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 733/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1578 - acc: 0.7963 - val_loss: 0.1549 - val_acc: 0.7917\n",
      "Epoch 734/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1578 - acc: 0.7778 - val_loss: 0.1544 - val_acc: 0.7778\n",
      "Epoch 735/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1574 - acc: 0.7917 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 736/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1578 - acc: 0.7978 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 737/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1614 - acc: 0.7948 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 738/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1601 - acc: 0.7855 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 739/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1560 - acc: 0.7870 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 740/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1620 - acc: 0.7809 - val_loss: 0.1551 - val_acc: 0.7639\n",
      "Epoch 741/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1586 - acc: 0.8009 - val_loss: 0.1546 - val_acc: 0.7639\n",
      "Epoch 742/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1581 - acc: 0.7824 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 743/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1616 - acc: 0.7963 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 744/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1546 - acc: 0.8071 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 745/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1576 - acc: 0.7886 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 746/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1562 - acc: 0.7809 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 747/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1579 - acc: 0.7917 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 748/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1591 - acc: 0.7762 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 749/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1577 - acc: 0.7870 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 750/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1545 - acc: 0.7978 - val_loss: 0.1542 - val_acc: 0.7778\n",
      "Epoch 751/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1627 - acc: 0.7855 - val_loss: 0.1547 - val_acc: 0.7778\n",
      "Epoch 752/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1615 - acc: 0.7870 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 753/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1575 - acc: 0.7917 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 754/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1572 - acc: 0.7886 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 755/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1585 - acc: 0.7901 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 756/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1604 - acc: 0.7963 - val_loss: 0.1547 - val_acc: 0.7778\n",
      "Epoch 757/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1571 - acc: 0.7917 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 758/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1556 - acc: 0.7840 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 759/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1593 - acc: 0.7886 - val_loss: 0.1552 - val_acc: 0.7639\n",
      "Epoch 760/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1589 - acc: 0.7840 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 761/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1614 - acc: 0.7793 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 762/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1562 - acc: 0.7917 - val_loss: 0.1550 - val_acc: 0.7917\n",
      "Epoch 763/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1601 - acc: 0.7917 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 764/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1588 - acc: 0.7901 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 765/1000\n",
      "648/648 [==============================] - 0s 120us/step - loss: 0.1579 - acc: 0.7932 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 766/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1580 - acc: 0.7886 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 767/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1592 - acc: 0.7870 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 768/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1580 - acc: 0.7932 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 769/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1596 - acc: 0.7747 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 770/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1588 - acc: 0.7948 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 771/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1583 - acc: 0.8056 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 772/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1577 - acc: 0.8009 - val_loss: 0.1547 - val_acc: 0.7778\n",
      "Epoch 773/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1568 - acc: 0.7932 - val_loss: 0.1542 - val_acc: 0.7778\n",
      "Epoch 774/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1584 - acc: 0.7901 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 775/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1573 - acc: 0.7917 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 776/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1562 - acc: 0.7978 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 777/1000\n",
      "648/648 [==============================] - 0s 114us/step - loss: 0.1599 - acc: 0.7886 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 778/1000\n",
      "648/648 [==============================] - 0s 113us/step - loss: 0.1557 - acc: 0.7917 - val_loss: 0.1548 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1590 - acc: 0.7886 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 780/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1615 - acc: 0.7886 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 781/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1554 - acc: 0.8040 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 782/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1567 - acc: 0.8102 - val_loss: 0.1543 - val_acc: 0.7639\n",
      "Epoch 783/1000\n",
      "648/648 [==============================] - 0s 97us/step - loss: 0.1596 - acc: 0.7886 - val_loss: 0.1549 - val_acc: 0.7778\n",
      "Epoch 784/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1576 - acc: 0.7932 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 785/1000\n",
      "648/648 [==============================] - 0s 111us/step - loss: 0.1539 - acc: 0.7994 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 786/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1515 - acc: 0.8009 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 787/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1601 - acc: 0.7870 - val_loss: 0.1543 - val_acc: 0.7639\n",
      "Epoch 788/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1581 - acc: 0.7978 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 789/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1564 - acc: 0.7978 - val_loss: 0.1542 - val_acc: 0.7778\n",
      "Epoch 790/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1583 - acc: 0.7917 - val_loss: 0.1544 - val_acc: 0.7778\n",
      "Epoch 791/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1578 - acc: 0.7948 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 792/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1539 - acc: 0.7886 - val_loss: 0.1545 - val_acc: 0.7778\n",
      "Epoch 793/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1559 - acc: 0.7901 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 794/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1588 - acc: 0.7932 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 795/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1569 - acc: 0.7901 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 796/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1567 - acc: 0.7870 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 797/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1568 - acc: 0.8009 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 798/1000\n",
      "648/648 [==============================] - 0s 91us/step - loss: 0.1566 - acc: 0.7994 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 799/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1559 - acc: 0.7994 - val_loss: 0.1546 - val_acc: 0.7778\n",
      "Epoch 800/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1564 - acc: 0.7840 - val_loss: 0.1544 - val_acc: 0.7778\n",
      "Epoch 801/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1568 - acc: 0.7932 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 802/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1583 - acc: 0.8056 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 803/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1562 - acc: 0.8056 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 804/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1563 - acc: 0.7778 - val_loss: 0.1550 - val_acc: 0.7778\n",
      "Epoch 805/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1533 - acc: 0.7870 - val_loss: 0.1555 - val_acc: 0.7778\n",
      "Epoch 806/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1542 - acc: 0.7963 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 807/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1557 - acc: 0.7932 - val_loss: 0.1558 - val_acc: 0.7778\n",
      "Epoch 808/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1581 - acc: 0.7948 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 809/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1566 - acc: 0.7901 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 810/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1566 - acc: 0.7901 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 811/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1537 - acc: 0.7978 - val_loss: 0.1546 - val_acc: 0.7639\n",
      "Epoch 812/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1556 - acc: 0.7978 - val_loss: 0.1540 - val_acc: 0.7639\n",
      "Epoch 813/1000\n",
      "648/648 [==============================] - 0s 127us/step - loss: 0.1583 - acc: 0.7809 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 814/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1564 - acc: 0.8071 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 815/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1566 - acc: 0.7932 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 816/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1557 - acc: 0.8071 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 817/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1533 - acc: 0.8009 - val_loss: 0.1548 - val_acc: 0.7778\n",
      "Epoch 818/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1548 - acc: 0.7948 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 819/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1581 - acc: 0.7963 - val_loss: 0.1552 - val_acc: 0.7778\n",
      "Epoch 820/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1605 - acc: 0.7948 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 821/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1566 - acc: 0.7978 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 822/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1576 - acc: 0.7917 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 823/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1548 - acc: 0.8009 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 824/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1554 - acc: 0.7870 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 825/1000\n",
      "648/648 [==============================] - 0s 88us/step - loss: 0.1567 - acc: 0.7840 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 826/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1547 - acc: 0.7932 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 827/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1559 - acc: 0.8071 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 828/1000\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1556 - acc: 0.796 - 0s 100us/step - loss: 0.1543 - acc: 0.7948 - val_loss: 0.1551 - val_acc: 0.7778\n",
      "Epoch 829/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1533 - acc: 0.8102 - val_loss: 0.1548 - val_acc: 0.7639\n",
      "Epoch 830/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1601 - acc: 0.7886 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 831/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1542 - acc: 0.7978 - val_loss: 0.1566 - val_acc: 0.7639\n",
      "Epoch 832/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1562 - acc: 0.7855 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 833/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1573 - acc: 0.7917 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 834/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1563 - acc: 0.7932 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 835/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1546 - acc: 0.8056 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 836/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1589 - acc: 0.7963 - val_loss: 0.1571 - val_acc: 0.7917\n",
      "Epoch 837/1000\n",
      "648/648 [==============================] - 0s 105us/step - loss: 0.1546 - acc: 0.8133 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 94us/step - loss: 0.1548 - acc: 0.7963 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 839/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1536 - acc: 0.8071 - val_loss: 0.1561 - val_acc: 0.7778\n",
      "Epoch 840/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1576 - acc: 0.7994 - val_loss: 0.1564 - val_acc: 0.7917\n",
      "Epoch 841/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1542 - acc: 0.7963 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 842/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1546 - acc: 0.7994 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 843/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1549 - acc: 0.8117 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 844/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1550 - acc: 0.8009 - val_loss: 0.1559 - val_acc: 0.7778\n",
      "Epoch 845/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1531 - acc: 0.7994 - val_loss: 0.1550 - val_acc: 0.7639\n",
      "Epoch 846/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1536 - acc: 0.8056 - val_loss: 0.1553 - val_acc: 0.7778\n",
      "Epoch 847/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1551 - acc: 0.8025 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 848/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1578 - acc: 0.7870 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 849/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1550 - acc: 0.7994 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 850/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1529 - acc: 0.8056 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 851/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1541 - acc: 0.7963 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 852/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1544 - acc: 0.7870 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 853/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1557 - acc: 0.7917 - val_loss: 0.1554 - val_acc: 0.7778\n",
      "Epoch 854/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1577 - acc: 0.7994 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 855/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1530 - acc: 0.8117 - val_loss: 0.1562 - val_acc: 0.7778\n",
      "Epoch 856/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1541 - acc: 0.8086 - val_loss: 0.1557 - val_acc: 0.7778\n",
      "Epoch 857/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1554 - acc: 0.7978 - val_loss: 0.1560 - val_acc: 0.7778\n",
      "Epoch 858/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1543 - acc: 0.8025 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 859/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1545 - acc: 0.8040 - val_loss: 0.1556 - val_acc: 0.7778\n",
      "Epoch 860/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1542 - acc: 0.7978 - val_loss: 0.1561 - val_acc: 0.7639\n",
      "Epoch 861/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1568 - acc: 0.8056 - val_loss: 0.1560 - val_acc: 0.7639\n",
      "Epoch 862/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1567 - acc: 0.8040 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 863/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1550 - acc: 0.8009 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 864/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1519 - acc: 0.8133 - val_loss: 0.1564 - val_acc: 0.7778\n",
      "Epoch 865/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1525 - acc: 0.8056 - val_loss: 0.1562 - val_acc: 0.7639\n",
      "Epoch 866/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1533 - acc: 0.8071 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 867/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1530 - acc: 0.8056 - val_loss: 0.1563 - val_acc: 0.7639\n",
      "Epoch 868/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1562 - acc: 0.7932 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 869/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1547 - acc: 0.8025 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 870/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1532 - acc: 0.7978 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 871/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1538 - acc: 0.8025 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 872/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1527 - acc: 0.7963 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 873/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1504 - acc: 0.7963 - val_loss: 0.1562 - val_acc: 0.7639\n",
      "Epoch 874/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1504 - acc: 0.7948 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 875/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1556 - acc: 0.7994 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 876/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1574 - acc: 0.7932 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 877/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1542 - acc: 0.7963 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 878/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1563 - acc: 0.7963 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 879/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1525 - acc: 0.7994 - val_loss: 0.1567 - val_acc: 0.7917\n",
      "Epoch 880/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1543 - acc: 0.8009 - val_loss: 0.1568 - val_acc: 0.7917\n",
      "Epoch 881/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1519 - acc: 0.7932 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 882/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1550 - acc: 0.7994 - val_loss: 0.1567 - val_acc: 0.7778\n",
      "Epoch 883/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1550 - acc: 0.7963 - val_loss: 0.1570 - val_acc: 0.7917\n",
      "Epoch 884/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1580 - acc: 0.7870 - val_loss: 0.1569 - val_acc: 0.7917\n",
      "Epoch 885/1000\n",
      "648/648 [==============================] - 0s 145us/step - loss: 0.1514 - acc: 0.8040 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 886/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1550 - acc: 0.7978 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 887/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1510 - acc: 0.7994 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 888/1000\n",
      "648/648 [==============================] - 0s 78us/step - loss: 0.1550 - acc: 0.7963 - val_loss: 0.1568 - val_acc: 0.7917\n",
      "Epoch 889/1000\n",
      "648/648 [==============================] - 0s 73us/step - loss: 0.1531 - acc: 0.7994 - val_loss: 0.1568 - val_acc: 0.7917\n",
      "Epoch 890/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1557 - acc: 0.8040 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 891/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1526 - acc: 0.7901 - val_loss: 0.1575 - val_acc: 0.7778\n",
      "Epoch 892/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1526 - acc: 0.7978 - val_loss: 0.1575 - val_acc: 0.7778\n",
      "Epoch 893/1000\n",
      "648/648 [==============================] - 0s 86us/step - loss: 0.1496 - acc: 0.8009 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 894/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1521 - acc: 0.8086 - val_loss: 0.1574 - val_acc: 0.7778\n",
      "Epoch 895/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1550 - acc: 0.7948 - val_loss: 0.1577 - val_acc: 0.7778\n",
      "Epoch 896/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1544 - acc: 0.8071 - val_loss: 0.1579 - val_acc: 0.7778\n",
      "Epoch 897/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1525 - acc: 0.8040 - val_loss: 0.1577 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1563 - acc: 0.7978 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 899/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1509 - acc: 0.8056 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 900/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1548 - acc: 0.7932 - val_loss: 0.1569 - val_acc: 0.7778\n",
      "Epoch 901/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1570 - acc: 0.7978 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 902/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1551 - acc: 0.8071 - val_loss: 0.1565 - val_acc: 0.7778\n",
      "Epoch 903/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1543 - acc: 0.7994 - val_loss: 0.1566 - val_acc: 0.7778\n",
      "Epoch 904/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1550 - acc: 0.7978 - val_loss: 0.1576 - val_acc: 0.7778\n",
      "Epoch 905/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1524 - acc: 0.8025 - val_loss: 0.1574 - val_acc: 0.7778\n",
      "Epoch 906/1000\n",
      "648/648 [==============================] - 0s 133us/step - loss: 0.1533 - acc: 0.8040 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 907/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1558 - acc: 0.7932 - val_loss: 0.1568 - val_acc: 0.7778\n",
      "Epoch 908/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1537 - acc: 0.8071 - val_loss: 0.1567 - val_acc: 0.7917\n",
      "Epoch 909/1000\n",
      "648/648 [==============================] - 0s 70us/step - loss: 0.1534 - acc: 0.7978 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 910/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1525 - acc: 0.8025 - val_loss: 0.1566 - val_acc: 0.7917\n",
      "Epoch 911/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1543 - acc: 0.8133 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 912/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1547 - acc: 0.8025 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 913/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1544 - acc: 0.7870 - val_loss: 0.1578 - val_acc: 0.7917\n",
      "Epoch 914/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1519 - acc: 0.7901 - val_loss: 0.1578 - val_acc: 0.7917\n",
      "Epoch 915/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1505 - acc: 0.8025 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 916/1000\n",
      "648/648 [==============================] - 0s 82us/step - loss: 0.1549 - acc: 0.8025 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 917/1000\n",
      "648/648 [==============================] - 0s 153us/step - loss: 0.1527 - acc: 0.7978 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 918/1000\n",
      "648/648 [==============================] - 0s 122us/step - loss: 0.1549 - acc: 0.7978 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 919/1000\n",
      "648/648 [==============================] - 0s 115us/step - loss: 0.1510 - acc: 0.8117 - val_loss: 0.1573 - val_acc: 0.7917\n",
      "Epoch 920/1000\n",
      "648/648 [==============================] - 0s 119us/step - loss: 0.1535 - acc: 0.8009 - val_loss: 0.1578 - val_acc: 0.7778\n",
      "Epoch 921/1000\n",
      "648/648 [==============================] - 0s 85us/step - loss: 0.1545 - acc: 0.8086 - val_loss: 0.1578 - val_acc: 0.7778\n",
      "Epoch 922/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1556 - acc: 0.7855 - val_loss: 0.1579 - val_acc: 0.7917\n",
      "Epoch 923/1000\n",
      "648/648 [==============================] - 0s 141us/step - loss: 0.1516 - acc: 0.8040 - val_loss: 0.1580 - val_acc: 0.7778\n",
      "Epoch 924/1000\n",
      "648/648 [==============================] - 0s 103us/step - loss: 0.1514 - acc: 0.7917 - val_loss: 0.1578 - val_acc: 0.7778\n",
      "Epoch 925/1000\n",
      "648/648 [==============================] - 0s 117us/step - loss: 0.1496 - acc: 0.8117 - val_loss: 0.1577 - val_acc: 0.7917\n",
      "Epoch 926/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1517 - acc: 0.8133 - val_loss: 0.1580 - val_acc: 0.8056\n",
      "Epoch 927/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1519 - acc: 0.7978 - val_loss: 0.1578 - val_acc: 0.8056\n",
      "Epoch 928/1000\n",
      "648/648 [==============================] - 0s 79us/step - loss: 0.1490 - acc: 0.8102 - val_loss: 0.1582 - val_acc: 0.7917\n",
      "Epoch 929/1000\n",
      "648/648 [==============================] - 0s 102us/step - loss: 0.1536 - acc: 0.7963 - val_loss: 0.1577 - val_acc: 0.7917\n",
      "Epoch 930/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1523 - acc: 0.7978 - val_loss: 0.1583 - val_acc: 0.8056\n",
      "Epoch 931/1000\n",
      "648/648 [==============================] - 0s 112us/step - loss: 0.1529 - acc: 0.8071 - val_loss: 0.1570 - val_acc: 0.7917\n",
      "Epoch 932/1000\n",
      "648/648 [==============================] - 0s 125us/step - loss: 0.1543 - acc: 0.8056 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 933/1000\n",
      "648/648 [==============================] - 0s 106us/step - loss: 0.1488 - acc: 0.8148 - val_loss: 0.1574 - val_acc: 0.7778\n",
      "Epoch 934/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1526 - acc: 0.8056 - val_loss: 0.1575 - val_acc: 0.7778\n",
      "Epoch 935/1000\n",
      "648/648 [==============================] - 0s 98us/step - loss: 0.1525 - acc: 0.8071 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 936/1000\n",
      "648/648 [==============================] - 0s 74us/step - loss: 0.1490 - acc: 0.8133 - val_loss: 0.1580 - val_acc: 0.7917\n",
      "Epoch 937/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1549 - acc: 0.8056 - val_loss: 0.1578 - val_acc: 0.7917\n",
      "Epoch 938/1000\n",
      "648/648 [==============================] - 0s 126us/step - loss: 0.1524 - acc: 0.7994 - val_loss: 0.1575 - val_acc: 0.7778\n",
      "Epoch 939/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1524 - acc: 0.8040 - val_loss: 0.1578 - val_acc: 0.7917\n",
      "Epoch 940/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1537 - acc: 0.8164 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 941/1000\n",
      "648/648 [==============================] - 0s 116us/step - loss: 0.1544 - acc: 0.8040 - val_loss: 0.1580 - val_acc: 0.8056\n",
      "Epoch 942/1000\n",
      "648/648 [==============================] - 0s 107us/step - loss: 0.1507 - acc: 0.8071 - val_loss: 0.1575 - val_acc: 0.7917\n",
      "Epoch 943/1000\n",
      "648/648 [==============================] - 0s 100us/step - loss: 0.1519 - acc: 0.7994 - val_loss: 0.1575 - val_acc: 0.8056\n",
      "Epoch 944/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1532 - acc: 0.8009 - val_loss: 0.1573 - val_acc: 0.8056\n",
      "Epoch 945/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1495 - acc: 0.8056 - val_loss: 0.1575 - val_acc: 0.8056\n",
      "Epoch 946/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1526 - acc: 0.8040 - val_loss: 0.1574 - val_acc: 0.8056\n",
      "Epoch 947/1000\n",
      "648/648 [==============================] - 0s 108us/step - loss: 0.1539 - acc: 0.8040 - val_loss: 0.1582 - val_acc: 0.8056\n",
      "Epoch 948/1000\n",
      "648/648 [==============================] - 0s 104us/step - loss: 0.1504 - acc: 0.8086 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 949/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1504 - acc: 0.8102 - val_loss: 0.1576 - val_acc: 0.7778\n",
      "Epoch 950/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1507 - acc: 0.8086 - val_loss: 0.1570 - val_acc: 0.7778\n",
      "Epoch 951/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1509 - acc: 0.8102 - val_loss: 0.1575 - val_acc: 0.7778\n",
      "Epoch 952/1000\n",
      "648/648 [==============================] - 0s 92us/step - loss: 0.1495 - acc: 0.8009 - val_loss: 0.1572 - val_acc: 0.7778\n",
      "Epoch 953/1000\n",
      "648/648 [==============================] - 0s 77us/step - loss: 0.1515 - acc: 0.8102 - val_loss: 0.1576 - val_acc: 0.7778\n",
      "Epoch 954/1000\n",
      "648/648 [==============================] - 0s 84us/step - loss: 0.1509 - acc: 0.8086 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 955/1000\n",
      "648/648 [==============================] - 0s 90us/step - loss: 0.1517 - acc: 0.8117 - val_loss: 0.1576 - val_acc: 0.7917\n",
      "Epoch 956/1000\n",
      "648/648 [==============================] - 0s 81us/step - loss: 0.1523 - acc: 0.8056 - val_loss: 0.1578 - val_acc: 0.8056\n",
      "Epoch 957/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 0s 84us/step - loss: 0.1541 - acc: 0.8102 - val_loss: 0.1584 - val_acc: 0.8056\n",
      "Epoch 958/1000\n",
      "648/648 [==============================] - 0s 101us/step - loss: 0.1507 - acc: 0.8102 - val_loss: 0.1577 - val_acc: 0.8056\n",
      "Epoch 959/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1560 - acc: 0.8040 - val_loss: 0.1574 - val_acc: 0.7778\n",
      "Epoch 960/1000\n",
      "648/648 [==============================] - 0s 96us/step - loss: 0.1524 - acc: 0.8133 - val_loss: 0.1586 - val_acc: 0.8056\n",
      "Epoch 961/1000\n",
      "648/648 [==============================] - 0s 93us/step - loss: 0.1458 - acc: 0.8102 - val_loss: 0.1579 - val_acc: 0.7917\n",
      "Epoch 962/1000\n",
      "648/648 [==============================] - 0s 99us/step - loss: 0.1509 - acc: 0.8179 - val_loss: 0.1584 - val_acc: 0.8056\n",
      "Epoch 963/1000\n",
      "648/648 [==============================] - 0s 83us/step - loss: 0.1499 - acc: 0.8164 - val_loss: 0.1577 - val_acc: 0.7778\n",
      "Epoch 964/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1558 - acc: 0.7948 - val_loss: 0.1583 - val_acc: 0.7917\n",
      "Epoch 965/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1527 - acc: 0.8009 - val_loss: 0.1585 - val_acc: 0.8056\n",
      "Epoch 966/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1473 - acc: 0.8117 - val_loss: 0.1583 - val_acc: 0.8056\n",
      "Epoch 967/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1505 - acc: 0.8009 - val_loss: 0.1571 - val_acc: 0.7778\n",
      "Epoch 968/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1500 - acc: 0.8009 - val_loss: 0.1580 - val_acc: 0.8056\n",
      "Epoch 969/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1515 - acc: 0.7978 - val_loss: 0.1581 - val_acc: 0.7917\n",
      "Epoch 970/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1544 - acc: 0.7978 - val_loss: 0.1579 - val_acc: 0.7778\n",
      "Epoch 971/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1491 - acc: 0.8148 - val_loss: 0.1578 - val_acc: 0.8056\n",
      "Epoch 972/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1542 - acc: 0.8148 - val_loss: 0.1573 - val_acc: 0.7778\n",
      "Epoch 973/1000\n",
      "648/648 [==============================] - 0s 95us/step - loss: 0.1547 - acc: 0.8040 - val_loss: 0.1589 - val_acc: 0.7917\n",
      "Epoch 974/1000\n",
      "648/648 [==============================] - 0s 87us/step - loss: 0.1519 - acc: 0.8071 - val_loss: 0.1583 - val_acc: 0.7778\n",
      "Epoch 975/1000\n",
      "648/648 [==============================] - 0s 80us/step - loss: 0.1529 - acc: 0.8025 - val_loss: 0.1582 - val_acc: 0.7778\n",
      "Epoch 976/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1510 - acc: 0.8179 - val_loss: 0.1585 - val_acc: 0.8056\n",
      "Epoch 977/1000\n",
      "648/648 [==============================] - 0s 71us/step - loss: 0.1499 - acc: 0.8117 - val_loss: 0.1591 - val_acc: 0.8056\n",
      "Epoch 978/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1545 - acc: 0.7978 - val_loss: 0.1586 - val_acc: 0.8056\n",
      "Epoch 979/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1527 - acc: 0.8040 - val_loss: 0.1585 - val_acc: 0.8056\n",
      "Epoch 980/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1490 - acc: 0.8056 - val_loss: 0.1587 - val_acc: 0.8056\n",
      "Epoch 981/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1510 - acc: 0.8040 - val_loss: 0.1591 - val_acc: 0.8056\n",
      "Epoch 982/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1475 - acc: 0.8071 - val_loss: 0.1583 - val_acc: 0.7778\n",
      "Epoch 983/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1505 - acc: 0.8102 - val_loss: 0.1592 - val_acc: 0.7917\n",
      "Epoch 984/1000\n",
      "648/648 [==============================] - 0s 68us/step - loss: 0.1506 - acc: 0.8009 - val_loss: 0.1581 - val_acc: 0.7778\n",
      "Epoch 985/1000\n",
      "648/648 [==============================] - 0s 67us/step - loss: 0.1461 - acc: 0.8086 - val_loss: 0.1583 - val_acc: 0.7639\n",
      "Epoch 986/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1547 - acc: 0.8040 - val_loss: 0.1591 - val_acc: 0.8056\n",
      "Epoch 987/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1501 - acc: 0.8148 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 988/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1498 - acc: 0.8071 - val_loss: 0.1590 - val_acc: 0.7917\n",
      "Epoch 989/1000\n",
      "648/648 [==============================] - 0s 89us/step - loss: 0.1516 - acc: 0.8056 - val_loss: 0.1580 - val_acc: 0.7778\n",
      "Epoch 990/1000\n",
      "648/648 [==============================] - 0s 69us/step - loss: 0.1497 - acc: 0.8148 - val_loss: 0.1590 - val_acc: 0.8056\n",
      "Epoch 991/1000\n",
      "648/648 [==============================] - 0s 65us/step - loss: 0.1500 - acc: 0.8102 - val_loss: 0.1584 - val_acc: 0.7778\n",
      "Epoch 992/1000\n",
      "648/648 [==============================] - 0s 72us/step - loss: 0.1517 - acc: 0.8133 - val_loss: 0.1592 - val_acc: 0.8056\n",
      "Epoch 993/1000\n",
      "648/648 [==============================] - 0s 94us/step - loss: 0.1476 - acc: 0.8071 - val_loss: 0.1587 - val_acc: 0.8056\n",
      "Epoch 994/1000\n",
      "648/648 [==============================] - 0s 76us/step - loss: 0.1502 - acc: 0.8133 - val_loss: 0.1592 - val_acc: 0.8056\n",
      "Epoch 995/1000\n",
      "648/648 [==============================] - 0s 75us/step - loss: 0.1509 - acc: 0.8210 - val_loss: 0.1589 - val_acc: 0.8056\n",
      "Epoch 996/1000\n",
      "648/648 [==============================] - 0s 66us/step - loss: 0.1513 - acc: 0.8071 - val_loss: 0.1583 - val_acc: 0.7639\n",
      "Epoch 997/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1504 - acc: 0.8117 - val_loss: 0.1587 - val_acc: 0.8056\n",
      "Epoch 998/1000\n",
      "648/648 [==============================] - 0s 64us/step - loss: 0.1491 - acc: 0.8086 - val_loss: 0.1580 - val_acc: 0.7639\n",
      "Epoch 999/1000\n",
      "648/648 [==============================] - 0s 63us/step - loss: 0.1510 - acc: 0.8040 - val_loss: 0.1586 - val_acc: 0.7639\n",
      "Epoch 1000/1000\n",
      "648/648 [==============================] - 0s 62us/step - loss: 0.1519 - acc: 0.8086 - val_loss: 0.1587 - val_acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, validation_split=0.1, epochs=1000,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 30us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model is: 73.33% \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Model is: %.2f%% \" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25b09438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25b09160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(x_test)\n",
    "y_test= [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred: yes</th>\n",
       "      <th>Pred: no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True:yes</th>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True: no</th>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred: yes  Pred: no\n",
       "True:yes         97        19\n",
       "True: no         29        35"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                   index=['True:yes', 'True: no'],\n",
    "                   columns=['Pred: yes', 'Pred: no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model4New.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
